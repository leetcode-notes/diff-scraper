<!DOCTYPE html>
<html class="google" lang="en">
  <head>
    <meta charset="utf-8">
    <script>
    (function(H){H.className=H.className.replace(/\bgoogle\b/,'google-js')})(document.documentElement)
    </script>
    <meta content="initial-scale=1, minimum-scale=1, width=device-width" name="viewport">
    <title>
      Speech Processing - Research at Google
    </title>
    <script src="//www.google.com/js/google.js">
    </script>
    <script>
    new gweb.analytics.AutoTrack({profile:"UA-5974346-1"});
    </script>
    <link href="//fonts.googleapis.com/css?family=Open+Sans:300,400,600,700&amp;lang=en" rel=
    "stylesheet">
    <link href="/css/research.css" rel="stylesheet">
    <link href="/favicon.ico" rel="shortcut icon" type="image/x-icon">
    <link href=
    '//fonts.googleapis.com/css?family=Roboto:100,100italic,300,300italic,400,400italic,500,500italic,700,700italic|Product+Sans:400'
    rel='stylesheet' type='text/css'>
    <link href="/app/app.css" rel="stylesheet">
    <style>
    .app-scope a{color:#4285f4}.app-scope a:hover{color:#3367D6}.app-scope .button-primary{background-color:#4285F4;color:rga(255,255,255,.89);font-weight:400}.app-scope .button-primary:hover{background-color:#3367D6}.app-scope .button-dark{background-color:#005F71;color:#fff;font-weight:400}.app-scope .button-dark:hover{background-color:#004f61;color:#fff}.app-scope header{height:80px}.app-scope header nav{width:635px}.app-scope .header-subnav ul li a{font-weight:400}.app-scope .header-title{padding-top:40px}.app-scope .logo{background:url("/app/images/logo.2x.png");background-size:290px 43px;height:43px;position:relative;top:40px;-webkit-transform:translateY(-50%);-ms-transform:translateY(-50%);transform:translateY(-50%);width:290px}@media(min-width:768px){.app-scope .logo{background:url("/app/images/logo.mini.2x.png");background-size:40px 43px;height:43px;width:40px}}@media(min-width:1024px){.app-scope .logo{background:url("/app/images/logo.2x.png");background-size:290px 43px;height:43px;width:290px}}.app-scope .logo img{display:none}.app-scope .nav-toggle.hamburger{height:20px;top:40px;-webkit-transform:translateY(-50%);-ms-transform:translateY(-50%);transform:translateY(-50%);width:20px}.app-scope .quote p{color:#445a64}.app-scope .slick-slider{-khtml-user-select:all;-moz-user-select:all;-ms-user-select:all;-webkit-user-select:all;user-select:all;-webkit-touch-callout:default;-ms-touch-action:auto;touch-action:auto}.app-scope a.text-link,.app-scope span.text-link{font-weight:400}@media (min-width:768px){.app-scope .search{float:left;width:16px;height:80px;margin-top:0;margin-left:10px;line-height:80px;overflow:hidden}.app-scope .search.search-open{width:auto}.app-scope .search.transition{-webkit-transition:width .5s cubic-bezier(.7,0,.3,1);transition:width .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-form{width:16px;height:50px;margin-top:15px}.app-scope .search.search-open .search-form{width:150px}.app-scope .search.transition .search-form{-webkit-transition:width .5s cubic-bezier(.7,0,.3,1);transition:width .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-form:after{width:0}.app-scope .search.search-open .search-form:after{width:100%}.app-scope .search.transition .search-form:after{-webkit-transition:width .4s cubic-bezier(.7,0,.3,1) .1s;transition:width .4s cubic-bezier(.7,0,.3,1) .1s}.app-scope .search-input{position:absolute;top:0;right:0;margin:0;width:100%;opacity:0}.app-scope .search.search-open .search-input{opacity:1}.app-scope .search.transition .search-input{-webkit-transition:opacity .5s cubic-bezier(.7,0,.3,1);transition:opacity .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-submit,.app-scope .search-toggle{bottom:17px}.app-scope .search.transition .search-submit,.app-scope .search.transition .search-toggle{-webkit-transition:opacity .5s cubic-bezier(.7,0,.3,1),visibility .5s cubic-bezier(.7,0,.3,1);transition:opacity .5s cubic-bezier(.7,0,.3,1),visibility .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-toggle{visibility:visible;z-index:5;opacity:.8}.app-scope .search-submit,.app-scope .search.search-open .search-toggle{z-index:4;opacity:0}.app-scope .search.search-open .search-submit{z-index:5;opacity:1}.app-scope .search-close{opacity:0}.app-scope .search.search-open .search-close{opacity:.8}.app-scope .search.transition .search-close{-webkit-transition:opacity .5s cubic-bezier(.7,0,.3,1);transition:opacity .5s cubic-bezier(.7,0,.3,1)}.app-scope .flyout-container{position:relative;right:auto;width:100%;height:80px;padding:0;background:0 0;overflow:hidden}.app-scope .nav-wrapper{float:right}.app-scope .nav-wrapper>ul{float:left;display:inline-block;height:80px;line-height:80px}.app-scope .nav-wrapper>ul li{display:inline-block;margin-left:10px}.app-scope .nav-wrapper>ul li+li{margin-top:0}.app-scope .nav-wrapper>ul li a{font-size:13px;font-weight:400;color:rgba(255,255,255,.8)}.app-scope .nav-wrapper>ul a:hover,.app-scope .nav-wrapper>ul li.active a{color:#fff}.app-scope .nav-toggle{display:none}.app-scope .flyout-secondary-nav{display:none}}@media (min-width:1024px){.app-scope .search{float:left;width:16px;height:80px;margin-top:0;margin-left:10px;line-height:80px;overflow:hidden}.app-scope .search.search-open{width:auto}.app-scope .search.transition{-webkit-transition:width .5s cubic-bezier(.7,0,.3,1);transition:width .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-form{width:16px;height:50px;margin-top:15px}.app-scope .search.search-open .search-form{width:150px}.app-scope .search.transition .search-form{-webkit-transition:width .5s cubic-bezier(.7,0,.3,1);transition:width .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-form:after{width:0}.app-scope .search.search-open .search-form:after{width:100%}.app-scope .search.transition .search-form:after{-webkit-transition:width .4s cubic-bezier(.7,0,.3,1) .1s;transition:width .4s cubic-bezier(.7,0,.3,1) .1s}.app-scope .search-input{position:absolute;top:0;right:0;margin:0;width:100%;opacity:0}.app-scope .search.search-open .search-input{opacity:1}.app-scope .search.transition .search-input{-webkit-transition:opacity .5s cubic-bezier(.7,0,.3,1);transition:opacity .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-submit,.app-scope .search-toggle{bottom:17px}.app-scope .search.transition .search-submit,.app-scope .search.transition .search-toggle{-webkit-transition:opacity .5s cubic-bezier(.7,0,.3,1),visibility .5s cubic-bezier(.7,0,.3,1);transition:opacity .5s cubic-bezier(.7,0,.3,1),visibility .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-toggle{visibility:visible;z-index:5;opacity:.8}.app-scope .search-submit,.app-scope .search.search-open .search-toggle{z-index:4;opacity:0}.app-scope .search.search-open .search-submit{z-index:5;opacity:1}.app-scope .search-close{opacity:0}.app-scope .search.search-open .search-close{opacity:.8}.app-scope .search.transition .search-close{-webkit-transition:opacity .5s cubic-bezier(.7,0,.3,1);transition:opacity .5s cubic-bezier(.7,0,.3,1)}.app-scope .flyout-container{position:relative;right:auto;width:100%;height:80px;padding:0;background:0 0;overflow:hidden}.app-scope .nav-wrapper{float:right}.app-scope .nav-wrapper>ul{float:left;display:inline-block;height:80px;line-height:80px}.app-scope .nav-wrapper>ul li{display:inline-block;margin-left:10px}.app-scope .nav-wrapper>ul li+li{margin-top:0}.app-scope .nav-wrapper>ul li a{font-size:13px;font-weight:400;color:rgba(255,255,255,.8)}.app-scope .nav-wrapper>ul a:hover,.app-scope .nav-wrapper>ul li.active a{color:#fff}.app-scope .nav-toggle{display:none}.app-scope .flyout-secondary-nav{display:none}}@media (min-width:1170px){.app-scope .search{float:left;width:16px;height:80px;margin-top:0;margin-left:10px;line-height:80px;overflow:hidden}.app-scope .search.search-open{width:auto}.app-scope .search.transition{-webkit-transition:width .5s cubic-bezier(.7,0,.3,1);transition:width .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-form{width:16px;height:50px;margin-top:15px}.app-scope .search.search-open .search-form{width:150px}.app-scope .search.transition .search-form{-webkit-transition:width .5s cubic-bezier(.7,0,.3,1);transition:width .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-form:after{width:0}.app-scope .search.search-open .search-form:after{width:100%}.app-scope .search.transition .search-form:after{-webkit-transition:width .4s cubic-bezier(.7,0,.3,1) .1s;transition:width .4s cubic-bezier(.7,0,.3,1) .1s}.app-scope .search-input{position:absolute;top:0;right:0;margin:0;width:100%;opacity:0}.app-scope .search.search-open .search-input{opacity:1}.app-scope .search.transition .search-input{-webkit-transition:opacity .5s cubic-bezier(.7,0,.3,1);transition:opacity .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-submit,.app-scope .search-toggle{bottom:17px}.app-scope .search.transition .search-submit,.app-scope .search.transition .search-toggle{-webkit-transition:opacity .5s cubic-bezier(.7,0,.3,1),visibility .5s cubic-bezier(.7,0,.3,1);transition:opacity .5s cubic-bezier(.7,0,.3,1),visibility .5s cubic-bezier(.7,0,.3,1)}.app-scope .search-toggle{visibility:visible;z-index:5;opacity:.8}.app-scope .search-submit,.app-scope .search.search-open .search-toggle{z-index:4;opacity:0}.app-scope .search.search-open .search-submit{z-index:5;opacity:1}.app-scope .search-close{opacity:0}.app-scope .search.search-open .search-close{opacity:.8}.app-scope .search.transition .search-close{-webkit-transition:opacity .5s cubic-bezier(.7,0,.3,1);transition:opacity .5s cubic-bezier(.7,0,.3,1)}.app-scope .flyout-container{position:relative;right:auto;width:100%;height:80px;padding:0;background:0 0;overflow:hidden}.app-scope .nav-wrapper{float:right}.app-scope .nav-wrapper>ul{float:left;display:inline-block;height:80px;line-height:80px}.app-scope .nav-wrapper>ul li{display:inline-block;margin-left:10px}.app-scope .nav-wrapper>ul li+li{margin-top:0}.app-scope .nav-wrapper>ul li a{font-size:13px;font-weight:400;color:rgba(255,255,255,.8)}.app-scope .nav-wrapper>ul a:hover,.app-scope .nav-wrapper>ul li.active a{color:#fff}.app-scope .nav-toggle{display:none}.app-scope .flyout-secondary-nav{display:none}}
    </style>
    <style>
    .app-scope.header-v2 .body{position:fixed;top:0;width:100%;background-color:#fff;z-index:1000}.app-scope.header-v2 .body.is-scrolled{box-shadow:0 1px 2px #ddd}.app-scope.header-v2 .top-padding{height:75px}.app-scope.header-v2 .top-padding.subnav-active{height:106px}@media (min-width:650px){.app-scope.header-v2 .top-padding{height:117px}.app-scope.header-v2 .top-padding.subnav-active{height:148px}}.app-scope.header-v2 .logo-wrapper-v2{border-bottom:1px solid #ddd}.app-scope.header-v2 .nav-wrapper-v2{border-bottom:1px solid #ddd}.app-scope.header-v2 .subnav-wrapper-v2{border-bottom:1px solid #ddd}.app-scope.header-v2 .logo-wrapper-v2,.app-scope.header-v2 .subnav-wrapper-v2{background:#fafafa;background:-moz-linear-gradient(top,#fafafa,#f5f5f5);background:-webkit-gradient(linear,left top,left bottom,color-stop(0,#fafafa),color-stop(1,#f5f5f5));background:-webkit-linear-gradient(top,#fafafa,#f5f5f5);background:-o-linear-gradient(top,#fafafa,#f5f5f5 100%);background:-ms-linear-gradient(top,#fafafa,#f5f5f5 100%);background:linear-gradient(to top,#fafafa,#f5f5f5);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#fafafa',endColorstr='#f5f5f5',GradientType=1)}.app-scope.header-v2 .logo-v2{display:inline-block;margin:13px 0 13px 0}.app-scope.header-v2 .logo-v2 .wide-logo{display:none;height:43px;width:315px}.app-scope.header-v2 .logo-v2 .narrow-logo{display:block;height:43px;width:40px}@media (min-width:400px){.app-scope.header-v2 .logo-v2 .wide-logo{display:block}.app-scope.header-v2 .logo-v2 .narrow-logo{display:none}}.app-scope.header-v2 .search-v2{display:none;position:absolute;right:15px;top:22px}@media (min-width:650px){.app-scope.header-v2 .search-v2{display:block}}@media (min-width:768px){.app-scope.header-v2 .search-v2{right:30px}}@media (min-width:1230px){.app-scope.header-v2 .search-v2{right:0}}.app-scope.header-v2 .search-v2 .search-button{background:url(/app/images/search-icon.png);background-color:#4285F4;background-size:15px 15px;background-position:center;background-repeat:no-repeat;border:none;border-top-right-radius:2px;border-bottom-right-radius:2px;width:30px;height:30px;vertical-align:top}.app-scope.header-v2 .search-v2 .search-box{width:160px;height:30px;padding:3px;border:solid 1px #ccc;border-top-left-radius:2px;border-bottom-left-radius:2px;vertical-align:top}.app-scope.header-v2 .hamburger-v2{display:block;position:absolute;right:15px;top:30px;font-size:16px}@media (min-width:650px){.app-scope.header-v2 .hamburger-v2{display:none}}.app-scope.header-v2 .nav-wrapper-v2{display:none}@media (min-width:650px){.app-scope.header-v2 .nav-wrapper-v2{display:block}}.app-scope.header-v2 .nav-wrapper-v2 li{display:inline-block}.app-scope.header-v2 .nav-wrapper-v2 li a{color:#63666a;font-size:16px;font-weight:400;padding:7px 0;margin-right:20px;display:block;-webkit-transition:border-color .4s ease-in-out;-moz-transition:border-color .4s ease-in-out;-ms-transition:border-color .4s ease-in-out;-o-transition:border-color .4s ease-in-out;transition:border-color .4s ease-in-out;border-bottom:4px solid #fff}.app-scope.header-v2 .nav-wrapper-v2 li a.active{border-bottom:4px solid #4285F4}.app-scope.header-v2 .nav-wrapper-v2 li a:hover{border-bottom:4px solid #4285F4}.app-scope.header-v2 .subnav-wrapper-v2{display:none;overflow-x:auto}.app-scope.header-v2 .subnav-wrapper-v2>.inner{min-width:768px}.app-scope.header-v2 .subnav-wrapper-v2.active{display:block}.app-scope.header-v2 .subnav-wrapper-v2 li{display:inline-block}.app-scope.header-v2 .subnav-wrapper-v2 li a{color:#63666a;font-size:13px;font-weight:400;padding:7px 0;margin-right:20px;display:block;-webkit-transition:color .4s ease-in-out;-moz-transition:color .4s ease-in-out;-ms-transition:color .4s ease-in-out;-o-transition:color .4s ease-in-out;transition:color .4s ease-in-out}.app-scope.header-v2 .subnav-wrapper-v2 li a.active{color:#4285F4}.app-scope.header-v2 .subnav-wrapper-v2 li a:hover{color:#4285F4}.app-scope.header-v2 .flyout-container{position:fixed;width:300px;right:-300px;height:100%}.app-scope.header-v2 .flyout-secondary-nav .secondary-nav-block{margin:10px 0}.app-scope.header-v2 .expanding-list .title{font-size:16px;color:#fff;text-transform:uppercase;letter-spacing:.02em}.app-scope.header-v2 .expanding-list .svg-icon{float:right;width:inherit;height:inherit;color:#fff}.app-scope.header-v2 .expanding-list .icon-chevron-down{-webkit-transition:transform .3s linear,color .3s linear;-ms-transition:transform .3s linear,color .3s linear;transition:transform .3s linear,color .3s linear}.app-scope.header-v2 .expanding-list .links-visible .icon-chevron-down{-webkit-transform:translateY(-50%) rotateX(180deg);-ms-transform:translateY(-50%) rotate(180deg);transform:translateY(-50%) rotateX(180deg)}.app-scope.header-v2 .expanding-list ul{margin-top:15px}.app-scope.header-v2 .expanding-list ul li{margin-left:10px}.app-scope.header-v2 .expanding-list ul li:before{content:"-";color:#fff}.app-scope.header-v2 .expanding-list ul a{text-transform:none;font-size:14px}.ng-cloak{display:none !important}
    </style>
  </head>
  <body>
    <div class="app-scope header-v2" ng-controller="HeaderCtrlV2 as vm">
      <div class="body" ng-class="{'is-scrolled': isScrolled}">
        <div class="logo-wrapper-v2">
          <div class="inner">
            <a class="logo-v2" href="/"><img alt="Research at Google" class="narrow-logo" src=
            "/app/images/logo.mini.2x.png"> <img alt="Research at Google" class="wide-logo" src=
            "/app/images/logo-v2.2x.png"></a>
            <div class="search-v2">
              <form ng-submit="vm.search()">
                <input class="search-box" ng-model="vm.searchText" placeholder=
                " Search"><button class="search-button" ng-click="vm.search()">&nbsp;</button>
              </form>
            </div>
            <div class="hamburger-v2">
              <span class="svg-icon icon-hamburger" ng-click="toggle = !toggle">&nbsp;</span>
            </div>
          </div>
        </div>
        <div class="nav-wrapper-v2 ng-cloak">
          <div class="inner">
            <ul>
              <li ng-repeat="link in mainLinks">
                <a gr-main-nav-active-link="true" href="{{link.href}}" target=
                "{{link.target || '_self'}}">{{link.text}}</a>
              </li>
            </ul>
          </div>
        </div>
        <div class="subnav-wrapper-v2 ng-cloak" ng-class="{'active': subNavActive}">
          <div class="inner">
            <ul>
              <li ng-repeat="link in subNavLinks">
                <a gr-sub-nav-active-link="true" href="{{link.href}}">{{link.text}}</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
      <nav ng-class="{'open' : toggle}">
        <div class="flyout-container" id="flyoutMenu">
          <div class="nav-wrapper">
            <ul>
              <li>
                <a class="dark" gr-active-link="true" href="/">Home</a>
              </li>
              <li>
                <a gr-active-link="true" href="/pubs/papers.html" ng-click=
                "toggle = false; searchToggle = false">Publications</a>
              </li>
              <li>
                <a gr-active-link="true" href="/researchers.html" ng-click=
                "toggle = false; searchToggle = false">People</a>
              </li>
              <li>
                <a gr-active-link="true" href="/teams/" ng-click=
                "toggle = false; searchToggle = false">Teams</a>
              </li>
              <li>
                <div expanding-list="true" links="outreachLinks" title="Outreach">
                  &nbsp;
                </div>
              </li>
              <li>
                <a href="http://googleresearch.blogspot.com/" ng-click=
                "toggle = false; searchToggle = false" target="_blank">Blog</a>
              </li>
              <li>
                <a gr-active-link="true" href="/workatgoogle.html" ng-click=
                "toggle = false; searchToggle = false">Work at Google</a>
              </li>
            </ul>
            <div class="search transition" ng-class="{'search-open' : searchToggle}">
              <form class="search-form" ng-submit="vm.search();">
                <input class="search-input" id="search" name="search" ng-model="vm.searchText"
                placeholder="Search" type="search" value=""> <input class="search-submit" ng-click=
                "toggle = false" type="submit" value=""> <label class="search-toggle" for="search"
                ng-click="searchToggle = !searchToggle">&nbsp;</label>
                <div class="search-close" ng-click="searchToggle = false">
                  <span class="svg-icon icon-close">&nbsp;</span>
                </div>
              </form>
            </div>
            <div class="flyout-secondary-nav">
              <div class="secondary-nav-block">
                <span>More</span>
                <ul>
                  <li>
                    <a class="dark" href="http://scholar.google.com/" target="_blank">Google
                    Scholar</a>
                  </li>
                  <li>
                    <a class="dark" href="http://www.youtube.com/user/GoogleTechTalks/featured"
                    target="_blank">YouTube Tech Talks</a>
                  </li>
                </ul>
              </div>
              <div class="secondary-nav-block">
                <span>Follow Us</span>
                <ul>
                  <li>
                    <a class="dark" href="https://plus.google.com/+ResearchatGoogle" target=
                    "_blank">Google+</a>
                  </li>
                  <li>
                    <a class="dark" href="http://twitter.com/googleresearch" target=
                    "_blank">Twitter</a>
                  </li>
                </ul>
              </div>
              <div class="secondary-nav-block">
                <span>Google</span>
                <ul>
                  <li>
                    <a class="dark" href="http://google.com" target="_blank">Google</a>
                  </li>
                  <li>
                    <a class="dark" href="http://www.google.com/intl/en/about/" target=
                    "_blank">About Google</a>
                  </li>
                  <li>
                    <a class="dark" href="http://www.google.com/intl/en/policies/privacy/" target=
                    "_blank">Privacy Policy</a>
                  </li>
                  <li>
                    <a class="dark" href="http://www.google.com/intl/en/policies/terms/" target=
                    "_blank">Terms</a>
                  </li>
                </ul>
              </div>
            </div>
          </div>
          <div class="nav-toggle close" ng-click="toggle = !toggle">
            <span class="svg-icon icon-close">&nbsp;</span>
          </div>
        </div>
      </nav>
      <div class="top-padding" ng-class="{'subnav-active': subNavActive}">
        &nbsp;
      </div>
    </div>
    <div id="maia-main" role="main">
      <div class="maia-teleport" id="content"></div>
      <div id="cse">
        &nbsp;
      </div>
      <h1>
        Speech Processing
      </h1>
      <div class="maia-cols">
        <div class="maia-col-4">
          <div>
            <div class="sidebar">
              <p>
                Our goal in Speech Technology Research is twofold: to make speaking to devices
                around you (home, in car), devices you wear (watch), devices with you (phone,
                tablet) ubiquitous and seamless.
              </p>
              <p>
                Our research focuses on what makes Google unique: computing scale and data. Using
                large scale computing resources pushes us to rethink the architecture and
                algorithms of speech recognition, and experiment with the kind of methods that have
                in the past been considered prohibitively expensive. We also look at parallelism
                and cluster computing in a new light to change the way experiments are run,
                algorithms are developed and research is conducted. The field of speech recognition
                is data-hungry, and using more and more data to tackle a problem tends to help
                performance but poses new challenges: how do you deal with data overload? How do
                you leverage unsupervised and semi-supervised techniques at scale? Which class of
                algorithms merely compensate for lack of data and which scale well with the task at
                hand? Increasingly, we find that the answers to these questions are surprising, and
                steer the whole field into directions that would never have been considered, were
                it not for the availability of significantly higher orders of magnitude of data.
              </p>
              <p>
                We are also in a unique position to deliver very user-centric research. Researchers
                have the wealth of millions of users talking to Voice Search or the Android Voice
                Input every day. and can conduct live experiments to test and benchmark new
                algorithms directly in a realistic controlled environment. Whether these are
                algorithmic performance improvements or user experience and human-computer
                interaction studies, we keep our users very close to make sure we solve real
                problems and have real impact.
              </p>
              <p>
                We have a huge commitment to the diversity of our users, and have made it a
                priority to deliver the best performance to every language on the planet. We
                currently have systems operating in more than 55 languages and we keep expanding
                our reach to more and more users. The challenges of internationalizing at scale is
                immense and rewarding. Many speakers of the languages we reach never had the
                experience of speaking to a computer before, and breaking this new ground brings up
                new research on how to better serve this wide variety of users. Combined with the
                unprecedented translation capabilities of Google Translate, we are now at the
                forefront of research in speech-to-speech translation and one step closer to a
                universal translator.
              </p>
              <p>
                In terms of a challenge, indexing and transcribing the web’s audio content is
                another challenge we have set for ourself, and is nothing short of gargantuan, both
                in scope and difficulty. The videos uploaded every day on YouTube range from
                lectures, to newscasts, music videos and of course... cat videos. Making sense of
                them takes the challenges of noise robustness, music recognition, speaker
                segmentation, language detection to new levels of difficulty. The payoff is
                immense: imagine making every lecture on the web accessible to every language; this
                is the kind of impact we are striving for.
              </p>
            </div>
          </div>
        </div>
        <div class="maia-col-8">
          <div class="mainbar">
            <h2>
              200 Publications
            </h2>
            <div class="section">
              <ul class="pub-list">
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Generative+Model-Based+Text-to-Speech+Synthesis+Zen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45882.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45882.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45882.html">Generative Model-Based Text-to-Speech
                    Synthesis</a>
                  </p>
                  <p>
                    <a href="/pubs/HeigaZen.html">Heiga Zen</a>
                  </p>
                  <p>
                    MIT (2017)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=AN+ACOUSTIC+KEYSTROKE+TRANSIENT+CANCELER+FOR+SPEECH+COMMUNICATION+TERMINALS+USING+A+SEMI-BLIND+ADAPTIVE+FILTER+MODEL+Buchner+Godsill+Skoglund"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    AN ACOUSTIC KEYSTROKE TRANSIENT CANCELER FOR SPEECH COMMUNICATION TERMINALS
                    USING A SEMI-BLIND ADAPTIVE FILTER MODEL
                  </p>
                  <p>
                    Herbert Buchner, Simon Godsill, <a href="/pubs/JanSkoglund.html">Jan
                    Skoglund</a>
                  </p>
                  <p>
                    ICASSP (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=AutoMOS:+Learning+a+non-intrusive+assessor+of+naturalness-of-speech+Patton+Agiomyrgiannakis+Terry+Wilson+Saurous+Sculley"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "https://arxiv.org/abs/1611.09207" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45744.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45744.html">AutoMOS: Learning a non-intrusive assessor of
                    naturalness-of-speech</a>
                  </p>
                  <p>
                    <a href="/pubs/105050.html">Brian Patton</a>, <a href=
                    "/pubs/author57972.html">Yannis Agiomyrgiannakis</a>, Michael Terry, <a href=
                    "/pubs/KevinWilson.html">Kevin Wilson</a>, Rif A. Saurous, <a href=
                    "/pubs/author38217.html">D. Sculley</a>
                  </p>
                  <p>
                    NIPS 2016 End-to-end Learning for Speech and Audio Processing Workshop (to
                    appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Automatic+Optimization+of+Data+Perturbation+Distributions+for+Multi-Style+Training+in+Speech+Recognition+Doulaty+Rose+Siohan"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45679.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45679.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45679.html">Automatic Optimization of Data Perturbation
                    Distributions for Multi-Style Training in Speech Recognition</a>
                  </p>
                  <p>
                    Mortaza Doulaty, <a href="/pubs/104847.html">Richard Rose</a>, <a href=
                    "/pubs/OlivierSiohan.html">Olivier Siohan</a>
                  </p>
                  <p>
                    Proceedings of the IEEE 2016 Workshop on Spoken Language Technology (SLT2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=BI-MAGNITUDE+PROCESSING+FRAMEWORK+FOR+NONLINEAR+ACOUSTIC+ECHO+CANCELLATION+ON+ANDROID+DEVICES+Huang+Skoglund+Luebs"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    BI-MAGNITUDE PROCESSING FRAMEWORK FOR NONLINEAR ACOUSTIC ECHO CANCELLATION ON
                    ANDROID DEVICES
                  </p>
                  <p>
                    Yiteng (Arden) Huang, <a href="/pubs/JanSkoglund.html">Jan Skoglund</a>,
                    Alejandro Luebs
                  </p>
                  <p>
                    International Workshop on Acoustic Signal Enhancement 2016 (IWAENC2016) (to
                    appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Building+Statistical+Parametric+Multi-speaker+Synthesis+for+Bangladeshi+Bangla+Gutkin+Ha+Jansche+Kjartansson+Pipatsrisawat+Sproat"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45301.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45301.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45301.html">Building Statistical Parametric Multi-speaker
                    Synthesis for Bangladeshi Bangla</a>
                  </p>
                  <p>
                    <a href="/pubs/AlexanderGutkin.html">Alexander Gutkin</a>, Linne Ha, <a href=
                    "/pubs/author35845.html">Martin Jansche</a>, Oddur Kjartansson, Knot
                    Pipatsrisawat, <a href="/pubs/RichardSproat.html">Richard Sproat</a>
                  </p>
                  <p>
                    SLTU-2016 5th Workshop on Spoken Language Technologies for Under-resourced
                    languages, 09-12 May 2016, Yogyakarta, Indonesia; Procedia Computer Science,
                    Elsevier B.V., pp. 194-200
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Complex+Linear+Projection+(CLP):+A+Discriminative+Approach+to+Joint+Feature+Extraction+and+Acoustic+Modeling+Variani+Sainath+Shafran+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45621.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45621.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45621.html">Complex Linear Projection (CLP): A Discriminative
                    Approach to Joint Feature Extraction and Acoustic Modeling</a>
                  </p>
                  <p>
                    <a href="/pubs/EhsanVariani.html">Ehsan Variani</a>, <a href=
                    "/pubs/TaraSainath.html">Tara N. Sainath</a>, <a href=
                    "/pubs/IzhakShafran.html">Izhak Shafran</a>, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>
                  </p>
                  <p>
                    Interspeech 2016 (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Contextual+prediction+models+for+speech+recognition+Halpern+Hall+Schogol+Riley+Roark+Skobeltsyn+Baeuml"
                  target="_blank">&nbsp;</a><a class="abstract-icon tooltip" href=
                  "/pubs/pub45547.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45547.html">Contextual prediction models for speech
                    recognition</a>
                  </p>
                  <p>
                    Yoni Halpern, <a href="/pubs/author38002.html">Keith Hall</a>, Vlad Schogol,
                    <a href="/pubs/author125.html">Michael Riley</a>, <a href=
                    "/pubs/BrianRoark.html">Brian Roark</a>, <a href=
                    "/pubs/GlebSkobeltsyn.html">Gleb Skobeltsyn</a>, Martin Baeuml
                  </p>
                  <p>
                    Proceedings of Interspeech 2016 (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Cross-lingual+projection+for+class-based+language+models+Gfeller+Schogol+Hall"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "https://www.aclweb.org/anthology/P/P16/P16-2014.pdf" target=
                  "_blank">&nbsp;</a><a class="abstract-icon tooltip" href=
                  "/pubs/pub45546.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45546.html">Cross-lingual projection for class-based language
                    models</a>
                  </p>
                  <p>
                    Beat Gfeller, Vlad Schogol, <a href="/pubs/author38002.html">Keith Hall</a>
                  </p>
                  <p>
                    ACL2016
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Directly+Modeling+Voiced+and+Unvoiced+Components+in+Speech+Waveforms+by+Neural+Networks+Tokuda+Zen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44808.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub44808.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44808.html">Directly Modeling Voiced and Unvoiced Components
                    in Speech Waveforms by Neural Networks</a>
                  </p>
                  <p>
                    Keiichi Tokuda, <a href="/pubs/HeigaZen.html">Heiga Zen</a>
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP), IEEE (2016), pp. 5640-5644
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Distributed+representation+and+estimation+of+WFST-based+n-gram+models+Allauzen+Riley+Roark"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45528.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45528.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45528.html">Distributed representation and estimation of
                    WFST-based n-gram models</a>
                  </p>
                  <p>
                    <a href="/pubs/author130.html">Cyril Allauzen</a>, <a href=
                    "/pubs/author125.html">Michael Riley</a>, <a href="/pubs/BrianRoark.html">Brian
                    Roark</a>
                  </p>
                  <p>
                    Proceedings of the ACL Workshop on Statistical NLP and Weighted Automata
                    (StatFSM) (2016), pp. 32-41
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=End-to-End+Text-Dependent+Speaker+Verification+Heigold+Moreno+Bengio+Shazeer"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44681.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub44681.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44681.html">End-to-End Text-Dependent Speaker
                    Verification</a>
                  </p>
                  <p>
                    <a href="/pubs/GeorgHeigold.html">Georg Heigold</a>, <a href=
                    "/pubs/IgnacioLopezMoreno.html">Ignacio Moreno</a>, <a href=
                    "/pubs/bengio.html">Samy Bengio</a>, Noam M. Shazeer
                  </p>
                  <p>
                    International Conference on Acoustics, Speech and Signal Processing (ICASSP),
                    IEEE (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Factored+Spatial+and+Spectral+Multichannel+Raw+Waveform+CLDNNs+Sainath+Weiss+Wilson+Narayanan+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44640.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Factored Spatial and Spectral Multichannel Raw Waveform CLDNNs
                  </p>
                  <p>
                    <a href="/pubs/TaraSainath.html">Tara N. Sainath</a>, <a href=
                    "/pubs/RonWeiss.html">Ron J. Weiss</a>, <a href="/pubs/KevinWilson.html">Kevin
                    W. Wilson</a>, <a href="/pubs/ArunNarayanan.html">Arun Narayanan</a>, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>
                  </p>
                  <p>
                    International Conference on Acoustics, Speech and Signal Processing (ICASSP),
                    IEEE (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Fast,+Compact,+and+High+Quality+LSTM-RNN+Based+Statistical+Parametric+Speech+Synthesizers+for+Mobile+Devices+Zen+Agiomyrgiannakis+Egberts+Henderson+Szczepaniak"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45379.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45379.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45379.html">Fast, Compact, and High Quality LSTM-RNN Based
                    Statistical Parametric Speech Synthesizers for Mobile Devices</a>
                  </p>
                  <p>
                    <a href="/pubs/HeigaZen.html">Heiga Zen</a>, <a href=
                    "/pubs/author57972.html">Yannis Agiomyrgiannakis</a>, Niels Egberts, <a href=
                    "/pubs/104803.html">Fergus Henderson</a>, Przemysław Szczepaniak
                  </p>
                  <p>
                    Proc. Interspeech, San Francisco, CA, USA (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=GLOBALLY+OPTIMIZED+LEAST-SQUARES+POST-FILTERING+FOR+MICROPHONE+ARRAY+SPEECH+ENHANCEMENT+Huang+Luebs+Skoglund+Kleijn"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    GLOBALLY OPTIMIZED LEAST-SQUARES POST-FILTERING FOR MICROPHONE ARRAY SPEECH
                    ENHANCEMENT
                  </p>
                  <p>
                    Yiteng (Arden) Huang, Alejandro Luebs, <a href="/pubs/JanSkoglund.html">Jan
                    Skoglund</a>, W. Bastiaan Kleijn
                  </p>
                  <p>
                    ICASSP (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=High+quality+agreement-based+semi-supervised+training+data+for+acoustic+modeling+De+Quitry+Oines+Moreno+Weinstein"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45770.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45770.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45770.html">High quality agreement-based semi-supervised
                    training data for acoustic modeling</a>
                  </p>
                  <p>
                    <a href="/pubs/FelixdeChaumontQuitry.html">Félix de Chaumont Quitry</a>, Asa
                    Oines, <a href="/pubs/author5289.html">Pedro Moreno</a>, Eugene Weinstein
                  </p>
                  <p>
                    2016 IEEE Workshop on Spoken Language Technology
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Learning+Compact+Recurrent+Neural+Networks+Lu+Sindhwani+Sainath"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Learning Compact Recurrent Neural Networks
                  </p>
                  <p>
                    Zhiyun Lu, <a href="/pubs/VikasSindhwani.html">Vikas Sindhwani</a>, <a href=
                    "/pubs/TaraSainath.html">Tara Sainath</a>
                  </p>
                  <p>
                    IEEE International Conference on Acoustics, Speech, and Signal Processing
                    (ICASSP), 2016
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Learning+N-gram+Language+Models+from+Uncertain+Data+Kuznetsov+Liao+Mohri+Riley+Roark"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45483.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45483.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45483.html">Learning N-gram Language Models from Uncertain
                    Data</a>
                  </p>
                  <p>
                    <a href="/pubs/104920.html">Vitaly Kuznetsov</a>, <a href=
                    "/pubs/author37501.html">Hank Liao</a>, <a href="/pubs/author122.html">Mehryar
                    Mohri</a>, <a href="/pubs/author125.html">Michael Riley</a>, <a href=
                    "/pubs/BrianRoark.html">Brian Roark</a>
                  </p>
                  <p>
                    Interspeech (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Learning+Personalized+Pronunciations+for+Contact+Names+Recognition+Bruguier+Peng+Beaufays"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45415.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45415.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45415.html">Learning Personalized Pronunciations for Contact
                    Names Recognition</a>
                  </p>
                  <p>
                    <a href="/pubs/105173.html">Tony Bruguier</a>, <a href=
                    "/pubs/FuchunPeng.html">Fuchun Peng</a>, <a href=
                    "/pubs/author21120.html">Francoise Beaufays</a>
                  </p>
                  <p>
                    Interspeech 2016 (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Listen,+Attend+and+Spell:+A+Neural+Network+for+Large+Vocabulary+Conversational+Speech+Recognition+Chan+Jaitly+Le+Vinyals"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44926.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub44926.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44926.html">Listen, Attend and Spell: A Neural Network for
                    Large Vocabulary Conversational Speech Recognition</a>
                  </p>
                  <p>
                    William Chan, <a href="/pubs/NavdeepJaitly.html">Navdeep Jaitly</a>, <a href=
                    "/pubs/QuocLe.html">Quoc V. Le</a>, <a href="/pubs/OriolVinyals.html">Oriol
                    Vinyals</a>
                  </p>
                  <p>
                    ICASSP (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Lower+Frame+Rate+Neural+Network+Acoustic+Models+Pundak+Sainath"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45555.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45555.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45555.html">Lower Frame Rate Neural Network Acoustic
                    Models</a>
                  </p>
                  <p>
                    <a href="/pubs/GolanPundak.html">Golan Pundak</a>, <a href=
                    "/pubs/TaraSainath.html">Tara Sainath</a>
                  </p>
                  <p>
                    Interspeech (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Modeling+Time-Frequency+Patterns+with+LSTM+vs.+Convolutional+Architectures+for+LVCSR+Tasks+Sainath+Li"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45401.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45401.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45401.html">Modeling Time-Frequency Patterns with LSTM vs.
                    Convolutional Architectures for LVCSR Tasks</a>
                  </p>
                  <p>
                    <a href="/pubs/TaraSainath.html">Tara N. Sainath</a>, <a href=
                    "/pubs/BoLi.html">Bo Li</a>
                  </p>
                  <p>
                    Proc. Interspeech, ISCA (2016) (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Multi-Language+Multi-Speaker+Acoustic+Modeling+for+LSTM-RNN+based+Statistical+Parametric+Speech+Synthesis+Li+Zen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45400.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45400.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45400.html">Multi-Language Multi-Speaker Acoustic Modeling
                    for LSTM-RNN based Statistical Parametric Speech Synthesis</a>
                  </p>
                  <p>
                    <a href="/pubs/BoLi.html">Bo Li</a>, <a href="/pubs/HeigaZen.html">Heiga
                    Zen</a>
                  </p>
                  <p>
                    Proc. Interspeech, ISCA (2016) (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Neural+Network+Adaptive+Beamforming+for+Robust+Multichannel+Speech+Recognition+Li+Sainath+Weiss+Wilson+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45399.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45399.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45399.html">Neural Network Adaptive Beamforming for Robust
                    Multichannel Speech Recognition</a>
                  </p>
                  <p>
                    <a href="/pubs/BoLi.html">Bo Li</a>, <a href="/pubs/TaraSainath.html">Tara N.
                    Sainath</a>, <a href="/pubs/RonWeiss.html">Ron J. Weiss</a>, <a href=
                    "/pubs/KevinWilson.html">Kevin W. Wilson</a>, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>
                  </p>
                  <p>
                    Proc. Interspeech, ISCA (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Neural+Speech+Recognizer:+Acoustic-to-Word+LSTM+Model+for+Large+Vocabulary+Speech+Recognition+Soltau+Liao+Sak"
                  target="_blank">&nbsp;</a><a class="abstract-icon tooltip" href=
                  "/pubs/pub45675.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45675.html">Neural Speech Recognizer: Acoustic-to-Word LSTM
                    Model for Large Vocabulary Speech Recognition</a>
                  </p>
                  <p>
                    Hagen Soltau, <a href="/pubs/author37501.html">Hank Liao</a>, <a href=
                    "/pubs/HasimSak.html">Hasim Sak</a>
                  </p>
                  <p>
                    ArXiv e-prints (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=ON+PRE-FILTERING+STRATEGIES+FOR+THE+GCC-PHAT+ALGORITHM+Kang+Graczyk+Skoglund"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    ON PRE-FILTERING STRATEGIES FOR THE GCC-PHAT ALGORITHM
                  </p>
                  <p>
                    Hong-Goo Kang, Michael Graczyk, <a href="/pubs/JanSkoglund.html">Jan
                    Skoglund</a>
                  </p>
                  <p>
                    International Workshop on Acoustic Signal Enhancement 2016 (IWAENC 2016) (to
                    appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=On+The+Compression+Of+Recurrent+Neural+Networks+With+An+Application+To+LVCSR+Acoustic+Modeling+For+Embedded+Speech+Recognition+Prabhavalkar+Alsharif+Bruguier+McGraw"
                  target="_blank">&nbsp;</a><a class="abstract-icon tooltip" href=
                  "/pubs/pub44632.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44632.html">On The Compression Of Recurrent Neural Networks
                    With An Application To LVCSR Acoustic Modeling For Embedded Speech
                    Recognition</a>
                  </p>
                  <p>
                    <a href="/pubs/RohitPrabhavalkar.html">Rohit Prabhavalkar</a>, <a href=
                    "/pubs/OuaisAlsharif.html">Ouais Alsharif</a>, <a href=
                    "/pubs/105173.html">Antoine Bruguier</a>, Ian McGraw
                  </p>
                  <p>
                    Proceedings of International Conference on Acoustics, Speech and Signal
                    Processing (ICASSP), IEEE (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=On+the+Efficient+Representation+and+Execution+of+Deep+Acoustic+Models+Alvarez+Prabhavalkar+Bakhtin"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "https://arxiv.org/abs/1607.04683" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45607.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45607.html">On the Efficient Representation and Execution of
                    Deep Acoustic Models</a>
                  </p>
                  <p>
                    <a href="/pubs/RazielAlvarez.html">Raziel Alvarez</a>, <a href=
                    "/pubs/RohitPrabhavalkar.html">Rohit Prabhavalkar</a>, Anton Bakhtin
                  </p>
                  <p>
                    Proceedings of Annual Conference of the International Speech Communication
                    Association (Interspeech) (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Personalized+Speech+Recognition+On+Mobile+Devices+McGraw+Prabhavalkar+Alvarez+Arenas+Rao+Rybach+Alsharif+Sak+Gruenstein+Beaufays+Parada"
                  target="_blank">&nbsp;</a><a class="abstract-icon tooltip" href=
                  "/pubs/pub44631.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44631.html">Personalized Speech Recognition On Mobile
                    Devices</a>
                  </p>
                  <p>
                    Ian McGraw, <a href="/pubs/RohitPrabhavalkar.html">Rohit Prabhavalkar</a>,
                    <a href="/pubs/RazielAlvarez.html">Raziel Alvarez</a>, Montse Gonzalez Arenas,
                    <a href="/pubs/KanishkaRao.html">Kanishka Rao</a>, David Rybach, <a href=
                    "/pubs/OuaisAlsharif.html">Ouais Alsharif</a>, <a href=
                    "/pubs/HasimSak.html">Hasim Sak</a>, <a href="/pubs/author39407.html">Alexander
                    Gruenstein</a>, <a href="/pubs/author21120.html">Françoise Beaufays</a>,
                    <a href="/pubs/CarolinaParada.html">Carolina Parada</a>
                  </p>
                  <p>
                    Proceedings of International Conference on Acoustics, Speech and Signal
                    Processing (ICASSP), IEEE (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Pynini:+A+Python+library+for+weighted+finite-state+grammar+compilation+Gorman"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45559.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45559.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45559.html">Pynini: A Python library for weighted
                    finite-state grammar compilation</a>
                  </p>
                  <p>
                    <a href="/pubs/KyleGorman.html">Kyle Gorman</a>
                  </p>
                  <p>
                    Proceedings of the ACL Workshop on Statistical NLP and Weighted Automata
                    (2016), pp. 75-80
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Recent+Advances+in+Google+Real-time+HMM-driven+Unit+Selection+Synthesizer+Gonzalvo+Tazari+Chan+Becker+Gutkin+Silen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45564.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45564.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45564.html">Recent Advances in Google Real-time HMM-driven
                    Unit Selection Synthesizer</a>
                  </p>
                  <p>
                    <a href="/pubs/XaviGonzalvo.html">Xavi Gonzalvo</a>, Siamak Tazari, Chun-an
                    Chan, Markus Becker, <a href="/pubs/AlexanderGutkin.html">Alexander Gutkin</a>,
                    Hanna Silen
                  </p>
                  <p>
                    INTERSPEECH 2016, Sep 8-12, San Francisco, USA, pp. 2238-2242
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Reducing+the+Computational+Complexity+of+Multimicrophone+Acoustic+Models+with+Integrated+Feature+Extraction+Sainath+Narayanan+Weiss+Variani+Wilson+Bacchiani+Shafran"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45490.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Reducing the Computational Complexity of Multimicrophone Acoustic Models with
                    Integrated Feature Extraction
                  </p>
                  <p>
                    <a href="/pubs/TaraSainath.html">Tara N. Sainath</a>, <a href=
                    "/pubs/ArunNarayanan.html">Arun Narayanan</a>, <a href=
                    "/pubs/RonWeiss.html">Ron J. Weiss</a>, <a href="/pubs/EhsanVariani.html">Ehsan
                    Variani</a>, <a href="/pubs/KevinWilson.html">Kevin W. Wilson</a>, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>, <a href=
                    "/pubs/IzhakShafran.html">Izhak Shafran</a>
                  </p>
                  <p>
                    Proc. Interspeech, ISCA (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Robust+Estimation+of+Reverberation+Time+Using+Polynomial+Roots+Kelly+Boland+Skoglund"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43989.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43989.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43989.html">Robust Estimation of Reverberation Time Using
                    Polynomial Roots</a>
                  </p>
                  <p>
                    <a href="/pubs/IanKelly.html">Ian Kelly</a>, Francis Boland, <a href=
                    "/pubs/JanSkoglund.html">Jan Skoglund</a>
                  </p>
                  <p>
                    AES 60th Conference on Dereverberation and Reverberation of Audio, Music, and
                    Speech, Google Ireland Ltd. (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Selection+and+Combination+of+Hypotheses+for+Dialectal+Speech+Recognition+Soto+Siohan+Elfeky+Moreno"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45288.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45288.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45288.html">Selection and Combination of Hypotheses for
                    Dialectal Speech Recognition</a>
                  </p>
                  <p>
                    Victor Soto, <a href="/pubs/OlivierSiohan.html">Olivier Siohan</a>, <a href=
                    "/pubs/MohamedElfeky.html">Mohamed Elfeky</a>, <a href=
                    "/pubs/author5289.html">Pedro J. Moreno</a>
                  </p>
                  <p>
                    ICASSP 2016
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Semantic+Model+for+Fast+Tagging+of+Word+Lattices+Velikovich"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45613.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45613.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45613.html">Semantic Model for Fast Tagging of Word
                    Lattices</a>
                  </p>
                  <p>
                    <a href="/pubs/LeonidVelikovich.html">Leonid Velikovich</a>
                  </p>
                  <p>
                    IEEE Spoken Language Technology (SLT) Workshop (2016) (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=THE+MATCHING-MINIMIZATION+ALGORITHM,+THE+INCA+ALGORITHM+AND+A++MATHEMATICAL+FRAMEWORK+FOR+VOICE+CONVERSION+WITH+UNALIGNED++CORPORA.+Agiomyrgiannakis"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44862.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub44862.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44862.html">THE MATCHING-MINIMIZATION ALGORITHM, THE INCA
                    ALGORITHM AND A MATHEMATICAL FRAMEWORK FOR VOICE CONVERSION WITH UNALIGNED
                    CORPORA.</a>
                  </p>
                  <p>
                    <a href="/pubs/author57972.html">Yannis Agiomyrgiannakis</a>
                  </p>
                  <p>
                    ICASSP, IEEE (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=TTS+for+Low+Resource+Languages:+A+Bangla+Synthesizer+Gutkin+Ha+Jansche+Pipatsrisawat+Sproat"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45300.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45300.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45300.html">TTS for Low Resource Languages: A Bangla
                    Synthesizer</a>
                  </p>
                  <p>
                    <a href="/pubs/AlexanderGutkin.html">Alexander Gutkin</a>, Linne Ha, <a href=
                    "/pubs/author35845.html">Martin Jansche</a>, Knot Pipatsrisawat, <a href=
                    "/pubs/RichardSproat.html">Richard Sproat</a>
                  </p>
                  <p>
                    10th edition of the Language Resources and Evaluation Conference, 23-28 May
                    2016, Portorož (Slovenia), European Language Resources Association (ELRA),
                    Paris, France, pp. 2005-2010
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Towards+Acoustic+Model+Unification+Across+Dialects+Waters+Bastani+Elfeky+Moreno+Velez"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45879.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45879.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45879.html">Towards Acoustic Model Unification Across
                    Dialects</a>
                  </p>
                  <p>
                    Austin Waters, Meysam Bastani, <a href="/pubs/MohamedElfeky.html">Mohamed G.
                    Elfeky</a>, <a href="/pubs/author5289.html">Pedro Moreno</a>, Xavier Velez
                  </p>
                  <p>
                    2016 IEEE Workshop on Spoken Language Technology
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Unsupervised+Context+Learning+For+Speech+Recognition+Michaely+Scheiner+Ghodsi+Aleksic+Wu"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45759.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45759.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45759.html">Unsupervised Context Learning For Speech
                    Recognition</a>
                  </p>
                  <p>
                    <a href="/pubs/AssafHurwitzMichaely.html">Assaf Michaely</a>, Justin Scheiner,
                    Mohammadreza Ghodsi, Petar Aleksic, Zelin Wu
                  </p>
                  <p>
                    Spoken Language Technology (SLT) Workshop, IEEE (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Unsupervised+Word+Segmentation+and+Lexicon++Discovery+Using+Acoustic+Word+Embeddings+Jansen+Kamper+Goldwater"
                  target="_blank">&nbsp;</a><a class="abstract-icon tooltip" href=
                  "/pubs/pub45561.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45561.html">Unsupervised Word Segmentation and Lexicon
                    Discovery Using Acoustic Word Embeddings</a>
                  </p>
                  <p>
                    <a href="/pubs/104952.html">Aren Jansen</a>, Herman Kamper, Sharon Goldwater
                  </p>
                  <p>
                    IEEE Transactions on Audio, Speech, and Language Processing (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Using+instantaneous+frequency+and+aperiodicity+detection+to+estimate+FO+for+high-quality+speech+synthesis+Kawahara+Agiomyrgiannakis+Zen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45793.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45793.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45793.html">Using instantaneous frequency and aperiodicity
                    detection to estimate FO for high-quality speech synthesis</a>
                  </p>
                  <p>
                    Hideki Kawahara, <a href="/pubs/author57972.html">Yannis Agiomyrgiannakis</a>,
                    <a href="/pubs/HeigaZen.html">Heiga Zen</a>
                  </p>
                  <p>
                    Proc. ISCA SSW9 (2016), pp. 238-245
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=VOICE+MORPHING+THAT+IMPROVES+TTS+QUALITY+USING+AN+OPTIMAL+DYNAMIC++FREQUENCY+WARPING-AND-WEIGHTING+TRANSFORM+Agiomyrgiannakis+Roupakia"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44861.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub44861.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44861.html">VOICE MORPHING THAT IMPROVES TTS QUALITY USING AN
                    OPTIMAL DYNAMIC FREQUENCY WARPING-AND-WEIGHTING TRANSFORM</a>
                  </p>
                  <p>
                    <a href="/pubs/author57972.html">Yannis Agiomyrgiannakis</a>, Zoe Roupakia
                  </p>
                  <p>
                    ICASSP, IEEE (2016)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=A+6+%C2%B5W+per+Channel+Analog+Biomimetic+Cochlear+Implant+Processor+Filterbank+Architecture+With+Across+Channels+AGC+Wang+Lyon+Drakakis"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43280.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43280.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43280.html">A 6 µW per Channel Analog Biomimetic Cochlear
                    Implant Processor Filterbank Architecture With Across Channels AGC</a>
                  </p>
                  <p>
                    Guang Wang, <a href="/pubs/author35932.html">Richard F. Lyon</a>, Emmanuel M.
                    Drakakis
                  </p>
                  <p>
                    IEEE Transactions on Biomedical Circuits and Systems, vol. 9 (2015), pp. 72-86
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=A+Gaussian+Mixture+Model+Layer+Jointly+Optimized+with+Discriminative+Features+within+A+Deep+Neural+Network+Architecture+Variani+McDermott+Heigold"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43912.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43912.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43912.html">A Gaussian Mixture Model Layer Jointly Optimized
                    with Discriminative Features within A Deep Neural Network Architecture</a>
                  </p>
                  <p>
                    <a href="/pubs/EhsanVariani.html">Ehsan Variani</a>, <a href=
                    "/pubs/ErikMcDermott.html">Erik McDermott</a>, <a href=
                    "/pubs/GeorgHeigold.html">Georg Heigold</a>
                  </p>
                  <p>
                    ICASSP, IEEE (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Acoustic+Modeling+for+Speech+Synthesis:+from+HMM+to+RNN+Zen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44630.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub44630.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44630.html">Acoustic Modeling for Speech Synthesis: from HMM
                    to RNN</a>
                  </p>
                  <p>
                    <a href="/pubs/HeigaZen.html">Heiga Zen</a>
                  </p>
                  <p>
                    IEEE ASRU, Scottsdale, Arizona, U.S.A. (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Acoustic+Modeling+in+Statistical+Parametric+Speech+Synthesis+-+From+HMM+to+LSTM-RNN+Zen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43893.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43893.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43893.html">Acoustic Modeling in Statistical Parametric
                    Speech Synthesis - From HMM to LSTM-RNN</a>
                  </p>
                  <p>
                    <a href="/pubs/HeigaZen.html">Heiga Zen</a>
                  </p>
                  <p>
                    Proc. MLSLP (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Acoustic+Modelling+with+CD-CTC-SMBR+LSTM+RNNS+Senior+Sak+De+Quitry+Sainath+Rao"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44269.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub44269.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44269.html">Acoustic Modelling with CD-CTC-SMBR LSTM RNNS</a>
                  </p>
                  <p>
                    <a href="/pubs/author37792.html">Andrew Senior</a>, <a href=
                    "/pubs/HasimSak.html">Hasim Sak</a>, <a href=
                    "/pubs/FelixdeChaumontQuitry.html">Felix de Chaumont Quitry</a>, <a href=
                    "/pubs/TaraSainath.html">Tara N. Sainath</a>, <a href=
                    "/pubs/KanishkaRao.html">Kanishka Rao</a>
                  </p>
                  <p>
                    ASRU (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Automatic+Gain+Control+and+Multi-style+Training+for+Robust+Small-Footprint+Keyword+Spotting+with+Deep+Neural+Networks+Prabhavalkar+Alvarez+Parada+Nakkiran+Sainath"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43289.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43289.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43289.html">Automatic Gain Control and Multi-style Training
                    for Robust Small-Footprint Keyword Spotting with Deep Neural Networks</a>
                  </p>
                  <p>
                    <a href="/pubs/RohitPrabhavalkar.html">Rohit Prabhavalkar</a>, <a href=
                    "/pubs/RazielAlvarez.html">Raziel Alvarez</a>, <a href=
                    "/pubs/CarolinaParada.html">Carolina Parada</a>, Preetum Nakkiran, <a href=
                    "/pubs/TaraSainath.html">Tara Sainath</a>
                  </p>
                  <p>
                    Proceedings of International Conference on Acoustics, Speech and Signal
                    Processing (ICASSP), IEEE (2015), pp. 4704-4708
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Automatic+Pronunciation+Verification+for+Speech+Recognition+Rao+Peng+Beaufays"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43262.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Automatic Pronunciation Verification for Speech Recognition
                  </p>
                  <p>
                    <a href="/pubs/KanishkaRao.html">Kanishka Rao</a>, <a href=
                    "/pubs/FuchunPeng.html">Fuchun Peng</a>, <a href=
                    "/pubs/author21120.html">Françoise Beaufays</a>
                  </p>
                  <p>
                    ICASSP (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Bringing+Contextual+Information+to+Google+Speech+Recognition+Aleksic+Ghodsi+Michaely+Allauzen+Hall+Roark+Rybach+Moreno"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43819.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Bringing Contextual Information to Google Speech Recognition
                  </p>
                  <p>
                    Petar Aleksic, Mohammadreza Ghodsi, <a href=
                    "/pubs/AssafHurwitzMichaely.html">Assaf Michaely</a>, <a href=
                    "/pubs/author130.html">Cyril Allauzen</a>, <a href=
                    "/pubs/author38002.html">Keith Hall</a>, <a href="/pubs/BrianRoark.html">Brian
                    Roark</a>, David Rybach, <a href="/pubs/author5289.html">Pedro Moreno</a>
                  </p>
                  <p>
                    Interspeech 2015, International Speech Communications Association
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Composition-based+on-the-fly+rescoring+for+salient+n-gram+biasing+Hall+Cho+Allauzen+Beaufays+Coccaro+Nakajima+Riley+Roark+Rybach+Zhang"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43816.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Composition-based on-the-fly rescoring for salient n-gram biasing
                  </p>
                  <p>
                    <a href="/pubs/author38002.html">Keith Hall</a>, Eunjoon Cho, <a href=
                    "/pubs/author130.html">Cyril Allauzen</a>, <a href=
                    "/pubs/author21120.html">Francoise Beaufays</a>, Noah Coccaro, Kaisuke
                    Nakajima, <a href="/pubs/author125.html">Michael Riley</a>, <a href=
                    "/pubs/BrianRoark.html">Brian Roark</a>, David Rybach, Linda Zhang
                  </p>
                  <p>
                    Interspeech 2015, International Speech Communications Association
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Compressing+Deep+Neural+Networks+using+a+Rank-Constrained+Topology+Nakkiran+Alvarez+Prabhavalkar+Parada"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43813.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43813.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43813.html">Compressing Deep Neural Networks using a
                    Rank-Constrained Topology</a>
                  </p>
                  <p>
                    Preetum Nakkiran, <a href="/pubs/RazielAlvarez.html">Raziel Alvarez</a>,
                    <a href="/pubs/RohitPrabhavalkar.html">Rohit Prabhavalkar</a>, <a href=
                    "/pubs/CarolinaParada.html">Carolina Parada</a>
                  </p>
                  <p>
                    Proceedings of Annual Conference of the International Speech Communication
                    Association (Interspeech), ISCA (2015), pp. 1473-1477
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Context+dependent+phone+models+for+LSTM+RNN+acoustic+modelling+Senior+Sak+Shafran"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43910.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Context dependent phone models for LSTM RNN acoustic modelling
                  </p>
                  <p>
                    <a href="/pubs/author37792.html">Andrew W. Senior</a>, <a href=
                    "/pubs/HasimSak.html">Hasim Sak</a>, <a href="/pubs/IzhakShafran.html">Izhak
                    Shafran</a>
                  </p>
                  <p>
                    ICASSP (2015), pp. 4585-4589
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Convolutional+Neural+Networks+for+Small-Footprint+Keyword+Spotting+Sainath+Parada"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43969.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Convolutional Neural Networks for Small-Footprint Keyword Spotting
                  </p>
                  <p>
                    <a href="/pubs/TaraSainath.html">Tara Sainath</a>, <a href=
                    "/pubs/CarolinaParada.html">Carolina Parada</a>
                  </p>
                  <p>
                    Interspeech (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Convolutional,+Long+Short-Term+Memory,+Fully+Connected+Deep+Neural+Networks+Sainath+Vinyals+Senior+Sak"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43455.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Convolutional, Long Short-Term Memory, Fully Connected Deep Neural Networks
                  </p>
                  <p>
                    <a href="/pubs/TaraSainath.html">Tara Sainath</a>, <a href=
                    "/pubs/OriolVinyals.html">Oriol Vinyals</a>, <a href=
                    "/pubs/author37792.html">Andrew Senior</a>, <a href="/pubs/HasimSak.html">Hasim
                    Sak</a>
                  </p>
                  <p>
                    ICASSP (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=DETECTION+AND+SUPPRESSION+OF+KEYBOARD+TRANSIENT+NOISE+IN+AUDIO+STREAMS+WITH+AUXILIARY+KEYBED+MICROPHONE+Godsill+Buchner+Skoglund"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    DETECTION AND SUPPRESSION OF KEYBOARD TRANSIENT NOISE IN AUDIO STREAMS WITH
                    AUXILIARY KEYBED MICROPHONE
                  </p>
                  <p>
                    Simon Godsill, Herbert Buchner, <a href="/pubs/JanSkoglund.html">Jan
                    Skoglund</a>
                  </p>
                  <p>
                    ICASSP 2015, IEEE
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=DIRECT-TO-REVERBERANT+RATIO+ESTIMATION+USING+A+NULL-STEERED+BEAMFORMER+Eaton+Moore+Naylor+Skoglund"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    DIRECT-TO-REVERBERANT RATIO ESTIMATION USING A NULL-STEERED BEAMFORMER
                  </p>
                  <p>
                    James Eaton, Alastair Moore, Patrick Naylor, <a href=
                    "/pubs/JanSkoglund.html">Jan Skoglund</a>
                  </p>
                  <p>
                    ICASSP 2015, IEEE
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Deep+Learning+for+Acoustic+Modeling+in+Parametric+Speech+Generation:+A+systematic+review+of+existing+techniques+and+future+trends+Ling+Kang+Zen+Senior+Schuster+Qian+Meng+Deng"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "http://dx.doi.org/10.1109/MSP.2014.2359987" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43434.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43434.html">Deep Learning for Acoustic Modeling in Parametric
                    Speech Generation: A systematic review of existing techniques and future
                    trends</a>
                  </p>
                  <p>
                    Zhen-Hua Ling, Shiyin Kang, <a href="/pubs/HeigaZen.html">Heiga Zen</a>,
                    <a href="/pubs/author37792.html">Andrew Senior</a>, <a href=
                    "/pubs/MikeSchuster.html">Mike Schuster</a>, Xiao-Jun Qian, Helen Meng, Li Deng
                  </p>
                  <p>
                    IEEE Signal Processing Magazine, vol. 32 (2015), pp. 35-52
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Directly+Modeling+Speech+Waveforms+by+Neural+Networks+for+Statistical+Parametric+Speech+Synthesis+Tokuda+Zen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43267.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43267.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43267.html">Directly Modeling Speech Waveforms by Neural
                    Networks for Statistical Parametric Speech Synthesis</a>
                  </p>
                  <p>
                    Keiichi Tokuda, <a href="/pubs/HeigaZen.html">Heiga Zen</a>
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP), IEEE (2015), pp. 4215-4219
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Fast+and+Accurate+Recurrent+Neural+Network+Acoustic+Models+for+Speech+Recognition+Sak+Senior+Rao+Beaufays"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43894.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Fast and Accurate Recurrent Neural Network Acoustic Models for Speech
                    Recognition
                  </p>
                  <p>
                    <a href="/pubs/HasimSak.html">Hasim Sak</a>, <a href=
                    "/pubs/author37792.html">Andrew W. Senior</a>, <a href=
                    "/pubs/KanishkaRao.html">Kanishka Rao</a>, Françoise Beaufays
                  </p>
                  <p>
                    CoRR, vol. abs/1507.06947 (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Fix+It+Where+It+Fails:+Pronunciation+Learning+by+Mining+Error+Corrections+from+Speech+Logs+Kou+Stanton+Peng+Beaufays+Strohman"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43263.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Fix It Where It Fails: Pronunciation Learning by Mining Error Corrections from
                    Speech Logs
                  </p>
                  <p>
                    Zhenzhen Kou, <a href="/pubs/DaisyStanton.html">Daisy Stanton</a>, <a href=
                    "/pubs/FuchunPeng.html">Fuchun Peng</a>, <a href=
                    "/pubs/author21120.html">Françoise Beaufays</a>, <a href=
                    "/pubs/TrevorStrohman.html">Trevor Strohman</a>
                  </p>
                  <p>
                    ICASSP (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Garbage+Modeling+for+On-device+Speech+Recognition+Gysel+Velikovich+McGraw+Beaufays"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43847.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Garbage Modeling for On-device Speech Recognition
                  </p>
                  <p>
                    Christophe Van Gysel, <a href="/pubs/LeonidVelikovich.html">Leonid
                    Velikovich</a>, Ian McGraw, <a href="/pubs/author21120.html">Françoise
                    Beaufays</a>
                  </p>
                  <p>
                    Interspeech 2015, International Speech Communications Association (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Geo-location+for+Voice+Search+Language+Modeling+Chelba+Zhang+Hall"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43817.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Geo-location for Voice Search Language Modeling
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, Xuedong Zhang, <a href=
                    "/pubs/author38002.html">Keith Hall</a>
                  </p>
                  <p>
                    Interspeech 2015, International Speech Communications Association, pp.
                    1438-1442
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Grapheme-to-Phoneme+Conversion+Using+Long+Short-Term+Memory+Recurrent+Neural+Networks+Rao+Peng+Sak+Beaufays"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43264.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Grapheme-to-Phoneme Conversion Using Long Short-Term Memory Recurrent Neural
                    Networks
                  </p>
                  <p>
                    <a href="/pubs/KanishkaRao.html">Kanishka Rao</a>, <a href=
                    "/pubs/FuchunPeng.html">Fuchun Peng</a>, <a href="/pubs/HasimSak.html">Hasim
                    Sak</a>, <a href="/pubs/author21120.html">Françoise Beaufays</a>
                  </p>
                  <p>
                    ICASSP (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Improved+recognition+of+contact+names+in+voice+commands+Aleksic+Allauzen+Elson+Kracun+Casado+Moreno"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Improved recognition of contact names in voice commands
                  </p>
                  <p>
                    Petar Aleksic, <a href="/pubs/author130.html">Cyril Allauzen</a>, David Elson,
                    Aleks Kracun, Diego Melendo Casado, <a href="/pubs/author5289.html">Pedro J.
                    Moreno</a>
                  </p>
                  <p>
                    ICASSP 2015
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Language+Modeling+in+the+Era+of+Abundant+Data+Chelba"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43258.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43258.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43258.html">Language Modeling in the Era of Abundant Data</a>
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>
                  </p>
                  <p>
                    Stanford Information Theory Forum (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Large+Vocabulary+Automatic+Speech+Recognition+for+Children+Liao+Pundak+Siohan+Carroll+Coccaro+Jiang+Sainath+Senior+Beaufays+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44268.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub44268.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44268.html">Large Vocabulary Automatic Speech Recognition for
                    Children</a>
                  </p>
                  <p>
                    <a href="/pubs/author37501.html">Hank Liao</a>, <a href=
                    "/pubs/GolanPundak.html">Golan Pundak</a>, <a href=
                    "/pubs/OlivierSiohan.html">Olivier Siohan</a>, Melissa Carroll, Noah Coccaro,
                    Qi-Ming Jiang, <a href="/pubs/TaraSainath.html">Tara N. Sainath</a>, <a href=
                    "/pubs/author37792.html">Andrew Senior</a>, <a href=
                    "/pubs/author21120.html">Françoise Beaufays</a>, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>
                  </p>
                  <p>
                    Interspeech (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Large-scale,+sequence-discriminative,+joint+adaptive+training+for+masking-based+robust+ASR+Narayanan+Misra+Chin"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44019.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub44019.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44019.html">Large-scale, sequence-discriminative, joint
                    adaptive training for masking-based robust ASR</a>
                  </p>
                  <p>
                    <a href="/pubs/ArunNarayanan.html">Arun Narayanan</a>, <a href=
                    "/pubs/AnanyaMisra.html">Ananya Misra</a>, Kean Chin
                  </p>
                  <p>
                    INTERSPEECH-2015, ISCA, pp. 3571-3575
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Learning+acoustic+frame+labeling+for+speech+recognition+with+recurrent+neural+networks+Sak+Senior+Rao+Irsoy+Graves+Beaufays+Schalkwyk"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43908.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Learning acoustic frame labeling for speech recognition with recurrent neural
                    networks
                  </p>
                  <p>
                    <a href="/pubs/HasimSak.html">Hasim Sak</a>, <a href=
                    "/pubs/author37792.html">Andrew W. Senior</a>, <a href=
                    "/pubs/KanishkaRao.html">Kanishka Rao</a>, Ozan Irsoy, Alex Graves, Françoise
                    Beaufays, Johan Schalkwyk
                  </p>
                  <p>
                    ICASSP (2015), pp. 4280-4284
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Learning+the+Speech+Front-end+with+Raw+Waveform+CLDNNs+Sainath+Weiss+Wilson+Senior+Vinyals"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43960.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Learning the Speech Front-end with Raw Waveform CLDNNs
                  </p>
                  <p>
                    <a href="/pubs/TaraSainath.html">Tara Sainath</a>, <a href=
                    "/pubs/RonWeiss.html">Ron J. Weiss</a>, <a href="/pubs/KevinWilson.html">Kevin
                    Wilson</a>, <a href="/pubs/author37792.html">Andrew W. Senior</a>, <a href=
                    "/pubs/OriolVinyals.html">Oriol Vinyals</a>
                  </p>
                  <p>
                    Interspeech (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Locally-Connected+and+Convolutional+Neural+Networks+for+Small+Footprint+Speaker+Recognition+Chen+Moreno+Sainath+Visontai+Alvarez+Parada"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43970.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Locally-Connected and Convolutional Neural Networks for Small Footprint Speaker
                    Recognition
                  </p>
                  <p>
                    Yu-hsin Chen, <a href="/pubs/IgnacioLopezMoreno.html">Ignacio Lopez Moreno</a>,
                    <a href="/pubs/TaraSainath.html">Tara Sainath</a>, Mirkó Visontai, <a href=
                    "/pubs/RazielAlvarez.html">Raziel Alvarez</a>, <a href=
                    "/pubs/CarolinaParada.html">Carolina Parada</a>
                  </p>
                  <p>
                    Interspeech (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Long+Short-Term+Memory+Language+Models+with+Additive+Morphological+Features+for+Automatic+Speech+Recognition+Renshaw+Hall"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43335.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Long Short-Term Memory Language Models with Additive Morphological Features for
                    Automatic Speech Recognition
                  </p>
                  <p>
                    Daniel Renshaw, <a href="/pubs/author38002.html">Keith B. Hall</a>
                  </p>
                  <p>
                    IEEE International Conference on Acoustics, Speech, and Signal Processing
                    (ICASSP) (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Multi-Dialectical+Languages+Effect+on+Speech+Recognition+Elfeky+Moreno+Soto"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45289.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Multi-Dialectical Languages Effect on Speech Recognition
                  </p>
                  <p>
                    <a href="/pubs/MohamedElfeky.html">Mohamed Elfeky</a>, <a href=
                    "/pubs/author5289.html">Pedro J. Moreno</a>, Victor Soto
                  </p>
                  <p>
                    International Conference on Natural Language and Speech Processing (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Multitask+learning+and+system+combination+for+automatic+speech+recognition+Siohan+Rybach"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44633.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Multitask learning and system combination for automatic speech recognition
                  </p>
                  <p>
                    <a href="/pubs/OlivierSiohan.html">Olivier Siohan</a>, David Rybach
                  </p>
                  <p>
                    2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Pruning+Sparse+Non-negative+Matrix+N-gram+Language+Models+Pelemans+Shazeer+Chelba"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43830.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43830.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43830.html">Pruning Sparse Non-negative Matrix N-gram
                    Language Models</a>
                  </p>
                  <p>
                    Joris Pelemans, Noam M. Shazeer, <a href="/pubs/author6342.html">Ciprian
                    Chelba</a>
                  </p>
                  <p>
                    Proceedings of Interspeech 2015, ISCA, pp. 1433-1437
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Query-by-Example+Keyword+Spotting+Using+Long+Short-Term+Memory+Networks+Chen+Parada+Sainath"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "http://www.clsp.jhu.edu/~guoguo/papers/icassp2015_myhotword.pdf" target=
                  "_blank">&nbsp;</a>
                  <p class="pub-title">
                    Query-by-Example Keyword Spotting Using Long Short-Term Memory Networks
                  </p>
                  <p>
                    Guoguo Chen, <a href="/pubs/CarolinaParada.html">Carolina Parada</a>, <a href=
                    "/pubs/TaraSainath.html">Tara N. Sainath</a>
                  </p>
                  <p>
                    ICASSP (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Rapid+Vocabulary+Addition+to+Context-Dependent+Decoder+Graphs+Allauzen+Riley"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Rapid Vocabulary Addition to Context-Dependent Decoder Graphs
                  </p>
                  <p>
                    <a href="/pubs/author130.html">Cyril Allauzen</a>, <a href=
                    "/pubs/author125.html">Michael Riley</a>
                  </p>
                  <p>
                    Interspeech 2015
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Sequence-based+Class+Tagging+for+Robust+Transcription+in+ASR+Vasserman+Schogol+Hall"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43818.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Sequence-based Class Tagging for Robust Transcription in ASR
                  </p>
                  <p>
                    <a href="/pubs/LucyVasserman.html">Lucy Vasserman</a>, Vlad Schogol, <a href=
                    "/pubs/author38002.html">Keith Hall</a>
                  </p>
                  <p>
                    Interspeech 2015, International Speech Communications Association (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Sparse+Non-negative+Matrix+Language+Modeling+for+Geo-annotated+Query+Session+Data+Chelba+Shazeer"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43964.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43964.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43964.html">Sparse Non-negative Matrix Language Modeling for
                    Geo-annotated Query Session Data</a>
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, Noam M. Shazeer
                  </p>
                  <p>
                    Automatic Speech Recognition and Understanding Workshop (ASRU 2015)
                    Proceedings, IEEE, to appear (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Speaker+Location+and+Microphone+Spacing+Invariant+Acoustic+Modeling+from+Raw+Multichannel+Waveforms+Sainath+Weiss+Wilson+Narayanan+Bacchiani+Senior"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44270.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Speaker Location and Microphone Spacing Invariant Acoustic Modeling from Raw
                    Multichannel Waveforms
                  </p>
                  <p>
                    <a href="/pubs/TaraSainath.html">Tara N. Sainath</a>, <a href=
                    "/pubs/RonWeiss.html">Ron J. Weiss</a>, <a href="/pubs/KevinWilson.html">Kevin
                    Wilson</a>, <a href="/pubs/ArunNarayanan.html">Arun Narayanan</a>, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>, <a href=
                    "/pubs/author37792.html">Andrew Senior</a>
                  </p>
                  <p>
                    ASRU (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Speech+Acoustic+Modeling+from+Raw+Multichannel+Waveforms+Hoshen+Weiss+Wilson"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43290.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43290.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43290.html">Speech Acoustic Modeling from Raw Multichannel
                    Waveforms</a>
                  </p>
                  <p>
                    Yedid Hoshen, <a href="/pubs/RonWeiss.html">Ron Weiss</a>, <a href=
                    "/pubs/KevinWilson.html">Kevin W Wilson</a>
                  </p>
                  <p>
                    International Conference on Acoustics, Speech, and Signal Processing, IEEE
                    (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Statistical+parametric+speech+synthesis:+from+HMM+to+LSTM-RNN+Zen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/44312.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub44312.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44312.html">Statistical parametric speech synthesis: from HMM
                    to LSTM-RNN</a>
                  </p>
                  <p>
                    <a href="/pubs/HeigaZen.html">Heiga Zen</a>
                  </p>
                  <p>
                    RTTH Summer School on Speech Technology -- A Deep Learning Perspective,
                    Barcelona, Spain (2015)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Unidirectional+Long+Short-Term+Memory+Recurrent+Neural+Network+with+Recurrent+Output+Layer+for+Low-Latency+Speech+Synthesis+Zen+Sak"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43266.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43266.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43266.html">Unidirectional Long Short-Term Memory Recurrent
                    Neural Network with Recurrent Output Layer for Low-Latency Speech Synthesis</a>
                  </p>
                  <p>
                    <a href="/pubs/HeigaZen.html">Heiga Zen</a>, <a href=
                    "/pubs/HasimSak.html">Hasim Sak</a>
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP), IEEE (2015), pp. 4470-4474
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=ViSQOL:+an+objective+speech+quality+model+Hines+Skoglund+Kokaram+Harte"
                  target="_blank">&nbsp;</a><a class="abstract-icon tooltip" href=
                  "/pubs/pub43990.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43990.html">ViSQOL: an objective speech quality model</a>
                  </p>
                  <p>
                    Andrew Hines, <a href="/pubs/JanSkoglund.html">Jan Skoglund</a>, <a href=
                    "/pubs/AnilKokaram.html">Anil Kokaram</a>, Naomi Harte
                  </p>
                  <p>
                    EURASIP Journal on Audio, Speech, and Music Processing, vol. 2015 (13) (2015),
                    pp. 1-18
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Vocaine+the+Vocoder+and+Applications+in+Speech+Synthesis+Agiomyrgiannakis"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43336.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43336.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43336.html">Vocaine the Vocoder and Applications in Speech
                    Synthesis</a>
                  </p>
                  <p>
                    <a href="/pubs/author57972.html">Yannis Agiomyrgiannakis</a>
                  </p>
                  <p>
                    ICASSP, IEEE (2015) (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=A+big+data+approach+to+acoustic+model+training+corpus+selection+Kapralova+Alex+Weinstein+Moreno+Siohan"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43230.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43230.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43230.html">A big data approach to acoustic model training
                    corpus selection</a>
                  </p>
                  <p>
                    <a href="/pubs/OlgaKapralova.html">Olga Kapralova</a>, John Alex, Eugene
                    Weinstein, <a href="/pubs/author5289.html">Pedro Moreno</a>, <a href=
                    "/pubs/OlivierSiohan.html">Olivier Siohan</a>
                  </p>
                  <p>
                    Conference of the International Speech Communication Association (Interspeech)
                    (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=An+Analysis+of+the+Effect+of+Larynx-Synchronous+Averaging+on+Dereverberation+of+Voiced+Speech+Moore+Naylor+Skoglund"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    An Analysis of the Effect of Larynx-Synchronous Averaging on Dereverberation of
                    Voiced Speech
                  </p>
                  <p>
                    Alastair H Moore, Patrick A Naylor, <a href="/pubs/JanSkoglund.html">Jan
                    Skoglund</a>
                  </p>
                  <p>
                    Proceedings of European Signal Processing Conference (EUSIPCO) 2014
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Asynchronous+Stochastic+Optimization+for+Sequence+Training+of+Deep+Neural+Networks+Heigold+McDermott+Vanhoucke+Senior+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42248.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42248.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42248.html">Asynchronous Stochastic Optimization for Sequence
                    Training of Deep Neural Networks</a>
                  </p>
                  <p>
                    <a href="/pubs/GeorgHeigold.html">Georg Heigold</a>, <a href=
                    "/pubs/ErikMcDermott.html">Erik McDermott</a>, <a href=
                    "/pubs/VincentVanhoucke.html">Vincent Vanhoucke</a>, <a href=
                    "/pubs/author37792.html">Andrew Senior</a>, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP), IEEE, Firenze, Italy (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Asynchronous+Stochastic+Optimization+for+Sequence+Training+of+Deep+Neural+Networks:+Towards+Big+Data+McDermott+Heigold+Moreno+Senior+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42561.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Asynchronous Stochastic Optimization for Sequence Training of Deep Neural
                    Networks: Towards Big Data
                  </p>
                  <p>
                    <a href="/pubs/ErikMcDermott.html">Erik McDermott</a>, <a href=
                    "/pubs/GeorgHeigold.html">Georg Heigold</a>, <a href=
                    "/pubs/author5289.html">Pedro Moreno</a>, Andrew Senior, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>
                  </p>
                  <p>
                    Interspeeech, ISCA (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Asynchronous,+Online,+GMM-free+Training+of+a+Context+Dependent+Acoustic+Model+for+Speech+Recognition+Bacchiani+Senior+Heigold"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42653.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Asynchronous, Online, GMM-free Training of a Context Dependent Acoustic Model
                    for Speech Recognition
                  </p>
                  <p>
                    <a href="/pubs/MichielBacchiani.html">M. Bacchiani</a>, <a href=
                    "/pubs/author37792.html">A. Senior</a>, <a href="/pubs/GeorgHeigold.html">G.
                    Heigold</a>
                  </p>
                  <p>
                    Proceedings of the European Conference on Speech Communication and Technology
                    (2014) (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Automatic+Language+Identification+Using+Deep+Neural+Networks+Lopez-Moreno+Gonzalez-Dominguez+Plchot"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42538.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42538.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42538.html">Automatic Language Identification Using Deep
                    Neural Networks</a>
                  </p>
                  <p>
                    <a href="/pubs/IgnacioLopezMoreno.html">Ignacio Lopez-Moreno</a>, Javier
                    Gonzalez-Dominguez, Oldrich Plchot
                  </p>
                  <p>
                    Proc. ICASSP, IEEE (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Automatic+Language+Identification+using+Long+Short-Term+Memory+Recurrent+Neural+Networks+Gonzalez-Dominguez+Lopez-Moreno+Sak"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42540.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Automatic Language Identification using Long Short-Term Memory Recurrent Neural
                    Networks
                  </p>
                  <p>
                    Javier Gonzalez-Dominguez, <a href="/pubs/IgnacioLopezMoreno.html">Ignacio
                    Lopez-Moreno</a>, <a href="/pubs/HasimSak.html">Hasim Sak</a>
                  </p>
                  <p>
                    Interspeech (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Autoregressive+Product+of+Multi-frame+Predictions+Can+Improve+the+Accuracy+of+Hybrid+Models+Jaitly+Vanhoucke+Hinton"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42947.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42947.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42947.html">Autoregressive Product of Multi-frame Predictions
                    Can Improve the Accuracy of Hybrid Models</a>
                  </p>
                  <p>
                    <a href="/pubs/NavdeepJaitly.html">Navdeep Jaitly</a>, <a href=
                    "/pubs/VincentVanhoucke.html">Vincent Vanhoucke</a>, <a href=
                    "/pubs/GeoffreyHinton.html">Geoffrey Hinton</a>
                  </p>
                  <p>
                    Proceedings of Interspeech 2014
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Backoff+Inspired+Features+for+Maximum+Entropy+Language+Models+Biadsy+Hall+Moreno+Roark"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43114.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub43114.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub43114.html">Backoff Inspired Features for Maximum Entropy
                    Language Models</a>
                  </p>
                  <p>
                    <a href="/pubs/FadiBiadsy.html">Fadi Biadsy</a>, <a href=
                    "/pubs/author38002.html">Keith Hall</a>, <a href="/pubs/author5289.html">Pedro
                    Moreno</a>, <a href="/pubs/BrianRoark.html">Brian Roark</a>
                  </p>
                  <p>
                    Proceedings of Interspeech, ISCA (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Computer-aided+quality+assurance+of+an+Icelandic+pronunciation+dictionary+Jansche"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42502.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42502.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42502.html">Computer-aided quality assurance of an Icelandic
                    pronunciation dictionary</a>
                  </p>
                  <p>
                    <a href="/pubs/author35845.html">Martin Jansche</a>
                  </p>
                  <p>
                    LREC 2014, Reykjavik
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Context+Dependent+State+Tying+for+Speech+Recognition+using+Deep+Neural+Network+Acoustic+Models+Bacchiani+Rybach"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42652.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Context Dependent State Tying for Speech Recognition using Deep Neural Network
                    Acoustic Models
                  </p>
                  <p>
                    <a href="/pubs/MichielBacchiani.html">M. Bacchiani</a>, D. Rybach
                  </p>
                  <p>
                    Proceedings of the International Conference on Acoustics,Speech and Signal
                    Processing (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Deep+Mixture+Density+Networks+for+Acoustic+Modeling+in+Statistical+Parametric+Speech+Synthesis+Zen+Senior"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42020.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42020.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42020.html">Deep Mixture Density Networks for Acoustic
                    Modeling in Statistical Parametric Speech Synthesis</a>
                  </p>
                  <p>
                    <a href="/pubs/HeigaZen.html">Heiga Zen</a>, <a href=
                    "/pubs/author37792.html">Andrew Senior</a>
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP), IEEE (2014), pp. 3872-3876
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Deep+Neural+Networks+for+Small+Footprint+Text-dependent+Speaker+Verification+Variani+Lei+McDermott+Moreno+Gonzalez-Dominguez"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41939.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Deep Neural Networks for Small Footprint Text-dependent Speaker Verification
                  </p>
                  <p>
                    <a href="/pubs/EhsanVariani.html">Ehsan Variani</a>, Xin Lei, <a href=
                    "/pubs/ErikMcDermott.html">Erik McDermott</a>, <a href=
                    "/pubs/IgnacioLopezMoreno.html">Ignacio Lopez Moreno</a>, Javier
                    Gonzalez-Dominguez
                  </p>
                  <p>
                    Proc. ICASSP, IEEE (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Discriminative+pronunciation+modeling+for+dialectal+speech+recognition+Lehr+Gorman+Shafran"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42900.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42900.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42900.html">Discriminative pronunciation modeling for
                    dialectal speech recognition</a>
                  </p>
                  <p>
                    Maider Lehr, <a href="/pubs/KyleGorman.html">Kyle Gorman</a>, <a href=
                    "/pubs/IzhakShafran.html">Izhak Shafran</a>
                  </p>
                  <p>
                    Proc. Interspeech (2014) (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Encoding+Linear+Models+As+Weighted+Finite-State+Transducers+Wu+Allauzen+Hall+Riley+Roark"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43078.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Encoding Linear Models As Weighted Finite-State Transducers
                  </p>
                  <p>
                    Ke Wu, <a href="/pubs/author130.html">Cyril Allauzen</a>, <a href=
                    "/pubs/author38002.html">Keith Hall</a>, <a href="/pubs/author125.html">Michael
                    Riley</a>, <a href="/pubs/BrianRoark.html">Brian Roark</a>
                  </p>
                  <p>
                    Interspeech 2014, ISCA, pp. 1258-1262
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Fine+Context,+Low-rank,+Softplus+Deep+Neural+Networks+for+Mobile+Speech+Recognition+Senior+Lei"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42028.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Fine Context, Low-rank, Softplus Deep Neural Networks for Mobile Speech
                    Recognition
                  </p>
                  <p>
                    <a href="/pubs/author37792.html">Andrew Senior</a>, Xin Lei
                  </p>
                  <p>
                    Proc. ICASSP (2014) (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Frame+by+Frame+Language+Identification+in+Short+Utterances+using+Deep+Neural+Networks+Gonzalez-Dominguez+Lopez-Moreno+Moreno+Gonzalez-Rodriguez"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42929.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42929.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42929.html">Frame by Frame Language Identification in Short
                    Utterances using Deep Neural Networks</a>
                  </p>
                  <p>
                    Javier Gonzalez-Dominguez, <a href="/pubs/IgnacioLopezMoreno.html">Ignacio
                    Lopez-Moreno</a>, <a href="/pubs/author5289.html">Pedro J. Moreno</a>, Joaquin
                    Gonzalez-Rodriguez
                  </p>
                  <p>
                    Neural Networks Special Issue: Neural Network Learning in Big Data (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=GMM-Free+DNN+Training+Senior+Heigold+Bacchiani+Liao"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42651.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    GMM-Free DNN Training
                  </p>
                  <p>
                    <a href="/pubs/author37792.html">A. Senior</a>, <a href=
                    "/pubs/GeorgHeigold.html">G. Heigold</a>, <a href=
                    "/pubs/MichielBacchiani.html">M. Bacchiani</a>, <a href=
                    "/pubs/author37501.html">H. Liao</a>
                  </p>
                  <p>
                    Proceedings of the International Conference on Acoustics,Speech and Signal
                    Processing (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Improving+DNN+Speaker+Independence+with+I-vector+Inputs+Senior+Lopez-Moreno"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42536.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42536.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42536.html">Improving DNN Speaker Independence with I-vector
                    Inputs</a>
                  </p>
                  <p>
                    <a href="/pubs/author37792.html">Andrew Senior</a>, <a href=
                    "/pubs/IgnacioLopezMoreno.html">Ignacio Lopez-Moreno</a>
                  </p>
                  <p>
                    Proc. ICASSP, IEEE (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=JustSpeak:+Enabling+Universal+Voice+Control+on+Android+Zhong+Raman+Burkhardt+Biadsy+Bigham"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41924.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub41924.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub41924.html">JustSpeak: Enabling Universal Voice Control on
                    Android</a>
                  </p>
                  <p>
                    <a href="/pubs/YuZhong.html">Yu Zhong</a>, <a href="/pubs/author3559.html">T.
                    V. Raman</a>, <a href="/pubs/CaseyBurkhardt.html">Casey Burkhardt</a>, <a href=
                    "/pubs/FadiBiadsy.html">Fadi Biadsy</a>, Jeffrey P. Bigham
                  </p>
                  <p>
                    W4A 2014
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Large-Scale+Speaker+Identification+Schmidt+Sharifi+Lopez-Moreno"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42535.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42535.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42535.html">Large-Scale Speaker Identification</a>
                  </p>
                  <p>
                    Ludwig Schmidt, Matthew Sharifi, <a href=
                    "/pubs/IgnacioLopezMoreno.html">Ignacio Lopez-Moreno</a>
                  </p>
                  <p>
                    Proc. ICASSP, IEEE (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Long+Short-Term+Memory+Based+Recurrent+Neural+Network+Architectures+for+Large+Vocabulary+Speech+Recognition+Sak+Senior+Beaufays"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43895.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Long Short-Term Memory Based Recurrent Neural Network Architectures for Large
                    Vocabulary Speech Recognition
                  </p>
                  <p>
                    <a href="/pubs/HasimSak.html">Hasim Sak</a>, <a href=
                    "/pubs/author37792.html">Andrew W. Senior</a>, Françoise Beaufays
                  </p>
                  <p>
                    CoRR, vol. abs/1402.1128 (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Long+short-term+memory+recurrent+neural+network+architectures+for+large+scale+acoustic+modeling+Sak+Senior+Beaufays"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43905.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Long short-term memory recurrent neural network architectures for large scale
                    acoustic modeling
                  </p>
                  <p>
                    <a href="/pubs/HasimSak.html">Hasim Sak</a>, <a href=
                    "/pubs/author37792.html">Andrew W. Senior</a>, Françoise Beaufays
                  </p>
                  <p>
                    INTERSPEECH (2014), pp. 338-342
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Pronunciation+Learning+for+Named-Entities+through+Crowd-Sourcing+Rutherford+Peng+Beaufays"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43086.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Pronunciation Learning for Named-Entities through Crowd-Sourcing
                  </p>
                  <p>
                    Attapol Rutherford, <a href="/pubs/FuchunPeng.html">Fuchun Peng</a>, <a href=
                    "/pubs/author21120.html">Françoise Beaufays</a>
                  </p>
                  <p>
                    Proceedings of Interspeech (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Sequence+Discriminative+Distributed+Training+of+Long+Short-Term+Memory+Recurrent+Neural+Networks+Sak+Vinyals+Heigold+Senior+McDermott+Monga+Mao"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42547.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42547.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42547.html">Sequence Discriminative Distributed Training of
                    Long Short-Term Memory Recurrent Neural Networks</a>
                  </p>
                  <p>
                    <a href="/pubs/HasimSak.html">Hasim Sak</a>, <a href=
                    "/pubs/OriolVinyals.html">Oriol Vinyals</a>, <a href=
                    "/pubs/GeorgHeigold.html">Georg Heigold</a>, Andrew Senior, <a href=
                    "/pubs/ErikMcDermott.html">Erik McDermott</a>, <a href=
                    "/pubs/RajatMonga.html">Rajat Monga</a>, Mark Mao
                  </p>
                  <p>
                    Interspeech (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Sinusoidal+Interpolation+Across+Missing+Data+Kleijn+Shabestary+Skoglund"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Sinusoidal Interpolation Across Missing Data
                  </p>
                  <p>
                    W. Bastiaan Kleijn, Turaj Zakizadeh Shabestary, <a href=
                    "/pubs/JanSkoglund.html">Jan Skoglund</a>
                  </p>
                  <p>
                    International Workshop on Acoustic Signal Enhancement 2014 (IWAENC 2014), pp.
                    71-75
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Small-Footprint+Keyword+Spotting+using+Deep+Neural+Networks+Chen+Parada+Heigold"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42537.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Small-Footprint Keyword Spotting using Deep Neural Networks
                  </p>
                  <p>
                    Guoguo Chen, <a href="/pubs/CarolinaParada.html">Carolina Parada</a>, <a href=
                    "/pubs/GeorgHeigold.html">Georg Heigold</a>
                  </p>
                  <p>
                    ICASSP, IEEE (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Statistical+Parametric+Speech+Synthesis+Zen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42624.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42624.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42624.html">Statistical Parametric Speech Synthesis</a>
                  </p>
                  <p>
                    <a href="/pubs/HeigaZen.html">Heiga Zen</a>
                  </p>
                  <p>
                    UKSpeech Conference, Edinburgh, UK (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Text-To-Speech+with+cross-lingual+Neural+Network-based+grapheme-to-phoneme+models+Gonzalvo+Podsiadlo"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45183.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45183.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45183.html">Text-To-Speech with cross-lingual Neural
                    Network-based grapheme-to-phoneme models</a>
                  </p>
                  <p>
                    <a href="/pubs/XaviGonzalvo.html">Xavi Gonzalvo</a>, Monika Podsiadlo
                  </p>
                  <p>
                    Proceedings of Interspeech, ISCA (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Training+Data+Selection+Based+On+Context-Dependent+State+Matching+Siohan"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42037.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42037.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42037.html">Training Data Selection Based On
                    Context-Dependent State Matching</a>
                  </p>
                  <p>
                    <a href="/pubs/OlivierSiohan.html">Olivier Siohan</a>
                  </p>
                  <p>
                    Proceedings of ICASSP 2014
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Word+Embeddings+for+Speech+Recognition+Bengio+Heigold"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42543.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub42543.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub42543.html">Word Embeddings for Speech Recognition</a>
                  </p>
                  <p>
                    <a href="/pubs/bengio.html">Samy Bengio</a>, <a href=
                    "/pubs/GeorgHeigold.html">Georg Heigold</a>
                  </p>
                  <p>
                    Proceedings of the 15th Conference of the International Speech Communication
                    Association, Interspeech (2014)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=A+FREQUENCY-WEIGHTED+POST-FILTERING+TRANSFORM+FOR+COMPENSATION+OF++THE+OVER-SMOOTHING+EFFECT+IN+HMM-BASED+SPEECH+SYNTHESIS+Agiomyrgiannakis+Eyben"
                  target="_blank">&nbsp;</a><a class="abstract-icon tooltip" href=
                  "/pubs/pub44863.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub44863.html">A FREQUENCY-WEIGHTED POST-FILTERING TRANSFORM FOR
                    COMPENSATION OF THE OVER-SMOOTHING EFFECT IN HMM-BASED SPEECH SYNTHESIS</a>
                  </p>
                  <p>
                    <a href="/pubs/author57972.html">Yannis Agiomyrgiannakis</a>, Florian Eyben
                  </p>
                  <p>
                    ICASSP, IEEE (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Accurate+and+Compact+Large+Vocabulary+Speech+Recognition+on+Mobile+Devices+Lei+Senior+Gruenstein+Sorensen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41176.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Accurate and Compact Large Vocabulary Speech Recognition on Mobile Devices
                  </p>
                  <p>
                    Xin Lei, <a href="/pubs/author37792.html">Andrew Senior</a>, <a href=
                    "/pubs/author39407.html">Alexander Gruenstein</a>, <a href=
                    "/pubs/author14753.html">Jeffrey Sorensen</a>
                  </p>
                  <p>
                    Interspeech (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=An+Empirical+study+of+learning+rates+in+deep+neural+networks+for+speech+recognition+Senior+Heigold+Ranzato+Yang"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40808.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    An Empirical study of learning rates in deep neural networks for speech
                    recognition
                  </p>
                  <p>
                    <a href="/pubs/author37792.html">Andrew Senior</a>, <a href=
                    "/pubs/GeorgHeigold.html">Georg Heigold</a>, Marc'aurelio Ranzato, <a href=
                    "/pubs/author61.html">Ke Yang</a>
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP), IEEE, Vancouver, CA (2013) (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Deep+Learning+in+Speech+Synthesis+Zen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41539.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub41539.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub41539.html">Deep Learning in Speech Synthesis</a>
                  </p>
                  <p>
                    <a href="/pubs/HeigaZen.html">Heiga Zen</a>
                  </p>
                  <p>
                    8th ISCA Speech Synthesis Workshop, Barcelona, Spain (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Deep+Neural+Networks+with+Auxiliary+Gaussian+Mixture+Models+for+Real-Time+Speech+Recognition+Lei+Lin+Heigold"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Deep Neural Networks with Auxiliary Gaussian Mixture Models for Real-Time
                    Speech Recognition
                  </p>
                  <p>
                    Xin Lei, <a href="/pubs/HuiLin.html">Hui Lin</a>, <a href=
                    "/pubs/GeorgHeigold.html">Georg Heigold</a>
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP), IEEE, Vancouver, CA (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Direct+construction+of+compact+context-dependency+transducers+from+data+Rybach+Riley+Alberti"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "http://dx.doi.org/10.1016/j.csl.2013.04.006" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub41450.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub41450.html">Direct construction of compact context-dependency
                    transducers from data</a>
                  </p>
                  <p>
                    David Rybach, <a href="/pubs/author125.html">Michael Riley</a>, <a href=
                    "/pubs/ChrisAlberti.html">Chris Alberti</a>
                  </p>
                  <p>
                    Computer Speech &amp; Language (2013) (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Empirical+Exploration+of+Language+Modeling+for+the+google.com+Query+Stream+as+Applied+to+Mobile+Voice+Search+Chelba+Schalkwyk"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "http://www.springer.com/engineering/signals/book/978-1-4614-6017-6" target=
                  "_blank">&nbsp;</a><a class="abstract-icon tooltip" href=
                  "/pubs/pub41096.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub41096.html">Empirical Exploration of Language Modeling for
                    the google.com Query Stream as Applied to Mobile Voice Search</a>
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, Johan Schalkwyk
                  </p>
                  <p>
                    Mobile Speech and Advanced Natural Language Solutions, Springer
                    Science+Business Media, New York (2013), pp. 197-229
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Language+Model+Verbalization+for+Automatic+Speech+Recognition+Sak+Beaufays+Nakajima+Allauzen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41158.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Language Model Verbalization for Automatic Speech Recognition
                  </p>
                  <p>
                    <a href="/pubs/HasimSak.html">Hasim Sak</a>, <a href=
                    "/pubs/author21120.html">Françoise Beaufays</a>, Kaisuke Nakajima, <a href=
                    "/pubs/author130.html">Cyril Allauzen</a>
                  </p>
                  <p>
                    Proc ICASSP, IEEE (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Language+Modeling+Capitalization+Beaufays+Strope"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41157.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Language Modeling Capitalization
                  </p>
                  <p>
                    <a href="/pubs/author21120.html">Françoise Beaufays</a>, Brian Strope
                  </p>
                  <p>
                    Proc ICASSP, IEEE (2013) (to appear)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Large+Scale+Distributed+Acoustic+Modeling+With+Back-off+N-grams+Chelba+Xu+Pereira+Richardson"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40694.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub40694.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub40694.html">Large Scale Distributed Acoustic Modeling With
                    Back-off N-grams</a>
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, <a href=
                    "/pubs/PengXu.html">Peng Xu</a>, <a href="/pubs/author1092.html">Fernando
                    Pereira</a>, Thomas Richardson
                  </p>
                  <p>
                    IEEE Transactions on Audio, Speech and Language Processing, vol. 21 (2013), pp.
                    1158-1169
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Large+Scale+Distributed+Acoustic+Modeling+With+Back-off+N-grams+Chelba+Xu+Pereira+Richardson"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41133.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub41133.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub41133.html">Large Scale Distributed Acoustic Modeling With
                    Back-off N-grams</a>
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, <a href=
                    "/pubs/PengXu.html">Peng Xu</a>, <a href="/pubs/author1092.html">Fernando
                    Pereira</a>, Thomas Richardson
                  </p>
                  <p>
                    ICSI, Berkeley, California (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Large+scale+deep+neural+network+acoustic+modeling+with+semi-supervised+training+data+for++YouTube+video+transcription+Liao+McDermott+Senior"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41403.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Large scale deep neural network acoustic modeling with semi-supervised training
                    data for YouTube video transcription
                  </p>
                  <p>
                    <a href="/pubs/author37501.html">Hank Liao</a>, <a href=
                    "/pubs/ErikMcDermott.html">Erik McDermott</a>, <a href=
                    "/pubs/author37792.html">Andrew Senior</a>
                  </p>
                  <p>
                    ASRU (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Mixture+of+mixture+n-gram+language+models+Sak+Allauzen+Nakajima+Beaufays"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43902.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Mixture of mixture n-gram language models
                  </p>
                  <p>
                    <a href="/pubs/HasimSak.html">Hasim Sak</a>, <a href=
                    "/pubs/author130.html">Cyril Allauzen</a>, Kaisuke Nakajima, Françoise Beaufays
                  </p>
                  <p>
                    ASRU (2013), pp. 31-36
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Monitoring+the+Effects+of+Temporal+Clipping+on+VoIP+Speech+Quality+Hines+Skoglund+Kokaram+Harte"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Monitoring the Effects of Temporal Clipping on VoIP Speech Quality
                  </p>
                  <p>
                    Andrew Hines, <a href="/pubs/JanSkoglund.html">Jan Skoglund</a>, <a href=
                    "/pubs/AnilKokaram.html">Anil Kokaram</a>, Naomi Harte
                  </p>
                  <p>
                    Interspeech 2013, pp. 1188-1192
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Multiframe+Deep+Neural+Networks+for+Acoustic+Modeling+Vanhoucke+Devin+Heigold"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40810.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Multiframe Deep Neural Networks for Acoustic Modeling
                  </p>
                  <p>
                    <a href="/pubs/VincentVanhoucke.html">Vincent Vanhoucke</a>, <a href=
                    "/pubs/104860.html">Matthieu Devin</a>, <a href="/pubs/GeorgHeigold.html">Georg
                    Heigold</a>
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP), IEEE, Vancouver, CA (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Multilingual+acoustic+models+using+distributed+deep+neural+networks+Heigold+Vanhoucke+Senior+Nguyen+Ranzato+Devin+Dean"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40807.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Multilingual acoustic models using distributed deep neural networks
                  </p>
                  <p>
                    <a href="/pubs/GeorgHeigold.html">Georg Heigold</a>, <a href=
                    "/pubs/VincentVanhoucke.html">Vincent Vanhoucke</a>, <a href=
                    "/pubs/author37792.html">Andrew Senior</a>, Patrick Nguyen, Marc'aurelio
                    Ranzato, <a href="/pubs/104860.html">Matthieu Devin</a>, <a href=
                    "/pubs/jeff.html">Jeff Dean</a>
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP), IEEE, Vancouver, CA (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=On+Rectified+Linear+Units+For+Speech+Processing+Zeiler+Ranzato+Monga+Mao+Yang+Le+Nguyen+Senior+Vanhoucke+Dean+Hinton"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40811.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub40811.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub40811.html">On Rectified Linear Units For Speech
                    Processing</a>
                  </p>
                  <p>
                    M.D. Zeiler, M. Ranzato, <a href="/pubs/RajatMonga.html">R. Monga</a>, M. Mao,
                    <a href="/pubs/author61.html">K. Yang</a>, <a href="/pubs/QuocLe.html">Q.V.
                    Le</a>, P. Nguyen, <a href="/pubs/author37792.html">A. Senior</a>, <a href=
                    "/pubs/VincentVanhoucke.html">V. Vanhoucke</a>, <a href="/pubs/jeff.html">J.
                    Dean</a>, <a href="/pubs/GeoffreyHinton.html">G.E. Hinton</a>
                  </p>
                  <p>
                    38th International Conference on Acoustics, Speech and Signal Processing
                    (ICASSP), Vancouver (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Pre-Initialized+Composition+for+Large-Vocabulary+Speech+Recognition+Allauzen+Riley"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41410.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Pre-Initialized Composition for Large-Vocabulary Speech Recognition
                  </p>
                  <p>
                    <a href="/pubs/author130.html">Cyril Allauzen</a>, <a href=
                    "/pubs/author125.html">Michael Riley</a>
                  </p>
                  <p>
                    Interspeech 2013, 666 – 670
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=RAPID+ADAPTATION+FOR+MOBILE+SPEECH+APPLICATIONS+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42650.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    RAPID ADAPTATION FOR MOBILE SPEECH APPLICATIONS
                  </p>
                  <p>
                    <a href="/pubs/MichielBacchiani.html">M. Bacchiani</a>
                  </p>
                  <p>
                    Proceedings of the International Conference on Acoustics,Speech and Signal
                    Processing (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Rate-Distortion+Optimization+for+Multichannel+Audio+Compression+Li+Skoglund+Kleijn"
                  target="_blank">&nbsp;</a><a class="abstract-icon tooltip" href=
                  "/pubs/pub41648.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub41648.html">Rate-Distortion Optimization for Multichannel
                    Audio Compression</a>
                  </p>
                  <p>
                    Minyue Li, <a href="/pubs/JanSkoglund.html">Jan Skoglund</a>, W. Bastiaan
                    Kleijn
                  </p>
                  <p>
                    2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics
                    (WASPAA)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Recurrent+Neural+Networks+for+Voice+Activity+Detection+Hughes+Mierle"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41186.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub41186.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub41186.html">Recurrent Neural Networks for Voice Activity
                    Detection</a>
                  </p>
                  <p>
                    <a href="/pubs/author37811.html">Thad Hughes</a>, Keir Mierle
                  </p>
                  <p>
                    ICASSP, IEEE (2013), pp. 7378-7382
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Robustness+of+Speech+Quality+Metrics+to+Background+Noise+and+Network+Degradations:+Comparing+VISQOL,+PESQ+and+POLQA+Hines+Skoglund+Kokaram+Harte"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41218.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Robustness of Speech Quality Metrics to Background Noise and Network
                    Degradations: Comparing VISQOL, PESQ and POLQA
                  </p>
                  <p>
                    Andrew Hines, <a href="/pubs/JanSkoglund.html">Jan Skoglund</a>, <a href=
                    "/pubs/AnilKokaram.html">Anil Kokaram</a>, Naomi Harte
                  </p>
                  <p>
                    IEEE International Conference on Acoustics, Speech, and Signal Processing
                    (ICASSP), IEEE (2013), pp. 3697-3701
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Search+Results+Based+N-Best+Hypothesis+Rescoring+With+Maximum+Entropy+Classification+Peng+Roy+Shahshahani+Beaufays"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/43151.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Search Results Based N-Best Hypothesis Rescoring With Maximum Entropy
                    Classification
                  </p>
                  <p>
                    <a href="/pubs/FuchunPeng.html">Fuchun Peng</a>, Scott Roy, Ben Shahshahani,
                    <a href="/pubs/author21120.html">Françoise Beaufays</a>
                  </p>
                  <p>
                    Proceedings of ASRU (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Smoothed+marginal+distribution+constraints+for+language+modeling+Roark+Allauzen+Riley"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41345.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub41345.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub41345.html">Smoothed marginal distribution constraints for
                    language modeling</a>
                  </p>
                  <p>
                    <a href="/pubs/BrianRoark.html">Brian Roark</a>, <a href=
                    "/pubs/author130.html">Cyril Allauzen</a>, <a href=
                    "/pubs/author125.html">Michael Riley</a>
                  </p>
                  <p>
                    Proceedings of the 51st Annual Meeting of the Association for Computational
                    Linguistics (ACL) (2013), pp. 43-52
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Speaker+Adaptation+of+Context+Dependent+Deep+Neural+Networks+Liao"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40836.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Speaker Adaptation of Context Dependent Deep Neural Networks
                  </p>
                  <p>
                    <a href="/pubs/author37501.html">Hank Liao</a>
                  </p>
                  <p>
                    International Conference of Acoustics, Speech, and Signal Processing. (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Speech+and+Natural+Language:+Where+Are+We+Now+And+Where+Are+We+Headed?+Chelba"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41117.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub41117.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub41117.html">Speech and Natural Language: Where Are We Now And
                    Where Are We Headed?</a>
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>
                  </p>
                  <p>
                    Mobile Voice Conference, San Francisco (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Statistical+Parametric+Speech+Synthesis+Using+Deep+Neural+Networks+Zen+Senior+Schuster"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40837.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub40837.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub40837.html">Statistical Parametric Speech Synthesis Using
                    Deep Neural Networks</a>
                  </p>
                  <p>
                    <a href="/pubs/HeigaZen.html">Heiga Zen</a>, <a href=
                    "/pubs/author37792.html">Andrew Senior</a>, <a href=
                    "/pubs/MikeSchuster.html">Mike Schuster</a>
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP), IEEE (2013), pp. 7962-7966
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Written-Domain+Language+Modeling+for+Automatic+Speech+Recognition+Sak+Sung+Beaufays+Allauzen"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41226.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Written-Domain Language Modeling for Automatic Speech Recognition
                  </p>
                  <p>
                    <a href="/pubs/HasimSak.html">Hasim Sak</a>, Yun-hsuan Sung, <a href=
                    "/pubs/author21120.html">Françoise Beaufays</a>, <a href=
                    "/pubs/author130.html">Cyril Allauzen</a>
                  </p>
                  <p>
                    Interspeech (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=iVector-based+Acoustic+Data++Selection+Siohan+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/41528.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    iVector-based Acoustic Data Selection
                  </p>
                  <p>
                    <a href="/pubs/OlivierSiohan.html">Olivier Siohan</a>, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>
                  </p>
                  <p>
                    Proceedings of Interspeech (2013)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Application+Of+Pretrained+Deep+Neural+Networks+To+Large+Vocabulary+Speech+Recognition+Jaitly+Nguyen+Senior+Vanhoucke"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/38130.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub38130.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub38130.html">Application Of Pretrained Deep Neural Networks To
                    Large Vocabulary Speech Recognition</a>
                  </p>
                  <p>
                    <a href="/pubs/NavdeepJaitly.html">Navdeep Jaitly</a>, Patrick Nguyen, <a href=
                    "/pubs/author37792.html">Andrew Senior</a>, <a href=
                    "/pubs/VincentVanhoucke.html">Vincent Vanhoucke</a>
                  </p>
                  <p>
                    Proceedings of Interspeech 2012
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Buildling+adaptive+dialogue+systems+via+Bayes-adaptive+POMDP+Png+Pineau+Chaib-draa"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40680.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub40680.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub40680.html">Buildling adaptive dialogue systems via
                    Bayes-adaptive POMDP</a>
                  </p>
                  <p>
                    <a href="/pubs/ShaoweiPng.html">Shaowei Png</a>, Joelle Pineau, B. Chaib-draa
                  </p>
                  <p>
                    IEEE Journal of Selected Topics in Signal Processing, vol. vol.6(8). 2012.
                    (2012), pp. 917-927
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Chapter+17:+Uncertainty+Decoding,+In+Virtanen,+Singh,+%26+Raj+(Eds.)+Techniques+for+Noise+Robustness+in+Automatic+Speech+Recognition.+Liao"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Chapter 17: Uncertainty Decoding, In Virtanen, Singh, &amp; Raj (Eds.)
                    Techniques for Noise Robustness in Automatic Speech Recognition.
                  </p>
                  <p>
                    <a href="/pubs/author37501.html">Hank Liao</a>
                  </p>
                  <p>
                    Wiley (2012), pp. 463-485
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Continuous+Space+Discriminative+Language+Modeling+Xu+Khudanpur+Lehr+Prud%E2%80%99hommeaux+Glenn+Karakos+Roark+Sagae+Saraclar+Shafran+Bikel+Callison-Burch+Cao+Hall+Hasler+Koehn+Lopez+Post+Riley"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40425.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Continuous Space Discriminative Language Modeling
                  </p>
                  <p>
                    Puyang Xu, Sanjeev Khudanpur, Maider Lehr, Emily Prud’hommeaux, Nathan Glenn,
                    Damianos Karakos, <a href="/pubs/BrianRoark.html">Brian Roark</a>, Kenji Sagae,
                    Murat Saraclar, <a href="/pubs/IzhakShafran.html">Izhak Shafran</a>, Dan Bikel,
                    Chris Callison-Burch, Yuan Cao, <a href="/pubs/author38002.html">Keith
                    Hall</a>, Eva Hasler, Philipp Koehn, Adam Lopez, Matt Post, Darcey Riley
                  </p>
                  <p>
                    ICASSP 2012
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Deep+Neural+Networks+for+Acoustic+Modeling+in+Speech+Recognition+Hinton+Deng+Yu+Dahl+Mohamed+Jaitly+Senior+Vanhoucke+Nguyen+Sainath+Kingsbury"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/38131.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub38131.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub38131.html">Deep Neural Networks for Acoustic Modeling in
                    Speech Recognition</a>
                  </p>
                  <p>
                    <a href="/pubs/GeoffreyHinton.html">Geoffrey Hinton</a>, Li Deng, Dong Yu,
                    George Dahl, Abdel-rahman Mohamed, <a href="/pubs/NavdeepJaitly.html">Navdeep
                    Jaitly</a>, <a href="/pubs/author37792.html">Andrew Senior</a>, <a href=
                    "/pubs/VincentVanhoucke.html">Vincent Vanhoucke</a>, Patrick Nguyen, <a href=
                    "/pubs/TaraSainath.html">Tara Sainath</a>, Brian Kingsbury
                  </p>
                  <p>
                    Signal Processing Magazine (2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Distributed+Acoustic+Modeling+with+Back-off+N-grams+Chelba+Xu+Pereira+Richardson"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37681.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub37681.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub37681.html">Distributed Acoustic Modeling with Back-off
                    N-grams</a>
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, <a href=
                    "/pubs/PengXu.html">Peng Xu</a>, <a href="/pubs/author1092.html">Fernando
                    Pereira</a>, Thomas Richardson
                  </p>
                  <p>
                    Proceedings of ICASSP 2012, IEEE, pp. 4129-4132
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Distributed+Discriminative+Language+Models+for+Google+Voice+Search+Jyothi+Johnson+Chelba+Strope"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37682.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub37682.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub37682.html">Distributed Discriminative Language Models for
                    Google Voice Search</a>
                  </p>
                  <p>
                    Preethi Jyothi, Leif Johnson, <a href="/pubs/author6342.html">Ciprian
                    Chelba</a>, Brian Strope
                  </p>
                  <p>
                    Proceedings of ICASSP 2012, IEEE, pp. 5017-5021
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Estimating+Word-Stability+During+Incremental+Speech+Recognition+McGraw+Gruenstein"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40463.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Estimating Word-Stability During Incremental Speech Recognition
                  </p>
                  <p>
                    Ian McGraw, <a href="/pubs/author39407.html">Alexander Gruenstein</a>
                  </p>
                  <p>
                    Interspeech (2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Exemplar-Based+Processing+for+Speech+Recognition:+An+Overview+Sainath+Ramabhadran+Nahamoo+Kanevsky+Compernolle+Demuynck+Gemmeke+Bellegarda+Sundaram"
                  target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Exemplar-Based Processing for Speech Recognition: An Overview
                  </p>
                  <p>
                    <a href="/pubs/TaraSainath.html">Tara N. Sainath</a>, Bhuvana Ramabhadran,
                    David Nahamoo, Dimitri Kanevsky, Dirk Van Compernolle, Kris Demuynck, <a href=
                    "/pubs/JortGemmeke.html">Jort F. Gemmeke</a>, Jerome R. Bellegarda, Shiva
                    Sundaram
                  </p>
                  <p>
                    IEEE Signal Process. Mag., vol. 29 (2012), pp. 98-113
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Google's+Cross-Dialect+Arabic+Voice+Search+Biadsy+Moreno+Jansche"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/38079.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub38079.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub38079.html">Google's Cross-Dialect Arabic Voice Search</a>
                  </p>
                  <p>
                    <a href="/pubs/FadiBiadsy.html">Fadi Biadsy</a>, <a href=
                    "/pubs/author5289.html">Pedro J. Moreno</a>, <a href=
                    "/pubs/author35845.html">Martin Jansche</a>
                  </p>
                  <p>
                    IEEE International Conference on Acoustics, Speech, and Signal Processing
                    (ICASSP 2012), pp. 4441-4444
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Hallucinated+N-Best+Lists+for+Discriminative+Language+Modeling+Sagae+Lehr+Prud%E2%80%99hommeaux+Xu+Glenn+Karakos+Khudanpur+Roark+Sara%C3%A7lar+Shafran+Bikel+Callison-Burch+Cao+Hall+Hassler+Koehn+Lopez+Post+Riley"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/38112.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Hallucinated N-Best Lists for Discriminative Language Modeling
                  </p>
                  <p>
                    Kenji Sagae, Maider Lehr, Emily Tucker Prud’hommeaux, Puyang Xu, Nathan Glenn,
                    Damianos Karakos, Sanjeev Khudanpur, <a href="/pubs/BrianRoark.html">Brian
                    Roark</a>, Murat Saraçlar, <a href="/pubs/IzhakShafran.html">Izhak Shafran</a>,
                    Daniel M. Bikel, Chris Callison-Burch, Yuan Cao, <a href=
                    "/pubs/author38002.html">Keith Hall</a>, Eva Hassler, Philipp Koehn, Adam
                    Lopez, Matt Post, Darcey Riley
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP) (2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Haptic+Voice+Recognition+Grand+Challenge+Sim+Zhao+Yu+Liao"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40604.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Haptic Voice Recognition Grand Challenge
                  </p>
                  <p>
                    K. Sim, S. Zhao, K. Yu, <a href="/pubs/author37501.html">H. Liao</a>
                  </p>
                  <p>
                    14th ACM International Conference on Multimodal Interaction. (2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=IMPROVED+PREDICTION+OF+NEARLY-PERIODIC+SIGNALS+Kleijn+Skoglund"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/39978.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    IMPROVED PREDICTION OF NEARLY-PERIODIC SIGNALS
                  </p>
                  <p>
                    Bastiaan Kleijn, <a href="/pubs/JanSkoglund.html">Jan Skoglund</a>
                  </p>
                  <p>
                    International Workshop on Acoustic Signal Enhancement 2012 (IWAENC2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Investigations+on+Exemplar-Based+Features+for+Speech+Recognition+Towards+Thousands+of+Hours+of+Unsupervised,+Noisy+Data+Heigold+Nguyen+Weintraub+Vanhoucke"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37825.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub37825.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub37825.html">Investigations on Exemplar-Based Features for
                    Speech Recognition Towards Thousands of Hours of Unsupervised, Noisy Data</a>
                  </p>
                  <p>
                    <a href="/pubs/GeorgHeigold.html">Georg Heigold</a>, Patrick Nguyen, Mitchel
                    Weintraub, <a href="/pubs/VincentVanhoucke.html">Vincent Vanhoucke</a>
                  </p>
                  <p>
                    Proceedings of the IEEE International Conference on Acoustics, Speech, and
                    Signal Processing (ICASSP), IEEE, Kyoto, Japan (2012), pp. 4437-4440
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Japanese+and+Korean+Voice+Search+Schuster+Nakajima"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37842.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Japanese and Korean Voice Search
                  </p>
                  <p>
                    <a href="/pubs/MikeSchuster.html">Mike Schuster</a>, Kaisuke Nakajima
                  </p>
                  <p>
                    International Conference on Acoustics, Speech and Signal Processing, IEEE
                    (2012), pp. 5149-5152
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Language+Modeling+for+Automatic+Speech+Recognition+Meets+the+Web:+Google+Search+by+Voice+Chelba+Schalkwyk+Harb+Parada+Allauzen+Johnson+Riley+Xu+Jyothi+Brants+Ha+Neveitt"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40380.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub40380.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub40380.html">Language Modeling for Automatic Speech
                    Recognition Meets the Web: Google Search by Voice</a>
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, Johan Schalkwyk, <a href=
                    "/pubs/BoulosHarb.html">Boulos Harb</a>, <a href=
                    "/pubs/CarolinaParada.html">Carolina Parada</a>, <a href=
                    "/pubs/author130.html">Cyril Allauzen</a>, Leif Johnson, <a href=
                    "/pubs/author125.html">Michael Riley</a>, <a href="/pubs/PengXu.html">Peng
                    Xu</a>, Preethi Jyothi, Thorsten Brants, Vida Ha, Will Neveitt
                  </p>
                  <p>
                    University of Toronto (2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Large+Scale+Language+Modeling+in+Automatic+Speech+Recognition+Chelba+Bikel+Shugrina+Nguyen+Kumar"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40491.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub40491.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub40491.html">Large Scale Language Modeling in Automatic Speech
                    Recognition</a>
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, Dan Bikel, Maria Shugrina,
                    Patrick Nguyen, <a href="/pubs/author3286.html">Shankar Kumar</a>
                  </p>
                  <p>
                    Google (2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Large-scale+Discriminative+Language+Model+Reranking+for+Voice+Search+Jyothi+Johnson+Chelba+Strope"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/38145.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub38145.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub38145.html">Large-scale Discriminative Language Model
                    Reranking for Voice Search</a>
                  </p>
                  <p>
                    Preethi Jyothi, Leif Johnson, <a href="/pubs/author6342.html">Ciprian
                    Chelba</a>, Brian Strope
                  </p>
                  <p>
                    Proceedings of the NAACL-HLT 2012 Workshop: Will We Ever Really Replace the
                    N-gram Model? On the Future of Language Modeling for HLT, Association for
                    Computational Linguistics, pp. 41-49
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Learning+improved+linear+transforms+for+speech+recognition+Senior+Cho+Weston"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/36901.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub36901.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub36901.html">Learning improved linear transforms for speech
                    recognition</a>
                  </p>
                  <p>
                    <a href="/pubs/author37792.html">Andrew Senior</a>, Youngmin Cho, Jason Weston
                  </p>
                  <p>
                    ICASSP, IEEE (2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Music+Models+for+Music-Speech+Separation+Hughes+Kristjansson"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37753.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Music Models for Music-Speech Separation
                  </p>
                  <p>
                    <a href="/pubs/author37811.html">Thad Hughes</a>, Trausti Kristjansson
                  </p>
                  <p>
                    ICASSP, IEEE (2012), pp. 4917-4920
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Optimal+Size,+Freshness+and+Time-frame+for+Voice+Search+Vocabulary+Kamvar+Chelba"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40492.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub40492.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub40492.html">Optimal Size, Freshness and Time-frame for Voice
                    Search Vocabulary</a>
                  </p>
                  <p>
                    <a href="/pubs/author34.html">Maryam Kamvar</a>, <a href=
                    "/pubs/author6342.html">Ciprian Chelba</a>
                  </p>
                  <p>
                    Google (2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Recognition+of+Multilingual+Speech+in+Mobile+Applications+Lin+Huang+Beaufays+Strope+Sung"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37830.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub37830.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub37830.html">Recognition of Multilingual Speech in Mobile
                    Applications</a>
                  </p>
                  <p>
                    <a href="/pubs/HuiLin.html">Hui Lin</a>, Jui-Ting Huang, <a href=
                    "/pubs/author21120.html">Francoise Beaufays</a>, Brian Strope, Yun-hsuan Sung
                  </p>
                  <p>
                    ICASSP (2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Recurrent+Neural+Networks+for+Noise+Reduction+in+Robust+ASR+Maas+Le+O%E2%80%99Neil+Vinyals+Nguyen+Ng"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/45168.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub45168.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub45168.html">Recurrent Neural Networks for Noise Reduction in
                    Robust ASR</a>
                  </p>
                  <p>
                    Andrew Maas, <a href="/pubs/QuocLe.html">Quoc V. Le</a>, Tyler M. O’Neil,
                    <a href="/pubs/OriolVinyals.html">Oriol Vinyals</a>, Patrick Nguyen, Andrew Y.
                    Ng
                  </p>
                  <p>
                    INTERSPEECH (2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Semi-supervised+Discriminative+Language+Modeling+for+Turkish+ASR+Sara%C3%A7lar+Bikel+Hall+Sagae"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37666.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Semi-supervised Discriminative Language Modeling for Turkish ASR
                  </p>
                  <p>
                    Murat Saraçlar, Daniel M. Bikel, <a href="/pubs/author38002.html">Keith
                    Hall</a>, Kenji Sagae
                  </p>
                  <p>
                    2012 IEEE International Conference on Acoustics, Speech, and Signal Processing
                    Proceedings, IEEE, Kyoto, Japan
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Spectral+Intersections+for+Non-Stationary+Signal+Separation+Kristjansson+Hughes"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/39988.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub39988.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub39988.html">Spectral Intersections for Non-Stationary Signal
                    Separation</a>
                  </p>
                  <p>
                    Trausti Kristjansson, <a href="/pubs/author37811.html">Thad Hughes</a>
                  </p>
                  <p>
                    Proceedings of InterSpeech 2012, Portland, OR
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Speech/Nonspeech+Segmentation+in+Web+Videos+Misra"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40362.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub40362.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub40362.html">Speech/Nonspeech Segmentation in Web Videos</a>
                  </p>
                  <p>
                    <a href="/pubs/AnanyaMisra.html">Ananya Misra</a>
                  </p>
                  <p>
                    Proceedings of InterSpeech 2012
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=VISQOL:+THE+VIRTUAL+SPEECH+QUALITY+OBJECTIVE+LISTENER+Hines+Skoglund+Kokaram+Harte"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/39979.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    VISQOL: THE VIRTUAL SPEECH QUALITY OBJECTIVE LISTENER
                  </p>
                  <p>
                    Andrew Hines, <a href="/pubs/JanSkoglund.html">Jan Skoglund</a>, <a href=
                    "/pubs/AnilKokaram.html">Anil Kokaram</a>, Naomi Harte
                  </p>
                  <p>
                    International Workshop on Acoustic Signal Enhancement 2012 (IWAENC2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Voice+Query+Refinement+Allauzen+Benson+Chelba+Riley+Schalkwyk"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/40343.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Voice Query Refinement
                  </p>
                  <p>
                    <a href="/pubs/author130.html">Cyril Allauzen</a>, Edward Benson, <a href=
                    "/pubs/author6342.html">Ciprian Chelba</a>, <a href=
                    "/pubs/author125.html">Michael Riley</a>, Johan Schalkwyk
                  </p>
                  <p>
                    Interspeech (2012)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=A+Web-Based+Tool+for+Developing+Multilingual+Pronunciation+Lexicons+Ainsley+Ha+Jansche+Kim+Nanzawa"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/38078.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub38078.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub38078.html">A Web-Based Tool for Developing Multilingual
                    Pronunciation Lexicons</a>
                  </p>
                  <p>
                    <a href="/pubs/SamanthaAinsley.html">Samantha Ainsley</a>, Linne Ha, <a href=
                    "/pubs/author35845.html">Martin Jansche</a>, Ara Kim, Masayuki Nanzawa
                  </p>
                  <p>
                    12th Annual Conference of the International Speech Communication Association
                    (Interspeech 2011), pp. 3331-3332
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Bayesian+Language+Model+Interpolation+for+Mobile+Speech+Input+Allauzen+Riley"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37567.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub37567.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub37567.html">Bayesian Language Model Interpolation for Mobile
                    Speech Input</a>
                  </p>
                  <p>
                    <a href="/pubs/author130.html">Cyril Allauzen</a>, <a href=
                    "/pubs/author125.html">Michael Riley</a>
                  </p>
                  <p>
                    Interspeech 2011, pp. 1429-1432
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Deploying+Google+Search+by+Voice+in+Cantonese+Sung+Jansche+Moreno"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37116.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub37116.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub37116.html">Deploying Google Search by Voice in Cantonese</a>
                  </p>
                  <p>
                    Yun-hsuan Sung, <a href="/pubs/author35845.html">Martin Jansche</a>, <a href=
                    "/pubs/author5289.html">Pedro Moreno</a>
                  </p>
                  <p>
                    12th Annual Conference of the International Speech Communication Association
                    (Interspeech 2011), pp. 2865-2868
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Discriminative+Features+for+Language+Identification+Alberti+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42649.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Discriminative Features for Language Identification
                  </p>
                  <p>
                    C. Alberti, <a href="/pubs/MichielBacchiani.html">M. Bacchiani</a>
                  </p>
                  <p>
                    INTERSPEECH (2011)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Improving+the+speed+of+neural+networks+on+CPUs+Vanhoucke+Senior+Mao"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37631.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub37631.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub37631.html">Improving the speed of neural networks on
                    CPUs</a>
                  </p>
                  <p>
                    <a href="/pubs/VincentVanhoucke.html">Vincent Vanhoucke</a>, <a href=
                    "/pubs/author37792.html">Andrew Senior</a>, Mark Z. Mao
                  </p>
                  <p>
                    Deep Learning and Unsupervised Feature Learning Workshop, NIPS 2011
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Language+Modeling+for+Automatic+Speech+Recognition+Meets+the+Web:+Google+Search+by+Voice+Chelba+Schalkwyk+Harb+Parada+Allauzen+Riley+Xu+Brants+Ha+Neveitt"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37075.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub37075.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub37075.html">Language Modeling for Automatic Speech
                    Recognition Meets the Web: Google Search by Voice</a>
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, Johan Schalkwyk, <a href=
                    "/pubs/BoulosHarb.html">Boulos Harb</a>, <a href=
                    "/pubs/CarolinaParada.html">Carolina Parada</a>, <a href=
                    "/pubs/author130.html">Cyril Allauzen</a>, <a href=
                    "/pubs/author125.html">Michael Riley</a>, <a href="/pubs/PengXu.html">Peng
                    Xu</a>, Thorsten Brants, Vida Ha, Will Neveitt
                  </p>
                  <p>
                    OGI/OHSU Seminar Series, Portland, Oregon, USA (2011)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Recognizing+English+Queries+in+Mandarin+Voice+Search+Chang+Sung+Strope+Beaufays"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37070.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Recognizing English Queries in Mandarin Voice Search
                  </p>
                  <p>
                    Hung-An Chang, Yun-hsuan Sung, Brian Strope, <a href=
                    "/pubs/author21120.html">Francoise Beaufays</a>
                  </p>
                  <p>
                    ICASSP (2011)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Speech+Retrieval+Chelba+Hazen+Ramabhadran+Sara%C3%A7lar"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "http://onlinelibrary.wiley.com/doi/10.1002/9781119992691.ch15/summary" target=
                  "_blank">&nbsp;</a>
                  <p class="pub-title">
                    Speech Retrieval
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, Timothy J. Hazen, Bhuvana
                    Ramabhadran, Murat Saraçlar
                  </p>
                  <p>
                    Spoken Language Understanding, John Wiley and Sons, Ltd (2011), pp. 417-446
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Summary+of+Opus+listening+test+results+Hoene+Valin+Vos+Skoglund"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "http://tools.ietf.org/html/ietf-codec-results-03" target=
                  "_blank">&nbsp;</a><a class="abstract-icon tooltip" href=
                  "/pubs/pub41650.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub41650.html">Summary of Opus listening test results</a>
                  </p>
                  <p>
                    Christian Hoene, Jean-Marc Valin, Koen Vos, <a href=
                    "/pubs/JanSkoglund.html">Jan Skoglund</a>
                  </p>
                  <p>
                    IETF, IETF (2011)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=TechWare:+Mobile+Media+Search+Resources+%5BBest+of+the+Web%5D+Liu+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42648.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    TechWare: Mobile Media Search Resources [Best of the Web]
                  </p>
                  <p>
                    Z. Liu, <a href="/pubs/MichielBacchiani.html">M. Bacchiani</a>
                  </p>
                  <p>
                    IEEE Signal Processing Magazine, vol. 28 (2011), pp. 142-145
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Unsupervised+Testing+Strategies+for+ASR+Strope+Beeferman+Gruenstein+Lei"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/38335.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Unsupervised Testing Strategies for ASR
                  </p>
                  <p>
                    Brian Strope, Doug Beeferman, <a href="/pubs/author39407.html">Alexander
                    Gruenstein</a>, Xin Lei
                  </p>
                  <p>
                    Interspeech 2011, pp. 1685-1688
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Challenges+in+Automatic+Speech+Recognition+Chelba+Schalkwyk+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/36913.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub36913.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub36913.html">Challenges in Automatic Speech Recognition</a>
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, Johan Schalkwyk, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>
                  </p>
                  <p>
                    Interspeech 2010
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Decision+Tree+State+Clustering+with+Word+and+Syllable+Features+Liao+Alberti+Bacchiani+Siohan"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/36828.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub36828.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub36828.html">Decision Tree State Clustering with Word and
                    Syllable Features</a>
                  </p>
                  <p>
                    <a href="/pubs/author37501.html">Hank Liao</a>, <a href=
                    "/pubs/ChrisAlberti.html">Chris Alberti</a>, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>, <a href=
                    "/pubs/OlivierSiohan.html">Olivier Siohan</a>
                  </p>
                  <p>
                    Interspeech, ISCA (2010), 2958 – 2961
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Discriminative+Topic+Segmentation+of+Text+and+Speech+Mohri+Moreno+Weinstein"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/35636.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Discriminative Topic Segmentation of Text and Speech
                  </p>
                  <p>
                    <a href="/pubs/author122.html">Mehryar Mohri</a>, <a href=
                    "/pubs/author5289.html">Pedro Moreno</a>, Eugene Weinstein
                  </p>
                  <p>
                    International Conference on Artificial Intelligence and Statistics (AISTATS)
                    (2010)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Google+Search+by+Voice:+A+Case+Study+Schalkwyk+Beeferman+Beaufays+Byrne+Chelba+Cohen+Garrett+Strope"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/36340.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Google Search by Voice: A Case Study
                  </p>
                  <p>
                    Johan Schalkwyk, Doug Beeferman, <a href="/pubs/author21120.html">Francoise
                    Beaufays</a>, <a href="/pubs/author39011.html">Bill Byrne</a>, <a href=
                    "/pubs/author6342.html">Ciprian Chelba</a>, Mike Cohen, <a href=
                    "/pubs/author34.html">Maryam Garrett</a>, Brian Strope
                  </p>
                  <p>
                    Advances in Speech Recognition: Mobile Environments, Call Centers and Clinics,
                    Springer (2010), pp. 61-90
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=On-Demand+Language+Model+Interpolation+for+Mobile+Speech+Input+Ballinger+Allauzen+Gruenstein+Schalkwyk"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/36756.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub36756.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub36756.html">On-Demand Language Model Interpolation for Mobile
                    Speech Input</a>
                  </p>
                  <p>
                    Brandon Ballinger, <a href="/pubs/author130.html">Cyril Allauzen</a>, <a href=
                    "/pubs/author39407.html">Alexander Gruenstein</a>, Johan Schalkwyk
                  </p>
                  <p>
                    Interspeech (2010), pp. 1812-1815
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Search+by+Voice+in+Mandarin+Chinese+Shan+Wu+Hu+Tang+Jansche+Moreno"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/36463.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub36463.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub36463.html">Search by Voice in Mandarin Chinese</a>
                  </p>
                  <p>
                    Jiulong Shan, Genqing Wu, Zhihong Hu, Xiliu Tang, <a href=
                    "/pubs/author35845.html">Martin Jansche</a>, <a href=
                    "/pubs/author5289.html">Pedro J. Moreno</a>
                  </p>
                  <p>
                    Interspeech 2010, pp. 354-357
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Unsupervised+Discovery+and+Training+of+Maximally+Dissimilar+Cluster+Models+Beaufays+Vanhoucke+Strope"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/36487.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub36487.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub36487.html">Unsupervised Discovery and Training of Maximally
                    Dissimilar Cluster Models</a>
                  </p>
                  <p>
                    <a href="/pubs/author21120.html">Francoise Beaufays</a>, <a href=
                    "/pubs/VincentVanhoucke.html">Vincent Vanhoucke</a>, Brian Strope
                  </p>
                  <p>
                    Proc Interspeech (2010)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=A+new+quality+measure+for+topic+segmentation+of+text+and+speech+Mohri+Moreno+Weinstein"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/37203.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    A new quality measure for topic segmentation of text and speech
                  </p>
                  <p>
                    <a href="/pubs/author122.html">Mehryar Mohri</a>, <a href=
                    "/pubs/author5289.html">Pedro J. Moreno</a>, Eugene Weinstein
                  </p>
                  <p>
                    Conference of the International Speech Communication Association (Interspeech)
                    (2009)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Restoring+Punctuation+and+Capitalization+in+Transcribed+Speech+Gravano+Jansche+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/34562.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub34562.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub34562.html">Restoring Punctuation and Capitalization in
                    Transcribed Speech</a>
                  </p>
                  <p>
                    Agustín Gravano, <a href="/pubs/author35845.html">Martin Jansche</a>, <a href=
                    "/pubs/MichielBacchiani.html">Michiel Bacchiani</a>
                  </p>
                  <p>
                    IEEE International Conference on Acoustics, Speech, and Signal Processing
                    (ICASSP) (2009), pp. 4741-4744
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Revisiting+Graphemes+with+Increasing+Amounts+of+Data+Sung+Hughes+Beaufays+Strope"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/34835.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Revisiting Graphemes with Increasing Amounts of Data
                  </p>
                  <p>
                    Yun-Hsuan Sung, <a href="/pubs/author37811.html">Thad Hughes</a>, <a href=
                    "/pubs/author21120.html">Francoise Beaufays</a>, Brian Strope
                  </p>
                  <p>
                    ICASSP, IEEE (2009)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Web-derived+Pronunciations+Ghoshal+Jansche+Khudanpur+Riley+Ulinski"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/34837.pdf" target="_blank">&nbsp;</a><a class=
                  "abstract-icon tooltip" href="/pubs/pub34837.html">&nbsp;</a>
                  <p class="pub-title">
                    <a href="/pubs/pub34837.html">Web-derived Pronunciations</a>
                  </p>
                  <p>
                    Arnab Ghoshal, <a href="/pubs/author35845.html">Martin Jansche</a>, Sanjeev
                    Khudanpur, <a href="/pubs/author125.html">Michael Riley</a>, Morgan Ulinski
                  </p>
                  <p>
                    IEEE International Conference on Acoustics, Speech, and Signal Processing
                    (ICASSP) (2009), pp. 4289-4292
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Confidence+Scores+for+Acoustic+Model+Adaptation+Gollan+Bacchiani"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/42647.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Confidence Scores for Acoustic Model Adaptation
                  </p>
                  <p>
                    C. Gollan, <a href="/pubs/MichielBacchiani.html">M. Bacchiani</a>
                  </p>
                  <p>
                    Proceedings of the International Conference on Acoustics,Speech and Signal
                    Processing (2008)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Deploying+GOOG-411:+Early+Lessons+in+Data,+Measurement,+and+Testing+Bacchiani+Beaufays+Schalkwyk+Schuster+Strope"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "/pubs/archive/33466.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Deploying GOOG-411: Early Lessons in Data, Measurement, and Testing
                  </p>
                  <p>
                    <a href="/pubs/MichielBacchiani.html">Michiel Bacchiani</a>, <a href=
                    "/pubs/author21120.html">Francoise Beaufays</a>, Johan Schalkwyk, <a href=
                    "/pubs/MikeSchuster.html">Mike Schuster</a>, Brian Strope
                  </p>
                  <p>
                    Proc. ICASSP (2008)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Retrieval+and+Browsing+of+Spoken+Content+Chelba+Hazen+Sara%C3%A7lar"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "http://dx.doi.org/10.1109/MSP.2008.917992" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Retrieval and Browsing of Spoken Content
                  </p>
                  <p>
                    <a href="/pubs/author6342.html">Ciprian Chelba</a>, Timothy J. Hazen, Murat
                    Saraçlar
                  </p>
                  <p>
                    Signal Processing Magazine, IEEE, vol. 25 (2008), pp. 39-49
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=Speech+Recognition+with+Weighted+Finite-State+Transducers+Mohri+Pereira+Riley"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "http://www.cs.nyu.edu/~mohri/postscript/hbka.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Speech Recognition with Weighted Finite-State Transducers
                  </p>
                  <p>
                    <a href="/pubs/author122.html">Mehryar Mohri</a>, <a href=
                    "/pubs/author1092.html">Fernando C. N. Pereira</a>, <a href=
                    "/pubs/author125.html">Michael Riley</a>
                  </p>
                  <p>
                    Handbook on Speech Processing and Speech Communication, Part E: Speech
                    recognition, Springer-Verlag, Heidelberg, Germany (2008)
                  </p>
                </li>
                <li>
                  <a class="search-icon tooltip" href=
                  "https://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=%7BSpeech+Recognition+with+Weighted+Finite-State+Transducers%7D+Mohri+Pereira+Riley"
                  target="_blank">&nbsp;</a><a class="pdf-icon tooltip" href=
                  "http://www.cs.nyu.edu/~mohri/postscript/hbka.pdf" target="_blank">&nbsp;</a>
                  <p class="pub-title">
                    Speech Recognition with Weighted Finite-State Transducers
                  </p>
                  <p>
                    <a href="/pubs/author122.html">Mehryar Mohri</a>, <a href=
                    "/pubs/author1092.html">Fernando C. N. Pereira</a>, <a href=
                    "/pubs/author125.html">Michael Riley</a>
                  </p>
                  <p>
                    Handbook on Speech Processing and Speech Communication, Part E: Speech
                    recognition, Springer-Verlag, Heidelberg, Germany (2007)
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <style>
    .app-scope footer{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;clear:both;position:relative;width:100%;font-size:14px;background:#fafafa;background:-moz-linear-gradient(top,#fafafa,#f5f5f5);background:-webkit-gradient(linear,left top,left bottom,color-stop(0,#fafafa),color-stop(1,#f5f5f5));background:-webkit-linear-gradient(top,#fafafa,#f5f5f5);background:-o-linear-gradient(top,#fafafa,#f5f5f5 100%);background:-ms-linear-gradient(top,#fafafa,#f5f5f5 100%);background:linear-gradient(to top,#fafafa,#f5f5f5);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#fafafa',endColorstr='#f5f5f5',GradientType=1)}.columns{padding:16px}.app-scope footer .secondary-nav-block{margin:0 32px 32px 0}@media (min-width:768px){.app-scope footer .secondary-nav{width:968px;margin:auto}.app-scope footer .secondary-nav-block{float:left;width:20%;margin:0 32px 0 0}.app-scope footer .secondary-nav-block:first-of-type{width:30%}.app-scope footer .secondary-nav-block:nth-of-type(3n){margin-right:0}}@media (min-width:768px){.app-scope footer .secondary-nav-block+.secondary-nav-block{margin-top:0}}.app-scope footer .secondary-nav-block span{text-transform:uppercase;font-weight:400;margin-left:16px;white-space:nowrap;color:#616161}.app-scope footer ul.first-column{margin-bottom:8px}@media (min-width:768px){.app-scope footer ul.first-column{float:left;width:50%}.app-scope footer ul.second-column{float:right;width:50%}}.app-scope footer .secondary-nav-block li{padding-left:16px}.app-scope footer .secondary-nav-block li+li{margin-top:8px}.app-scope footer .secondary-nav-block li a{color:#616161;font-weight:300;font-size:12px}.app-scope footer .secondary-nav-block li a:hover{text-decoration:underline}.app-scope footer .secondary-nav-block .svg-icon{display:inline-block;width:20px;margin-right:5px;vertical-align:middle}.app-scope footer .secondary-nav-block .icon-google-plus{font-size:18px;vertical-align:text-bottom}@media (min-width:768px){.app-scope footer .secondary-nav-block::before{content:'';display:block;position:absolute;top:0;bottom:0;border-left:1px solid #e0e0e0;z-index:1}.app-scope footer .secondary-nav-block:first-of-type::before{display:none}}.app-scope footer .section-nav{padding:36px 0;margin:auto}.app-scope footer .section-logo{padding:16px 0 0 0;background-color:#eceff1}.app-scope footer .section-logo .footer-items{width:100%}.app-scope footer .section-logo .footer-logo{float:left}.app-scope footer .section-logo .footer-logo img{opacity:.54}.app-scope footer .section-logo .footer-links{float:right}.app-scope footer .section-logo .footer-links a{font-size:12px;font-weight:300}.app-scope footer .section-logo .footer-links a::after{content:'\b7';padding:6px;font-weight:400}.app-scope footer .section-logo .footer-links a:last-of-type::after{display:none}.app-scope footer .ribbon{position:absolute;top:-36px;right:0;height:4px;width:128px}.app-scope footer .ribbon table{height:100%}.app-scope footer .ribbon-color{width:32px;height:100%;border:0}.ribbon-color.blue{background-color:#4285f4}.ribbon-color.red{background-color:#db4437}.ribbon-color.yellow{background-color:#f4b400}.ribbon-color.green{background-color:#0f9d58}
    </style>
    <div class="app-scope">
      <div class="body">
        <footer>
          <section class="section-nav">
            <div class="inner">
              <div class="secondary-nav">
                <div class="secondary-nav-block">
                  <span>Research At Google</span>
                  <div class="columns">
                    <ul class="first-column">
                      <li>
                        <a href="/">Home</a>
                      </li>
                      <li>
                        <a href="/pubs/papers.html">Publications</a>
                      </li>
                      <li>
                        <a href="/researchers.html">People</a>
                      </li>
                      <li>
                        <a href="/teams/">Teams</a>
                      </li>
                    </ul>
                    <ul class="second-column">
                      <li>
                        <a href="/research-outreach.html#/research-outreach">Outreach</a>
                      </li>
                      <li>
                        <a href="http://googleresearch.blogspot.com/" target="_blank">Blog</a>
                      </li>
                      <li>
                        <a href="/workatgoogle.html">Work at Google</a>
                      </li>
                    </ul>
                  </div>
                </div>
                <div class="secondary-nav-block">
                  <span>More</span>
                  <div class="columns">
                    <ul>
                      <li>
                        <a href="http://scholar.google.com/" target="_blank">Google Scholar</a>
                      </li>
                      <li>
                        <a href="http://www.youtube.com/user/GoogleTechTalks/featured" target=
                        "_blank">YouTube Tech Talks</a>
                      </li>
                    </ul>
                  </div>
                </div>
                <div class="secondary-nav-block">
                  <span>Follow Us</span>
                  <div class="columns">
                    <ul>
                      <li>
                        <a href="https://plus.google.com/+ResearchatGoogle" target=
                        "_blank">Google+</a>
                      </li>
                      <li>
                        <a href="http://twitter.com/googleresearch" target="_blank">Twitter</a>
                      </li>
                    </ul>
                  </div>
                </div>
              </div>
              <div class="ribbon">
                <table>
                  <tr>
                    <td class="ribbon-color blue"></td>
                    <td class="ribbon-color red"></td>
                    <td class="ribbon-color yellow"></td>
                    <td class="ribbon-color green"></td>
                  </tr>
                </table>
              </div>
            </div>
          </section>
          <section class="section-logo">
            <div class="inner">
              <div class="footer-items">
                <div class="footer-logo">
                  <a href="https://www.google.com"><img alt="Google" src=
                  "https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_dark_color_42x16dp.png"></a>
                </div>
                <div class="footer-links">
                  <a href="https://www.google.com">Google</a> <a href=
                  "https://www.google.com/intl/en/about/">About Google</a> <a href=
                  "https://www.google.com/intl/en/policies/privacy/">Privacy</a> <a href=
                  "http://www.google.com/intl/en/policies/terms/">Terms</a> <a href="" onclick=
                  "sendFeedback()">Feedback</a>
                </div>
              </div>
            </div>
          </section>
        </footer>
      </div>
    </div>
    <script>
    function sendFeedback() {
    var config = {
      'productId': '720193',
      'bucket': 'site',
      'allowNonLoggedInFeedback' : true
    };
    userfeedback.api.startFeedback(config);
  }
    </script> 
    <script src="//www.google.com/jsapi">
    </script> 
    <script src="/js/research.view.js">
    </script> 
    <script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js">
    </script> 
    <script src="//ajax.googleapis.com/ajax/libs/angularjs/1.4.2/angular.min.js">
    </script> 
    <script src="//ajax.googleapis.com/ajax/libs/angularjs/1.4.2/angular-route.js">
    </script> 
    <script src="//rgc-deps.appspot.com/slick-carousel/1.5.9/slick.min.js">
    </script> 
    <script src=
    "//rgc-deps.appspot.com/angular-slick/1d3215bb32fbdd2ccf311fd49e80db1f1ec415df/slick.js">
    </script> 
    <script src=
    "//rgc-deps.appspot.com/angularUtils/5fd576f747f9f233ab9752fdc38908f5899ddc9c/dirPagination.js">
    </script> 
    <script src="/app/app.js">
    </script> 
    <script src="/app/research-outreach/research-outreach.js">
    </script> 
    <script src="/app/research-outreach/research-outreach.service.js">
    </script> 
    <script src="/app/research-outreach/faq/faq.controller.js">
    </script> 
    <script src=
    "/app/research-outreach/faculty-engagement/visiting-faculty-program/visiting-faculty.controller.js">
    </script> 
    <script src=
    "/app/research-outreach/faculty-engagement/visiting-faculty-program/visiting-faculty.service.js">
    </script> 
    <script src=
    "/app/research-outreach/faculty-engagement/faculty-research-award-recipients/faculty-research-award-recipients.js">
    </script> 
    <script src=
    "/app/research-outreach/faculty-engagement/faculty-research-award-recipients/faculty-research-award-recipients.service.js">
    </script> 
    <script src=
    "/app/research-outreach/graduate-fellowship-award-recipients/graduate-fellowship-award-recipients.js">
    </script> 
    <script src="/app/components/subnav.directive.js">
    </script> 
    <script src="/app/components/active-links.directive.js">
    </script> 
    <script src="/app/components/header-v2.js">
    </script> 
    <script src="/app/components/to-trusted.filter.js">
    </script> 
    <script src="/app/components/faq-item.directive.js">
    </script> 
    <script src="/app/components/sidebar-nav.directive.js">
    </script> 
    <script src="/app/components/cards.directive.js">
    </script> 
    <script>
    var videoUnit= new gweb.ui.LightBox('video-lightbox', 'Some tech-talks in Speech Processing');
  videoUnit.setAnimate(true);
  videoUnit.setScaleImages(true);
  videoUnit.setOutsideNav(true);
  videoUnit.setCloseText('CLOSE');
  videoUnit.setItemCount(true);
  videoUnit.init();
    </script> 
    <script>
    angular.bootstrap(document, ['googleResearch']);
    </script> 
    <script src="//www.gstatic.com/feedback/api.js">
    </script> 
    <script src="//www.google.com/js/maia.js">
    </script>
  </body>
</html>