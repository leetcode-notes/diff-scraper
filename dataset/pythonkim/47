<!doctype html>
<html lang="ko">

<head>

<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel="alternate" type="application/rss+xml" title="파이쿵" href="http://pythonkim.tistory.com/rss" />
<link href="//s1.daumcdn.net/cfs.tistory/custom/blog/207/2072317/skin/images/bootstrap.min.css" rel="stylesheet">
<link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
<link href="//s1.daumcdn.net/cfs.tistory/custom/blog/207/2072317/skin/style.css?_T_=1470399111" rel="stylesheet">
<link rel="shortcut icon" href="/favicon.ico" />
<title>파이쿵 :: 35. 딥러닝으로 MNIST 98%이상 해보기 (lab 10) 소스 코드</title>

<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
  <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
		
<!-- 구글 애널리틱스 -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-76456208-1', 'auto');
  ga('send', 'pageview');
</script>
	

<style type="text/css">
		#daumSearchBox {
			height: 21px;
			background-image : url(http://i1.daumcdn.net/imgsrc.search/search_all/show/tistory/plugin/bg_search2_2.gif);
			margin: 5px auto ;
			padding: 0;
		}
		#daumSearchBox input {
			background: none;
			margin : 0;
			padding : 0;
			border : 0;
		}
		#daumSearchBox #daumLogo {
			width: 34px;
			height: 21px;
			float: left;
			margin-right: 5px;
			background-image : url(http://i1.daumcdn.net/img-media/tistory/img/bg_search1_2_2010ci.gif);
		}
		#daumSearchBox #show_q {
			background-color: transparent;
			border: none;
			font: 12px Gulim, Sans-serif;
			color: #555;
			margin-top: 4px;
			margin-right: 15px;
			float: left;
		}

		#daumSearchBox #show_btn {
			background-image : url(http://i1.daumcdn.net/imgsrc.search/search_all/show/tistory/plugin/bt_search_2.gif);
			width: 37px;
			height: 21px;
			float: left;
			margin:0;
			cursor:pointer;
			text-indent:-1000em;
		}
	</style><link rel="stylesheet" href="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/plugins/lightbox/assets/css/lightbox.min.css" />
<link rel="stylesheet" type="text/css" href="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/plugins/TistoryProfileLayer/style.css" />
<script type="text/javascript" src="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/plugins/TistoryProfileLayer/profile.js"></script>
	<style type="text/css">
		.another_category { border: 1px solid #E5E5E5; padding: 10px 10px 5px; margin:10px 0; clear: both; }
		.another_category h4 { font-size: 12px !important; margin: 0 !important; border-bottom: 1px solid #E5E5E5 !important; padding: 2px 0 6px !important; }
		.another_category h4 a { font-weight: bold !important; }
		.another_category table { table-layout: fixed; border-collapse: collapse; width: 100% !important; margin-top: 10px !important; }
		* html .another_category table { width: auto !important; }
		*:first-child+html .another_category table { width: auto !important; }
		.another_category th, .another_category td { padding: 0 0 4px !important; }
		.another_category th { text-align: left; font-size: 12px !important; font-weight: normal;  word-break: break-all; overflow: hidden; line-height: 1.5; }
		.another_category td { text-align: right; width: 80px; font-size: 11px; }
		.another_category th a { font-weight: normal; text-decoration: none; border: none !important; }
		.another_category th a.current{ font-weight: bold; text-decoration: none !important; border-bottom: 1px solid !important; }
		.another_category th span { font-weight: normal; text-decoration: none; font: 10px Tahoma, Sans-serif; border: none !important; }

		.another_category_color_gray, .another_category_color_gray h4 { border-color: #E5E5E5 !important; }
		.another_category_color_gray * { color: #909090 !important; }
		.another_category_color_gray th a.current{border-color:#909090 !important;}
		.another_category_color_gray h4, .another_category_color_gray h4 a { color: #737373 !important; }


		.another_category_color_red, .another_category_color_red h4 { border-color: #F6D4D3 !important;  }
		.another_category_color_red * { color: #E86869 !important; }
		.another_category_color_red th a.current{border-color:#E86869 !important;}
		.another_category_color_red h4, .another_category_color_red h4 a { color: #ED0908 !important; }


		.another_category_color_green, .another_category_color_green h4 { border-color: #CCE7C8 !important; }
		.another_category_color_green * { color: #64C05B !important; }
		.another_category_color_green th a.current{border-color:#64C05B !important;}
		.another_category_color_green h4, .another_category_color_green h4 a { color: #3EA731 !important; }


		.another_category_color_blue, .another_category_color_blue h4 { border-color: #C8DAF2 !important; }
		.another_category_color_blue * { color: #477FD6 !important; }
		.another_category_color_blue th a.current{border-color:#477FD6 !important;}
		.another_category_color_blue h4, .another_category_color_blue h4 a { color: #1960CA !important; }


		.another_category_color_violet, .another_category_color_violet h4 { border-color: #E1CEEC !important;  }
		.another_category_color_violet * { color:#9D64C5 !important; }
		.another_category_color_violet th a.current{border-color:#9D64C5 !important;}
		.another_category_color_violet h4, .another_category_color_violet h4 a { color: #7E2CB5 !important; }
	</style>
<script type="text/javascript">
window.TistoryBlog = {
    url: "http://pythonkim.tistory.com",
	tistoryUrl: "http://pythonkim.tistory.com"
};
var servicePath = "";
var blogURL = "";
</script>
<script type="text/javascript" src="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/script/_/base.js"></script>
<link rel="stylesheet" type="text/css" href="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/style/dialog.css"/>
<link rel="stylesheet" type="text/css" href="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/style/menubar.css"/><style type="text/css">.tt_article_useless_p_margin p {padding-top:0 !important;padding-bottom:0 !important;margin-top:0 !important;margin-bottom:0 !important;}</style><meta name="referrer" content="always"><link rel="shortcut icon" href="http://i1.daumcdn.net/cfs.tistory/static/top/favicon_0630.ico"/><meta name="description" content="이번 동영상에서 교수님께서 여러 가지 코드를 말씀하셨다. 종류도 많고 코드도 길고 해서 따로 정리했다. 모든 코드의 learning_rate은 0.001로 고정시켰고, training_epochs 또한 15회로 고정시켰다. 교수님께서 말씀하신 부분만 수정했다. 다만 XavierForMNIST.py에서 동영상에 나오지 않은 코드가 일부 있다. bias를 초기화하는 부분인데, 동영상에는 없었다. 교수님 동영상을 보고 나처럼 정리하는 사람들이 많다. 도움을..">

<!-- BEGIN OPENGRAPH -->
<link rel="canonical" href="http://pythonkim.tistory.com/47" /><meta property="og:type" content="article"><meta property="og:url" content="http://pythonkim.tistory.com/47" ><meta property="og:site_name" content="파이쿵" ><meta property="og:title" content="35. 딥러닝으로 MNIST 98%이상 해보기 (lab 10) 소스 코드" ><meta name="by" content="사과쿵" ><meta property="og:description" content="이번 동영상에서 교수님께서 여러 가지 코드를 말씀하셨다. 종류도 많고 코드도 길고 해서 따로 정리했다. 모든 코드의 learning_rate은 0.001로 고정시켰고, training_epochs 또한 15회로 고정시켰다. 교수님께서 말씀하신 부분만 수정했다. 다만 XavierForMNIST.py에서 동영상에 나오지 않은 코드가 일부 있다. bias를 초기화하는 부분인데, 동영상에는 없었다. 교수님 동영상을 보고 나처럼 정리하는 사람들이 많다. 도움을.." ><meta property="og:image" content="https://t1.daumcdn.net/cssjs/icon/557567EA016E200001" ><meta property="article:section" content="과학" >
<!-- END OPENGRAPH -->



<!-- BEGIN TWITTERCARD -->
<meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@TISTORY"><meta name="twitter:title" content="35. 딥러닝으로 MNIST 98%이상 해보기 (lab 10) 소스 코드" ><meta name="twitter:description" content="이번 동영상에서 교수님께서 여러 가지 코드를 말씀하셨다. 종류도 많고 코드도 길고 해서 따로 정리했다. 모든 코드의 learning_rate은 0.001로 고정시켰고, training_epochs 또한 15회로 고정시켰다. 교수님께서 말씀하신 부분만 수정했다. 다만 XavierForMNIST.py에서 동영상에 나오지 않은 코드가 일부 있다. bias를 초기화하는 부분인데, 동영상에는 없었다. 교수님 동영상을 보고 나처럼 정리하는 사람들이 많다. 도움을.." ><meta property="twitter:image" content="https://t1.daumcdn.net/cssjs/icon/557567EA016E200001" >
<!-- END TWITTERCARD -->



<!-- BEGIN DAUMAPP -->
<meta property="dg:plink" content="http://pythonkim.tistory.com/47" ><meta name="plink" content="http://pythonkim.tistory.com/47" ><meta name="title" content="35. 딥러닝으로 MNIST 98%이상 해보기 (lab 10) 소스 코드" ><meta name="article:media_name" content="파이쿵" ><meta property="article:mobile_url" content="http://pythonkim.tistory.com/m/47" ><meta property="article:pc_url" content="http://pythonkim.tistory.com/47" ><meta property="article:mobile_view_url" content="http://pythonkim.tistory.com/m/47" ><meta property="article:pc_view_url" content="http://pythonkim.tistory.com/47" ><meta property="article:pc_service_home" content="http://www.tistory.com" ><meta property="article:mobile_service_home" content="http://www.tistory.com/m" ><meta property="article:txid" content="2072317_47" /><meta property="article:published_time" content="2016-08-03T01:37:27+09:00" ><meta property="og:regDate" content="20160803013727" ><meta property="article:modified_time" content="2016-09-13T13:29:25+09:00" >
<!-- END DAUMAPP -->



<!-- BEGIN STRUCTURED_DATA -->
<script type="application/ld+json">{"@context":"http://schema.org", "@type":"BlogPosting","mainEntityOfPage":{"@id": "http://pythonkim.tistory.com/47"},"url":"http://pythonkim.tistory.com/47","headline":"35. 딥러닝으로 MNIST 98%이상 해보기 (lab 10) 소스 코드","description":"이번 동영상에서 교수님께서 여러 가지 코드를 말씀하셨다. 종류도 많고 코드도 길고 해서 따로 정리했다. 모든 코드의 learning_rate은 0.001로 고정시켰고, training_epochs 또한 15회로 고정시켰다. 교수님께서 말씀하신 부분만 수정했다. 다만 XavierForMNIST.py에서 동영상에 나오지 않은 코드가 일부 있다. bias를 초기화하는 부분인데, 동영상에는 없었다. 교수님 동영상을 보고 나처럼 정리하는 사람들이 많다. 도움을..","author":{"@type":"Person","name":"사과쿵"},"image":{"@type":"ImageObject","url":"https://t1.daumcdn.net/cssjs/icon/557567EA016E200001","width":"800px","height":"800px"},"datePublished":"20160803T01:37:27+09:00","dateModified":"20160913T13:29:25+09:00","publisher":{"@type":"Organization","name":"TISTORY","logo":{"@type":"ImageObject","url":"https://t1.daumcdn.net/cssjs/icon/557567EA016E200001","width":"800px","height":"800px"}}}</script>
<!-- END STRUCTURED_DATA -->

<link rel="apple-touch-icon" href="//i1.daumcdn.net/thumb/C180x180/?fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F211AB7495706515D201F0D">
<link rel="apple-touch-icon" sizes="76x76" href="//i1.daumcdn.net/thumb/C76x76/?fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F211AB7495706515D201F0D">
<link rel="apple-touch-icon" sizes="120x120" href="//i1.daumcdn.net/thumb/C120x120/?fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F211AB7495706515D201F0D">
<link rel="apple-touch-icon" sizes="152x152" href="//i1.daumcdn.net/thumb/C152x152/?fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F211AB7495706515D201F0D"></head>

<body>

<script type="text/javascript">
	T.config = {"TOP_SSL_URL":"https:\/\/www.tistory.com","PREVIEW":false,"ROLE":"guest","PREV_PAGE":"\/48","NEXT_PAGE":"\/46","BLOG":{"isDormancy":false,"title":"\ud30c\uc774\ucff5"},"NEED_COMMENT_LOGIN":false,"COMMENT_LOGIN_CONFIRM_MESSAGE":"","LOGIN_URL":"https:\/\/www.tistory.com\/auth\/login\/?redirectUrl=http%3A%2F%2Fpythonkim.tistory.com%2F47","DEFAULT_URL":"http:\/\/pythonkim.tistory.com","USER":{"name":null,"homepage":null}};
</script>

<script type="text/javascript" src="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/script/blog/common.js"></script>
<div style="margin:0; padding:0; border:none; background:none; float:none; clear:none; z-index:0"></div>


<div id="header">
	<div class="container-fluid">
		<div class="row">
			<div class="col-md-12">
				<!-- Wrapper for slides 가로세로 비율(4:1)-->
				<div id="carousel" class="carousel slide" data-ride="carousel">
					<div class="centered carousel-inner" role="listbox">
						<div class="item active">
							<img src="//s1.daumcdn.net/cfs.tistory/custom/blog/207/2072317/skin/images/slider_01.png" width="100%" alt="Carousel 01">
							<div class="carousel-caption">
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>
</div>
<!-- header close -->

<div id="content">					<!-- 슬라이드와 본문 사이의 여백 -->
	<div class="container">
		<div class="row">				<!-- 본문 수평 마진 결정 -->
			<div class="col-md-9">
				

				

				
					<div class="entry">
						<div class="titleWrap jumbotron">
							<!-- 현재 보여지는 글의 제목 -->
							<h2>35. 딥러닝으로 MNIST 98%이상 해보기 (lab 10) 소스 코드</h2>
							<!-- 현재 보여지는 글 제목의 아래에 있는 레이블 박스 2개 -->
							<!--<span class="category label label-primary">머신러닝_김성훈교수님</span> -->
							<!--<span class="date label label-info">2016.08.03 01:37</span> -->
						</div>
						
						<!-- 현재 보여지는 글의 본문과 본문 아래 글 목록까지 함께. _article_rep_desc_로 동시 처리 -->
						<div class="article">
							<p>이번 동영상에서 교수님께서 여러 가지 코드를 말씀하셨다. 종류도 많고 코드도 길고 해서 따로 정리했다.</p>
<p>모든 코드의 learning_rate은 0.001로 고정시켰고, training_epochs 또한 15회로 고정시켰다. 교수님께서 말씀하신 부분만 수정했다. 다만 XavierForMNIST.py에서 동영상에 나오지 않은 코드가 일부 있다. bias를 초기화하는 부분인데, 동영상에는 없었다.</p>
<p>교수님 동영상을 보고 나처럼 정리하는 사람들이 많다. 도움을 받은 사이트를 소개한다. 아래 코드에 대한 설명은 이미 이전 글에서 했다. 그래도 부족한 사람은 아래 링크를 참고하기 바란다.</p>
<p>&nbsp; <b><a href="http://goodtogreate.tistory.com/entry/MNIST-데이터-셋을-이용한-손글씨-인식-Deep-Neural-Network-구현" target="_blank" class="tx-link"><span style="color: rgb(255, 94, 0);">MNIST 데이터 셋을 이용한 손글씨 인식 Deep Neural Network 구현</span></a></b></p>
<p><br /></p>
<pre style="background-color:#272822;color:#f8f8f2;font-family:'Menlo';font-size:9.0pt;"><span style="color:#75715e;"># NeuralNetworkForMnist.py : 94.57%<br /></span><span style="color:#75715e;"><br /></span><span style="color:#66d9ef;font-style:italic;">import </span>tensorflow <span style="color:#66d9ef;font-style:italic;">as </span>tf<br /><br /><span style="color:#75715e;"># Import MINST data<br /></span><span style="color:#66d9ef;font-style:italic;">from </span>tensorflow.examples.tutorials.mnist <span style="color:#66d9ef;font-style:italic;">import </span>input_data<br />mnist <span style="color:#f92672;">= </span>input_data.read_data_sets(<span style="color:#008080;font-weight:bold;">"/tmp/data/"</span>, <span style="color:#660099;">one_hot</span><span style="color:#f92672;">=</span><span style="color:#66d9ef;font-style:italic;">True</span>)<br /><br /><span style="color:#75715e;"># Parameters. 반복문에서 사용하는데, 미리 만들어 놓았다.<br /></span>learning_rate <span style="color:#f92672;">= </span><span style="color:#ae81ff;">0.001<br /></span>training_epochs <span style="color:#f92672;">= </span><span style="color:#ae81ff;">15<br /></span>batch_size <span style="color:#f92672;">= </span><span style="color:#ae81ff;">100<br /></span>display_step <span style="color:#f92672;">= </span><span style="color:#ae81ff;">1<br /></span><span style="color:#ae81ff;"><br /></span><span style="color:#75715e;"># tf Graph Input<br /></span>X <span style="color:#f92672;">= </span>tf.placeholder(tf.float32, [<span style="color:#66d9ef;font-style:italic;">None</span>, <span style="color:#ae81ff;">784</span>]) <span style="color:#75715e;"># mnist data image of shape 28*28=784<br /></span>Y <span style="color:#f92672;">= </span>tf.placeholder(tf.float32, [<span style="color:#66d9ef;font-style:italic;">None</span>, <span style="color:#ae81ff;">10</span>])  <span style="color:#75715e;"># 0-9 digits recognition =&gt; 10 classes<br /></span><span style="color:#75715e;"><br /></span><span style="color:#75715e;"># --------------------------- 수정한 부분 ------------------------------ #<br /></span><span style="color:#75715e;"># Set model weights<br /></span>W1 <span style="color:#f92672;">= </span>tf.Variable(tf.random_normal([<span style="color:#ae81ff;">784</span>, <span style="color:#ae81ff;">256</span>]))<br />W2 <span style="color:#f92672;">= </span>tf.Variable(tf.random_normal([<span style="color:#ae81ff;">256</span>, <span style="color:#ae81ff;">256</span>]))<br />W3 <span style="color:#f92672;">= </span>tf.Variable(tf.random_normal([<span style="color:#ae81ff;">256</span>,  <span style="color:#ae81ff;">10</span>]))<br /><br />B1 <span style="color:#f92672;">= </span>tf.Variable(tf.random_normal([<span style="color:#ae81ff;">256</span>]))<br />B2 <span style="color:#f92672;">= </span>tf.Variable(tf.random_normal([<span style="color:#ae81ff;">256</span>]))<br />B3 <span style="color:#f92672;">= </span>tf.Variable(tf.random_normal([ <span style="color:#ae81ff;">10</span>]))<br /><br /><span style="color:#75715e;"># Construct model<br /></span>L1 <span style="color:#f92672;">= </span>tf.nn.relu(tf.add(tf.matmul(X, W1), B1))<br />L2 <span style="color:#f92672;">= </span>tf.nn.relu(tf.add(tf.matmul(L1, W2), B2)) <span style="color:#75715e;"># Hidden layer with ReLU activation<br /></span>hypothesis <span style="color:#f92672;">= </span>tf.add(tf.matmul(L2, W3), B3)     <span style="color:#75715e;"># No need to use softmax here<br /></span><span style="color:#75715e;"># ---------------------------- 여기까지 ------------------------------- #<br /></span><span style="color:#75715e;"><br /></span><span style="color:#75715e;"># Minimize error using cross entropy<br /></span>cost <span style="color:#f92672;">= </span>tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(hypothesis, Y))   <span style="color:#75715e;"># softmax loss<br /></span><span style="color:#75715e;"># Gradient Descent<br /></span>optimizer <span style="color:#f92672;">= </span>tf.train.AdamOptimizer(<span style="color:#660099;">learning_rate</span><span style="color:#f92672;">=</span>learning_rate).minimize(cost)<br /><br /><span style="color:#75715e;"># Initializing the variables<br /></span>init <span style="color:#f92672;">= </span>tf.initialize_all_variables()<br /><br /><span style="color:#75715e;"># Launch the graph<br /></span><span style="color:#66d9ef;font-style:italic;">with </span>tf.Session() <span style="color:#66d9ef;font-style:italic;">as </span>sess<span style="color:#f92672;">:<br /></span><span style="color:#f92672;">    </span>sess.run(init)<br /><br />    <span style="color:#75715e;"># Training cycle<br /></span><span style="color:#75715e;">    </span><span style="color:#66d9ef;font-style:italic;">for </span>epoch <span style="color:#66d9ef;font-style:italic;">in </span><span style="color:#66d9ef;">range</span>(training_epochs)<span style="color:#f92672;">:<br /></span><span style="color:#f92672;">        </span>avg_cost <span style="color:#f92672;">= </span><span style="color:#ae81ff;">0.<br /></span><span style="color:#ae81ff;">        </span><span style="color:#75715e;"># 나누어 떨어지지 않으면, 뒤쪽 이미지 일부는 사용하지 않는다.<br /></span><span style="color:#75715e;">        </span>total_batch <span style="color:#f92672;">= </span><span style="color:#66d9ef;">int</span>(mnist.train.num_examples<span style="color:#f92672;">/</span>batch_size)<br />        <span style="color:#75715e;"># Loop over all batches<br /></span><span style="color:#75715e;">        </span><span style="color:#66d9ef;font-style:italic;">for </span>i <span style="color:#66d9ef;font-style:italic;">in </span><span style="color:#66d9ef;">range</span>(total_batch)<span style="color:#f92672;">:<br /></span><span style="color:#f92672;">            </span>batch_xs, batch_ys <span style="color:#f92672;">= </span>mnist.train.next_batch(batch_size)<br />            <span style="color:#75715e;"># Run optimization op (backprop) and cost op (to get loss value)<br /></span><span style="color:#75715e;">            </span>_, c <span style="color:#f92672;">= </span>sess.run([optimizer, cost], <span style="color:#660099;">feed_dict</span><span style="color:#f92672;">=</span>{X<span style="color:#f92672;">: </span>batch_xs, Y<span style="color:#f92672;">: </span>batch_ys})<br /><br />            <span style="color:#75715e;"># 분할해서 구동하기 때문에 cost를 계속해서 누적시킨다. 전체 중의 일부에 대한 비용.<br /></span><span style="color:#75715e;">            </span>avg_cost <span style="color:#f92672;">+= </span>c <span style="color:#f92672;">/ </span>total_batch<br />        <span style="color:#75715e;"># Display logs per epoch step. display_step이 1이기 때문에 if는 필요없다.<br /></span><span style="color:#75715e;">        </span><span style="color:#66d9ef;font-style:italic;">if </span>(epoch<span style="color:#f92672;">+</span><span style="color:#ae81ff;">1</span>) <span style="color:#f92672;">% </span>display_step <span style="color:#f92672;">== </span><span style="color:#ae81ff;">0</span><span style="color:#f92672;">:<br /></span><span style="color:#f92672;">            </span><span style="color:#66d9ef;">print</span>(<span style="color:#008080;font-weight:bold;">"Epoch:"</span>, <span style="color:#008080;font-weight:bold;">'%04d' </span><span style="color:#f92672;">% </span>(epoch<span style="color:#f92672;">+</span><span style="color:#ae81ff;">1</span>), <span style="color:#008080;font-weight:bold;">"cost="</span>, <span style="color:#008080;font-weight:bold;">"{:.9f}"</span>.format(avg_cost))<br /><br />    <span style="color:#66d9ef;">print</span>(<span style="color:#008080;font-weight:bold;">"Optimization Finished!"</span>)<br /><br />    <span style="color:#75715e;"># Test model<br /></span><span style="color:#75715e;">    </span>correct_prediction <span style="color:#f92672;">= </span>tf.equal(tf.argmax(hypothesis, <span style="color:#ae81ff;">1</span>), tf.argmax(Y, <span style="color:#ae81ff;">1</span>))<br />    <span style="color:#75715e;"># Calculate accuracy<br /></span><span style="color:#75715e;">    </span>accuracy <span style="color:#f92672;">= </span>tf.reduce_mean(tf.cast(correct_prediction, tf.float32))<br />    <span style="color:#66d9ef;">print</span>(<span style="color:#008080;font-weight:bold;">"Accuracy:"</span>, accuracy.eval({X<span style="color:#f92672;">: </span>mnist.test.images, Y<span style="color:#f92672;">: </span>mnist.test.labels}))</pre>
<pre style="background-color:#272822;color:#f8f8f2;font-family:'Menlo';font-size:9.0pt;"><span style="color:#ffffff;">[출력 결과]<br />Epoch: 0001 cost= 230.355805381<br />Epoch: 0002 cost= 44.542764827<br />Epoch: 0003 cost= 27.731916585<br />Epoch: 0004 cost= 19.474284099<br />Epoch: 0005 cost= 13.878197979<br />Epoch: 0006 cost= 10.265536548<br />Epoch: 0007 cost= 7.547600131<br />Epoch: 0008 cost= 5.628515447<br />Epoch: 0009 cost= 4.225564419<br />Epoch: 0010 cost= 3.117088286<br />Epoch: 0011 cost= 2.374554315<br />Epoch: 0012 cost= 1.842727151<br />Epoch: 0013 cost= 1.413149142<br />Epoch: 0014 cost= 1.093248269<br />Epoch: 0015 cost= 0.855855221<br />Optimization Finished!<br />Accuracy: 0.9457</span></pre>
<p><br /></p>
<p>정말로 아무 것도 하지 않고, 앞의 코드에 대해 초기값만 xavier 알고리듬을 사용했다. 전체 코드 대신 수정이 발생한 부분에 대해서만 코드를 표시했다.</p>
<pre style="background-color:#272822;color:#f8f8f2;font-family:'Menlo';font-size:9.0pt;"><span style="color:#75715e;"># XavierForMnist.py : 97.78%<br /></span><span style="color:#75715e;"><br /></span><span style="color:#66d9ef;font-style:italic;">import </span>tensorflow <span style="color:#66d9ef;font-style:italic;">as </span>tf<br /><br /><span style="color:#75715e;"># --------------------------- 추가한 부분 ------------------------------ #<br /></span><span style="color:#75715e;"># http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow<br /></span><span style="color:#66d9ef;font-style:italic;">def </span><span style="color:#a6e22e;">xavier_init</span>(<span style="color:#fd971f;font-style:italic;">n_inputs</span>, <span style="color:#fd971f;font-style:italic;">n_outputs</span>, <span style="color:#fd971f;font-style:italic;">uniform=True</span>)<span style="color:#f92672;">:<br /></span><span style="color:#f92672;"><br /></span><span style="color:#f92672;">    </span><span style="color:#66d9ef;font-style:italic;">if </span><span style="color:#fd971f;font-style:italic;">uniform</span><span style="color:#f92672;">:<br /></span><span style="color:#f92672;">        </span><span style="color:#75715e;"># 6 was used in the paper.<br /></span><span style="color:#75715e;">        </span>init_range <span style="color:#f92672;">= </span>tf.sqrt(<span style="color:#ae81ff;">6.0 </span><span style="color:#f92672;">/ </span>(<span style="color:#fd971f;font-style:italic;">n_inputs </span><span style="color:#f92672;">+ </span><span style="color:#fd971f;font-style:italic;">n_outputs</span>))<br />        <span style="color:#66d9ef;font-style:italic;">return </span>tf.random_uniform_initializer(<span style="color:#f92672;">-</span>init_range, init_range)<br />    <span style="color:#66d9ef;font-style:italic;">else</span><span style="color:#f92672;">:<br /></span><span style="color:#f92672;">        </span><span style="color:#75715e;"># 3 gives us approximately the same limits as above since this repicks<br /></span><span style="color:#75715e;">        # values greater than 2 standard deviations from the mean.<br /></span><span style="color:#75715e;">        </span>stddev <span style="color:#f92672;">= </span>tf.sqrt(<span style="color:#ae81ff;">3.0 </span><span style="color:#f92672;">/ </span>(<span style="color:#fd971f;font-style:italic;">n_inputs </span><span style="color:#f92672;">+ </span><span style="color:#fd971f;font-style:italic;">n_outputs</span>))<br />        <span style="color:#66d9ef;font-style:italic;">return </span>tf.truncated_normal_initializer(<span style="color:#660099;">stddev</span><span style="color:#f92672;">=</span>stddev)<br /><span style="color:#75715e;"># ---------------------------- 여기까지 ------------------------------- #<br /></span><span style="color:#75715e;"><br /></span><span style="color:#75715e;"># 수정하지 않은 부분의 마지막 줄<br /></span>X <span style="color:#f92672;">= </span>tf.placeholder(tf.float32, [<span style="color:#66d9ef;font-style:italic;">None</span>, <span style="color:#ae81ff;">784</span>])<br />Y <span style="color:#f92672;">= </span>tf.placeholder(tf.float32, [<span style="color:#66d9ef;font-style:italic;">None</span>, <span style="color:#ae81ff;">10</span>])<br /><br /><span style="color:#75715e;"># --------------------------- 수정한 부분 ------------------------------ #<br /></span><span style="color:#75715e;"># Store layers weight &amp; bias<br /></span>W1 <span style="color:#f92672;">= </span>tf.get_variable(<span style="color:#008080;font-weight:bold;">"W1"</span>, <span style="color:#660099;">shape</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">784</span>, <span style="color:#ae81ff;">256</span>], <span style="color:#660099;">initializer</span><span style="color:#f92672;">=</span>xavier_init(<span style="color:#ae81ff;">784</span>, <span style="color:#ae81ff;">256</span>))<br />W2 <span style="color:#f92672;">= </span>tf.get_variable(<span style="color:#008080;font-weight:bold;">"W2"</span>, <span style="color:#660099;">shape</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">256</span>, <span style="color:#ae81ff;">256</span>], <span style="color:#660099;">initializer</span><span style="color:#f92672;">=</span>xavier_init(<span style="color:#ae81ff;">256</span>, <span style="color:#ae81ff;">256</span>))<br />W3 <span style="color:#f92672;">= </span>tf.get_variable(<span style="color:#008080;font-weight:bold;">"W3"</span>, <span style="color:#660099;">shape</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">256</span>,  <span style="color:#ae81ff;">10</span>], <span style="color:#660099;">initializer</span><span style="color:#f92672;">=</span>xavier_init(<span style="color:#ae81ff;">256</span>,  <span style="color:#ae81ff;">10</span>))<br /><br />B1 <span style="color:#f92672;">= </span>tf.Variable(tf.zeros([<span style="color:#ae81ff;">256</span>]))       <span style="color:#75715e;"># 동영상에 없는 코드<br /></span>B2 <span style="color:#f92672;">= </span>tf.Variable(tf.zeros([<span style="color:#ae81ff;">256</span>]))<br />B3 <span style="color:#f92672;">= </span>tf.Variable(tf.zeros([ <span style="color:#ae81ff;">10</span>]))<br /><span style="color:#75715e;"># ---------------------------- 여기까지 ------------------------------- #<br /></span><span style="color:#75715e;"><br /></span><span style="color:#75715e;"># 수정한 내용없음</span></pre>
<pre style="background-color:#272822;color:#f8f8f2;font-family:'Menlo';font-size:9.0pt;"><span style="color:#ffffff;">[출력 결과]<br />Epoch: 0001 cost= 0.283199429<br />Epoch: 0002 cost= 0.100252399<br />Epoch: 0003 cost= 0.062173021<br />Epoch: 0004 cost= 0.046147975<br />Epoch: 0005 cost= 0.034034847<br />Epoch: 0006 cost= 0.024862914<br />Epoch: 0007 cost= 0.022365937<br />Epoch: 0008 cost= 0.018858417<br />Epoch: 0009 cost= 0.015144211<br />Epoch: 0010 cost= 0.011575518<br />Epoch: 0011 cost= 0.015414950<br />Epoch: 0012 cost= 0.011545146<br />Epoch: 0013 cost= 0.012465422<br />Epoch: 0014 cost= 0.010137170<br />Epoch: 0015 cost= 0.012283421<br />Optimization Finished!<br />Accuracy: 0.9778</span></pre>
<p>xavier 초기화에서 눈여겨봐야 할 것이 있다면, [출력 결과]이다. 첫 번째로 출력된 cost가 0.283으로 시작한다. 반면 첫 번째 코드에서는 마지막의 cost가 0.855이다. hinton 교수님께서 말씀하셨던 "좋은 초기화"가 무엇인지 제대로 보여주고 있다.</p><p><br /></p>
<p>바로 앞에 있는 xavier 초기화 코드에 dropout 알고리듬을 다시 추가했다. 마찬가지로 수정이 발생한 부분에 대해서만 표시했다.</p><pre style="background-color:#272822;color:#f8f8f2;font-family:'Menlo';font-size:9.0pt;"><span style="color:#75715e;"># DropoutForMnist.py : 98.19%<br /></span><span style="color:#75715e;"><br /></span><span style="color:#75715e;"># 수정하지 않은 부분의 마지막 줄<br /></span>X <span style="color:#f92672;">= </span>tf.placeholder(tf.float32, [<span style="color:#66d9ef;font-style:italic;">None</span>, <span style="color:#ae81ff;">784</span>])<br />Y <span style="color:#f92672;">= </span>tf.placeholder(tf.float32, [<span style="color:#66d9ef;font-style:italic;">None</span>, <span style="color:#ae81ff;">10</span>])<br /><br /><span style="color:#75715e;"># --------------------------- 수정한 부분 ------------------------------ #<br /></span><span style="color:#75715e;"># set dropout rate<br /></span>dropout_rate <span style="color:#f92672;">= </span>tf.placeholder(<span style="color:#008080;font-weight:bold;">"float"</span>)<br /><br /><span style="color:#75715e;"># set model weights<br /></span>W1 <span style="color:#f92672;">= </span>tf.get_variable(<span style="color:#008080;font-weight:bold;">"W1"</span>, <span style="color:#660099;">shape</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">784</span>, <span style="color:#ae81ff;">256</span>], <span style="color:#660099;">initializer</span><span style="color:#f92672;">=</span>xavier_init(<span style="color:#ae81ff;">784</span>, <span style="color:#ae81ff;">256</span>))<br />W2 <span style="color:#f92672;">= </span>tf.get_variable(<span style="color:#008080;font-weight:bold;">"W2"</span>, <span style="color:#660099;">shape</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">256</span>, <span style="color:#ae81ff;">256</span>], <span style="color:#660099;">initializer</span><span style="color:#f92672;">=</span>xavier_init(<span style="color:#ae81ff;">256</span>, <span style="color:#ae81ff;">256</span>))<br />W3 <span style="color:#f92672;">= </span>tf.get_variable(<span style="color:#008080;font-weight:bold;">"W3"</span>, <span style="color:#660099;">shape</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">256</span>, <span style="color:#ae81ff;">256</span>], <span style="color:#660099;">initializer</span><span style="color:#f92672;">=</span>xavier_init(<span style="color:#ae81ff;">256</span>, <span style="color:#ae81ff;">256</span>))<br />W4 <span style="color:#f92672;">= </span>tf.get_variable(<span style="color:#008080;font-weight:bold;">"W4"</span>, <span style="color:#660099;">shape</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">256</span>, <span style="color:#ae81ff;">256</span>], <span style="color:#660099;">initializer</span><span style="color:#f92672;">=</span>xavier_init(<span style="color:#ae81ff;">256</span>, <span style="color:#ae81ff;">256</span>))<br />W5 <span style="color:#f92672;">= </span>tf.get_variable(<span style="color:#008080;font-weight:bold;">"W5"</span>, <span style="color:#660099;">shape</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">256</span>,  <span style="color:#ae81ff;">10</span>], <span style="color:#660099;">initializer</span><span style="color:#f92672;">=</span>xavier_init(<span style="color:#ae81ff;">256</span>,  <span style="color:#ae81ff;">10</span>))<br /><br />B1 <span style="color:#f92672;">= </span>tf.Variable(tf.random_normal([<span style="color:#ae81ff;">256</span>]))<br />B2 <span style="color:#f92672;">= </span>tf.Variable(tf.random_normal([<span style="color:#ae81ff;">256</span>]))<br />B3 <span style="color:#f92672;">= </span>tf.Variable(tf.random_normal([<span style="color:#ae81ff;">256</span>]))<br />B4 <span style="color:#f92672;">= </span>tf.Variable(tf.random_normal([<span style="color:#ae81ff;">256</span>]))<br />B5 <span style="color:#f92672;">= </span>tf.Variable(tf.random_normal([ <span style="color:#ae81ff;">10</span>]))<br /><br /><span style="color:#75715e;"># Construct model<br /></span>_L1 <span style="color:#f92672;">= </span>tf.nn.relu(tf.add(tf.matmul(X,W1),B1))<br />L1 <span style="color:#f92672;">= </span>tf.nn.dropout(_L1, dropout_rate)<br />_L2 <span style="color:#f92672;">= </span>tf.nn.relu(tf.add(tf.matmul(L1, W2),B2)) <span style="color:#75715e;"># Hidden layer with ReLU activation<br /></span>L2 <span style="color:#f92672;">= </span>tf.nn.dropout(_L2, dropout_rate)<br />_L3 <span style="color:#f92672;">= </span>tf.nn.relu(tf.add(tf.matmul(L2, W3),B3)) <span style="color:#75715e;"># Hidden layer with ReLU activation<br /></span>L3 <span style="color:#f92672;">= </span>tf.nn.dropout(_L3, dropout_rate)<br />_L4 <span style="color:#f92672;">= </span>tf.nn.relu(tf.add(tf.matmul(L3, W4),B4)) <span style="color:#75715e;"># Hidden layer with ReLU activation<br /></span>L4 <span style="color:#f92672;">= </span>tf.nn.dropout(_L4, dropout_rate)<br /><br />hypothesis <span style="color:#f92672;">= </span>tf.add(tf.matmul(L4, W5), B5)     <span style="color:#75715e;"># No need to use softmax here<br /></span><span style="color:#75715e;"># ---------------------------- 여기까지 ------------------------------- #<br /></span><span style="color:#75715e;"><br /></span><span style="color:#75715e;"># 여기서부터는 run 호출에 dropout_rate 추가한 부분만 수정<br /></span>_, c <span style="color:#f92672;">= </span>sess.run([optimizer, cost],<br />            <span style="color:#660099;">feed_dict</span><span style="color:#f92672;">=</span>{X<span style="color:#f92672;">: </span>batch_xs, Y<span style="color:#f92672;">: </span>batch_ys, dropout_rate<span style="color:#f92672;">: </span><span style="color:#ae81ff;">0.7</span>})<br /><span style="color:#66d9ef;">print</span>(<span style="color:#008080;font-weight:bold;">"Accuracy:"</span>, accuracy.eval({X<span style="color:#f92672;">: </span>mnist.test.images,<br />            Y<span style="color:#f92672;">: </span>mnist.test.labels, dropout_rate<span style="color:#f92672;">: </span><span style="color:#ae81ff;">1</span>}))</pre>
<pre style="background-color:#272822;color:#f8f8f2;font-family:'Menlo';font-size:9.0pt;"><span style="color:#ffffff;">[출력 결과]<br />Epoch: 0001 cost= 0.285693568<br />Epoch: 0002 cost= 0.102228592<br />Epoch: 0003 cost= 0.065145561<br />Epoch: 0004 cost= 0.047662693<br />Epoch: 0005 cost= 0.034276855<br />Epoch: 0006 cost= 0.027074164<br />Epoch: 0007 cost= 0.021216354<br />Epoch: 0008 cost= 0.019675067<br />Epoch: 0009 cost= 0.015092999<br />Epoch: 0010 cost= 0.014085908<br />Epoch: 0011 cost= 0.013787527<br />Epoch: 0012 cost= 0.010379254<br />Epoch: 0013 cost= 0.010147506<br />Epoch: 0014 cost= 0.013407918<br />Epoch: 0015 cost= 0.009291326<br />Optimization Finished!<br />Accuracy: 0.9819</span></pre><p>레이어 갯수가 많지 않아서 dropout이 좋은 효과를 내지 못하는 것처럼 보인다. CPU 버전에서는 dropout 코드가 그래도 가장 좋은 성능을 보여줬는데, GPU 버전에서 돌려보니까 의외로 dropout 알고리듬을 적용하지 않은 xavier 초기화 코드가 가장 좋은 성능을 냈다. CPU와 GPU의 버전 차이가 있는지는 모르겠지만, "성능 차이는 없겠다"라는 생각이 들었다.</p><p>횟수를 150으로 늘려봤다. cost는 0.002까지 떨어졌으니까, 마지막의 0.009에 비하면 많이 떨어지긴 했는데 정확도는 조금 올라간 것으로 나왔다. 텐서플로우 샘플에 포함된 코드처럼 99%를 찍거나 하지는 않았다. xavier와 dropout 모두 95.25%까지 나오고 더 이상 발전이 없었다.&nbsp;</p><p>이런..&nbsp;마지막으로 다시 돌렸는데, 98.56%가 나왔다. 100번 반복 이후로는 cost가 0으로 나왔다. 소숫점 9자리에서 0이니까, 그 아래로 미세한 숫자가 있을 수 있지만, 더 이상 줄어들 것이 없기 때문에 이 정도가 최선의 결과일 수밖에 없겠다.</p><p>이번 동영상의 코드는 교수님께서 여러 가지 이론들이 어떻게 반영되는지, 성능이 얼마나 좋아지는지 보여주기 위해서 만드셨다. 나중에 반드시 텐서플로우 샘플에 포함된 코드도 봐야 한다. 코드가 쉽진 않지만, 99.2%의 결과를 어떻게 만들 수 있는지는 꼭 확인해야 한다.</p><div class="daum_like_wrapper"><iframe class="daum_like_button" id="daum_like_button_47" frameborder="0" scrolling="no" allowTransparency="true" src="http://pythonkim.tistory.com/like/?uid=2072317_47&sc=404%2CblogId_2072317&url=http%3A%2F%2Fpythonkim.tistory.com%2F47&published=1470155847" style="width:100%;height:44px;margin:10px auto"></iframe></div><div style="width:100%;margin-top:30px;clear:both;height:30px">		<div class="entry-ccl" style="float:right;margin-top:0;height:0">
			<a href="http://creativecommons.org/licenses/by/4.0/deed.ko" target="_blank" style="text-decoration: none">
				<img id="ccl-icon-47-0" class="entry-ccl-by" src="//i1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/static/admin/editor/ccl_black01.png"
				     onmouseover="tistoryCcl.show(this, 3)"
				     onmouseout="tistoryCcl.hide()" alt="저작자 표시" style="width:15px;height:15px"/>
								<!--
	<rdf:RDF xmlns="http://web.resource.org/cc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
		<Work rdf:about="">
			<license rdf:resource="http://creativecommons.org/licenses/by-fr/2.0/kr/" />
		</Work>
		<License rdf:about="http://creativecommons.org/licenses/by-fr/">
			<permits rdf:resource="http://web.resource.org/cc/Reproduction"/>
			<permits rdf:resource="http://web.resource.org/cc/Distribution"/>
			<requires rdf:resource="http://web.resource.org/cc/Notice"/>
			<requires rdf:resource="http://web.resource.org/cc/Attribution"/>
			<permits rdf:resource="http://web.resource.org/cc/DerivativeWorks"/>
		</License>
	</rdf:RDF>
	-->
			</a>
		</div>
					<script type="text/javascript">
				if (/MSIE [0-6]\./.test(navigator.userAgent)) {
					for (var i = 0; i <1; i++) {
						var el = document.getElementById('ccl-icon-47-' + i);
						el.style.filter = 'progid:DXImageTransform.Microsoft.AlphaImageLoader(src="' + el.src + '",sizingMethod="image")';
						el.src = '//i1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/static/admin/form/s.gif';
					}
				}
			</script>
			<div style="width:31px;float:left;"><a href="/toolbar/popup/abuseReport/?entryId=47" onclick="window.open(this.href, 'tistoryThisBlogPopup', 'width=550, height=510, toolbar=no, menubar=no, status=no, scrollbars=no'); return false;"><img style="border:0" src="//t1.daumcdn.net/tistory_admin/static/ico/ico_spam_report.png" alt="신고"></a></div></div><div class="another_category another_category_color_gray">
<h4>'<a href="/category/머신러닝_김성훈교수님">머신러닝_김성훈교수님</a>' 카테고리의 다른 글</h4>
<table>
<tr>
<th>
<a href="http://pythonkim.tistory.com/53" >38. ConvNet Max pooling 과 Full Network (lec 11-2)</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.11</td>
</tr>
<tr>
<th>
<a href="http://pythonkim.tistory.com/52" >37. ConvNet의 Conv 레이어 만들기 (lec 11-1)</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.11</td>
</tr>
<tr>
<th>
<a href="http://pythonkim.tistory.com/47"  class ="current" >35. 딥러닝으로 MNIST 98%이상 해보기 (lab 10) 소스 코드</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.03</td>
</tr>
<tr>
<th>
<a href="http://pythonkim.tistory.com/44" >34. 딥러닝으로 MNIST 98%이상 해보기 (lab 10)</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.02</td>
</tr>
<tr>
<th>
<a href="http://pythonkim.tistory.com/43" >33. 레고처럼 넷트웍 모듈을 마음껏 쌓아 보자 (lec 10-4)</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.02</td>
</tr>
<tr>
<th>
<a href="http://pythonkim.tistory.com/42" >32. Dropout 과 앙상블 (lec 10-3)</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.02</td>
</tr>
</table></div>
						</div>

						<!-- 글 목록 하단의 프로필. 이미지와 간략한 소개 나오는 곳 -->
						<!-- 프로필 아래에 "받은 트랙백이 없고, 댓글이 없습니다." <div class="actionTrail"> -->
						
					</div> 					<!-- end of entry -->
				

			<!-- 하단 목록 번호 1 2 3 .. 9 10 <s_paging> -->
			</div>
			
			<div class="col-md-3">
				<!-- 기본 사이드바 -->
				<div class="sidebar">
				
					<!-- 오른쪽 사이드바의 공지사항 모듈. 없앨려면, s_sidebar_element 안쪽을 주석으로 막아야 한다. b 태그 추가했다 -->
						
							<div id="notice" class="widget">
								<h3><i class="fa fa-bullhorn"></i>공지사항</h3>
								<ul class="fa-ul">
									
										<li><i class="fa-ul fa fa-chevron-right"></i>
											<a href="/notice/77"><b>파이썬 동영상</b></a> </li>
									
										<li><i class="fa-ul fa fa-chevron-right"></i>
											<a href="/notice/76"><b>머신러닝 동영상</b></a> </li>
									
										<li><i class="fa-ul fa fa-chevron-right"></i>
											<a href="/notice/25"><b>머신러닝 목차</b></a> </li>
									
								</ul>
							</div>
						
					
					<!-- 오른쪽 사이드바의 카테고리 모듈. 없앨려면, s_sidebar_element 안쪽을 주석으로 막아야 한다. -->
						<div id="category" class="widget">
							<h3><i class="fa fa-folder"></i>카테고리</h3>
							<ul class="tt_category">
	<li class="">
		<a class="link_tit" href="/category">
			분류 전체보기							<span class="c_cnt">(70)</span>
			
					</a>

				<ul class="category_list">
							<li class="">
					<a class="link_item" href="/category/프로필">
						프로필													<span class="c_cnt">(0)</span>
						
											</a>

					
				</li>
							<li class="">
					<a class="link_item" href="/category/머신러닝">
						머신러닝													<span class="c_cnt">(3)</span>
						
											</a>

					
				</li>
							<li class="">
					<a class="link_item" href="/category/머신러닝_김성훈교수님">
						머신러닝_김성훈교수님													<span class="c_cnt">(45)</span>
						
											</a>

					
				</li>
							<li class="">
					<a class="link_item" href="/category/텐서플로우">
						텐서플로우													<span class="c_cnt">(12)</span>
						
											</a>

					
				</li>
							<li class="">
					<a class="link_item" href="/category/이것저것">
						이것저것													<span class="c_cnt">(10)</span>
						
											</a>

					
				</li>
					</ul>
			</li>
</ul>

						</div>
					
						<div class="author alert alert-success">
							<img src="http://cfile4.uf.tistory.com/image/211AB7495706515D201F0D" alt="블로그 이미지" 
									 class="img-responsive img-circle text-center" width="50%">
							<p><span class="text label label-primary"></span></p>
							<p>얼떨결에 붙인 이름 파이썬_킴</p>
						</div>
					
				</div>
			</div>
		</div>
	</div>
</div>
<!--	
<div id="footer">
	<div class="container">
		<div class="row">
				<div class="copyright">
					<p class="text-center">Copyright 2016 파이썬_킴. All Rights Reserved.<br/>
				</div>
		</div>
	</div>
</div>
-->


<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="//s1.daumcdn.net/cfs.tistory/custom/blog/207/2072317/skin/images/bootstrap.min.js"></script>
<script>
$(window).scroll(function() {
  if ($(document).scrollTop() > 50) {
    $('nav').addClass('shrink');
  } else {
    $('nav').removeClass('shrink');
  }
});
</script>
<script id="DragSearchJs" type="text/javascript" src="http://s1.daumcdn.net/img.search/front/js/searchDragSelection.js?nil_ch=tistory" charset="euc-kr"></script>
<script>
$("body").bind('copy', function (e) {
    if (typeof window.getSelection == "undefined") {//IE8 or earlier...
        event.preventDefault();

        var pagelink = '\n\n 출처: ' + decodeURI(document.location.href),
            copytext =  window.getSelection() + pagelink;

        if (window.clipboardData) {
            window.clipboardData.setData('Text', copytext);
        }
        return;
    }
    var body_element = document.getElementsByTagName('body')[0];
    var selection = window.getSelection();

    //if the selection is short let's not annoy our users
    if (("" + selection).length < 30) return;

    //create a div outside of the visible area
    var newdiv = document.createElement('div');
    newdiv.style.position = 'absolute';
    newdiv.style.left = '-99999px';
    body_element.appendChild(newdiv);
    newdiv.appendChild(selection.getRangeAt(0).cloneContents());

    //we need a <pre> tag workaround
    //otherwise the text inside "pre" loses all the line breaks!
    if (selection.getRangeAt(0).commonAncestorContainer.nodeName == "PRE") {
        newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
    }

    newdiv.innerHTML += "<br /><br />출처: <a href='"
        + document.location.href + "'>"
        + decodeURI(document.location.href) + "</a> [파이쿵]";

    selection.selectAllChildren(newdiv);
    window.setTimeout(function () { body_element.removeChild(newdiv); }, 200);
});
</script><script> if (!window.jQuery) document.write("<script src=\"http://t1.daumcdn.net/tistory_admin/lib/jquery-1.12.4.min.js\"><\/script>") </script>
	<script src="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/plugins/lightbox/assets/js/lightbox.min.js"></script>
	<script>
	    lightbox.option({
			"fadeDuration": 200,
		    "resizeDuration": 200,
		    "wrapAround": false,
			"albumLabel": "%1 / %2",
			"fitImagesInViewport":true ,
			"stopEvent": false
	    })
	</script><script type="text/javascript">
var _tiq = 'undefined' !== typeof _tiq ? _tiq : []; // Global Variables
_tiq.push(["__setParam", "title", "파이쿵 :: 35. 딥러닝으로 MNIST 98%이상 해보기 (lab 10) 소스 코드"]);
_tiq.push(["__setParam", "svcdomain", "user.tistory.com"]);
_tiq.push(["__setParam", "category", ""]);
_tiq.push(["__setParam", "articleno", "47"]);
_tiq.push(["__setParam", "plink", "http://pythonkim.tistory.com/47"]);
_tiq.push(["__setParam", "date", "2016-08-03 01:37:27"]);
_tiq.push(["__setParam", "author", "pythonkim"]);
_tiq.push(["__setParam", "length", "25615"]);
_tiq.push(["__setParam", "isauthor", "N"]);
_tiq.push(["__setParam", "ishidden", "1"]);
_tiq.push(["__setParam", "comments", "0"]);
_tiq.push(["__setParam", "param1", "0"]);
_tiq.push(["__setParam", "param2", "e"]);
_tiq.push(["__setParam", "param3", ""]);
_tiq.push(["__setParam", "like_ex", "{'serviceId': 'tistory', 'uniqueId': '2072317_47', 'serviceCategories': '404,blogId_2072317'}"]);
_tiq.push(["__trackPageview"]);
(function(d) {
	var se = d.createElement('script'); se.type = 'text/javascript'; se.async = true;
	se.src = location.protocol + '//m2.daumcdn.net/tiara/js/td.min.js';
	var s = d.getElementsByTagName('head')[0]; s.appendChild(se);
})(document);
</script>
<script type="text/javascript">
var __TiaraObj = __TiaraObj || {}; if ('undefined' === typeof __TiaraObj.startTime) { __TiaraObj.startTime = new Date(); }
var addEvent = function (evt, fn) { window.addEventListener ? window.addEventListener(evt, fn, false) : window.attachEvent('on' + evt, fn); };
var ua = navigator.userAgent.toLowerCase(); var isIOS = /iP[ao]d|iPhone/i.test(ua); var contentStat = function() {
_tiq.push(['__content', 't_content', {
"c_id":"2072317_47", 
"c_title":"파이쿵 :: 35. 딥러닝으로 MNIST 98%이상 해보기 (lab 10) 소스 코드", 
"type":"article", 
"author":"사과쿵", 
"author_id":"1415031", 
"cp":"pythonkim", 
"cp_id":"2072317", 
"regdata":"2016-08-03 01:37:27", 
"plink":"http://pythonkim.tistory.com/47", 
"media":"pcweb", 
"comment_cnt":0, 
"duration": (new Date()).getTime() - __TiaraObj.startTime.getTime()
}]); };
addEvent(isIOS ? "pagehide" : "beforeunload", contentStat);
</script>
<script type="text/javascript">window.roosevelt_params_queue = window.roosevelt_params_queue || []; window.roosevelt_params_queue.push({channel_id: "dk", channel_label: "tistory"});</script>
<script type="text/javascript" src="//adimg.daumcdn.net/rt/dk_bt/roosevelt_dk_bt.js" async></script><script type="text/javascript">if(window.console!=undefined){setTimeout(console.log.bind(console,"%cTISTORY","font:8em Arial;color:#EC6521;font-weight:bold"),0);setTimeout(console.log.bind(console,"%c  나를 표현하는 블로그","font:2em sans-serif;color:#333;"),0);}</script>		<div id="tistorytoolbarid"
		     style="position:absolute;height:20px;top:4px;right:0px;background-color:transparent;background-image:none;z-index:11;">
			<div class="tistorytoolbar tt_menubar_login">
				<div
					class="tt_menubar_whiteBar">
					<div id="ttMenubarInnerWrap" class="tt_menubar_inner">
						<div class="tt_menubar_bg_toolbar"></div>
						<h2 style="display:none;">티스토리 툴바</h2>
						<div class="tt_menubar_mainmenu"><a
								class="tt_menubar_link_tit tt_menubar_link_tit_daum tt_menubar_link_tit_eng"
								href="http://www.daum.net/?nil_ref=tistory"
								target="_blank">Daum</a></div>
						<div class="tt_menubar_bg_bar"></div>
						<div class="tt_menubar_mainmenu"><a class="tt_menubar_link_tit tt_menubar_link_tit_eng"
						                                    href="http://www.tistory.com">Tistory</a>
						</div>
						<div class="tt_menubar_bg_bar"></div>
						<div class="tt_menubar_logout"><a class="tt_menubar_link_tit"
														  href="https://www.tistory.com/auth/login">로그인</a>
						</div>
					</div>
				</div>
			</div>
		</div>
		</body>
</html>
