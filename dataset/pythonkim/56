<!doctype html>
<html lang="ko">

<head>

<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel="alternate" type="application/rss+xml" title="파이쿵" href="http://pythonkim.tistory.com/rss" />
<link href="//s1.daumcdn.net/cfs.tistory/custom/blog/207/2072317/skin/images/bootstrap.min.css" rel="stylesheet">
<link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
<link href="//s1.daumcdn.net/cfs.tistory/custom/blog/207/2072317/skin/style.css?_T_=1470399111" rel="stylesheet">
<link rel="shortcut icon" href="/favicon.ico" />
<title>파이쿵 :: 40. ConvNet을 TensorFlow로 구현하자 (MNIST 99%) (lab 11)</title>

<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
  <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
		
<!-- 구글 애널리틱스 -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-76456208-1', 'auto');
  ga('send', 'pageview');
</script>
	

<style type="text/css">
		#daumSearchBox {
			height: 21px;
			background-image : url(http://i1.daumcdn.net/imgsrc.search/search_all/show/tistory/plugin/bg_search2_2.gif);
			margin: 5px auto ;
			padding: 0;
		}
		#daumSearchBox input {
			background: none;
			margin : 0;
			padding : 0;
			border : 0;
		}
		#daumSearchBox #daumLogo {
			width: 34px;
			height: 21px;
			float: left;
			margin-right: 5px;
			background-image : url(http://i1.daumcdn.net/img-media/tistory/img/bg_search1_2_2010ci.gif);
		}
		#daumSearchBox #show_q {
			background-color: transparent;
			border: none;
			font: 12px Gulim, Sans-serif;
			color: #555;
			margin-top: 4px;
			margin-right: 15px;
			float: left;
		}

		#daumSearchBox #show_btn {
			background-image : url(http://i1.daumcdn.net/imgsrc.search/search_all/show/tistory/plugin/bt_search_2.gif);
			width: 37px;
			height: 21px;
			float: left;
			margin:0;
			cursor:pointer;
			text-indent:-1000em;
		}
	</style><link rel="stylesheet" href="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/plugins/lightbox/assets/css/lightbox.min.css" />
<link rel="stylesheet" type="text/css" href="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/plugins/TistoryProfileLayer/style.css" />
<script type="text/javascript" src="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/plugins/TistoryProfileLayer/profile.js"></script>
	<style type="text/css">
		.another_category { border: 1px solid #E5E5E5; padding: 10px 10px 5px; margin:10px 0; clear: both; }
		.another_category h4 { font-size: 12px !important; margin: 0 !important; border-bottom: 1px solid #E5E5E5 !important; padding: 2px 0 6px !important; }
		.another_category h4 a { font-weight: bold !important; }
		.another_category table { table-layout: fixed; border-collapse: collapse; width: 100% !important; margin-top: 10px !important; }
		* html .another_category table { width: auto !important; }
		*:first-child+html .another_category table { width: auto !important; }
		.another_category th, .another_category td { padding: 0 0 4px !important; }
		.another_category th { text-align: left; font-size: 12px !important; font-weight: normal;  word-break: break-all; overflow: hidden; line-height: 1.5; }
		.another_category td { text-align: right; width: 80px; font-size: 11px; }
		.another_category th a { font-weight: normal; text-decoration: none; border: none !important; }
		.another_category th a.current{ font-weight: bold; text-decoration: none !important; border-bottom: 1px solid !important; }
		.another_category th span { font-weight: normal; text-decoration: none; font: 10px Tahoma, Sans-serif; border: none !important; }

		.another_category_color_gray, .another_category_color_gray h4 { border-color: #E5E5E5 !important; }
		.another_category_color_gray * { color: #909090 !important; }
		.another_category_color_gray th a.current{border-color:#909090 !important;}
		.another_category_color_gray h4, .another_category_color_gray h4 a { color: #737373 !important; }


		.another_category_color_red, .another_category_color_red h4 { border-color: #F6D4D3 !important;  }
		.another_category_color_red * { color: #E86869 !important; }
		.another_category_color_red th a.current{border-color:#E86869 !important;}
		.another_category_color_red h4, .another_category_color_red h4 a { color: #ED0908 !important; }


		.another_category_color_green, .another_category_color_green h4 { border-color: #CCE7C8 !important; }
		.another_category_color_green * { color: #64C05B !important; }
		.another_category_color_green th a.current{border-color:#64C05B !important;}
		.another_category_color_green h4, .another_category_color_green h4 a { color: #3EA731 !important; }


		.another_category_color_blue, .another_category_color_blue h4 { border-color: #C8DAF2 !important; }
		.another_category_color_blue * { color: #477FD6 !important; }
		.another_category_color_blue th a.current{border-color:#477FD6 !important;}
		.another_category_color_blue h4, .another_category_color_blue h4 a { color: #1960CA !important; }


		.another_category_color_violet, .another_category_color_violet h4 { border-color: #E1CEEC !important;  }
		.another_category_color_violet * { color:#9D64C5 !important; }
		.another_category_color_violet th a.current{border-color:#9D64C5 !important;}
		.another_category_color_violet h4, .another_category_color_violet h4 a { color: #7E2CB5 !important; }
	</style>
<script type="text/javascript">
window.TistoryBlog = {
    url: "http://pythonkim.tistory.com",
	tistoryUrl: "http://pythonkim.tistory.com"
};
var servicePath = "";
var blogURL = "";
</script>
<script type="text/javascript" src="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/script/_/base.js"></script>
<link rel="stylesheet" type="text/css" href="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/style/dialog.css"/>
<link rel="stylesheet" type="text/css" href="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/style/menubar.css"/><style type="text/css">.tt_article_useless_p_margin p {padding-top:0 !important;padding-bottom:0 !important;margin-top:0 !important;margin-bottom:0 !important;}</style><meta name="referrer" content="always"><link rel="shortcut icon" href="http://i1.daumcdn.net/cfs.tistory/static/top/favicon_0630.ico"/><meta name="description" content="앞서 설명했던 3개 동영상에 대한 실습 동영상이다.  교수님께서 올려 놓으신 소스코드가 있는 웹사이트 주소. 오른쪽 하단의 주소를 입력해서 다운로드하면 된다. 이번 동영상에 나온 코드 외에도 많이 있다. https://github.com/nlintz/TensorFlow-Tutorials  CNN(Convolutional Neural Network) 구성도. conv 2개, pooling 2개, fc의 형태로 만들어 졌다.  이전 동영상에 나왔던 그림을 코드로 어떻게 구현하는지 보여준다...">

<!-- BEGIN OPENGRAPH -->
<link rel="canonical" href="http://pythonkim.tistory.com/56" /><meta property="og:type" content="article"><meta property="og:url" content="http://pythonkim.tistory.com/56" ><meta property="og:site_name" content="파이쿵" ><meta property="og:title" content="40. ConvNet을 TensorFlow로 구현하자 (MNIST 99%) (lab 11)" ><meta name="by" content="사과쿵" ><meta property="og:description" content="앞서 설명했던 3개 동영상에 대한 실습 동영상이다.  교수님께서 올려 놓으신 소스코드가 있는 웹사이트 주소. 오른쪽 하단의 주소를 입력해서 다운로드하면 된다. 이번 동영상에 나온 코드 외에도 많이 있다. https://github.com/nlintz/TensorFlow-Tutorials  CNN(Convolutional Neural Network) 구성도. conv 2개, pooling 2개, fc의 형태로 만들어 졌다.  이전 동영상에 나왔던 그림을 코드로 어떻게 구현하는지 보여준다..." ><meta property="og:image" content="http://cfile7.uf.tistory.com/image/2130144857ABEB5820FDB0" ><meta property="article:section" content="과학" >
<!-- END OPENGRAPH -->



<!-- BEGIN TWITTERCARD -->
<meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@TISTORY"><meta name="twitter:title" content="40. ConvNet을 TensorFlow로 구현하자 (MNIST 99%) (lab 11)" ><meta name="twitter:description" content="앞서 설명했던 3개 동영상에 대한 실습 동영상이다.  교수님께서 올려 놓으신 소스코드가 있는 웹사이트 주소. 오른쪽 하단의 주소를 입력해서 다운로드하면 된다. 이번 동영상에 나온 코드 외에도 많이 있다. https://github.com/nlintz/TensorFlow-Tutorials  CNN(Convolutional Neural Network) 구성도. conv 2개, pooling 2개, fc의 형태로 만들어 졌다.  이전 동영상에 나왔던 그림을 코드로 어떻게 구현하는지 보여준다..." ><meta property="twitter:image" content="http://cfile7.uf.tistory.com/image/2130144857ABEB5820FDB0" >
<!-- END TWITTERCARD -->



<!-- BEGIN DAUMAPP -->
<meta property="dg:plink" content="http://pythonkim.tistory.com/56" ><meta name="plink" content="http://pythonkim.tistory.com/56" ><meta name="title" content="40. ConvNet을 TensorFlow로 구현하자 (MNIST 99%) (lab 11)" ><meta name="article:media_name" content="파이쿵" ><meta property="article:mobile_url" content="http://pythonkim.tistory.com/m/56" ><meta property="article:pc_url" content="http://pythonkim.tistory.com/56" ><meta property="article:mobile_view_url" content="http://pythonkim.tistory.com/m/56" ><meta property="article:pc_view_url" content="http://pythonkim.tistory.com/56" ><meta property="article:pc_service_home" content="http://www.tistory.com" ><meta property="article:mobile_service_home" content="http://www.tistory.com/m" ><meta property="article:txid" content="2072317_56" /><meta property="article:published_time" content="2016-08-11T12:54:12+09:00" ><meta property="og:regDate" content="20160811125412" ><meta property="article:modified_time" content="2017-01-21T12:27:36+09:00" >
<!-- END DAUMAPP -->



<!-- BEGIN STRUCTURED_DATA -->
<script type="application/ld+json">{"@context":"http://schema.org", "@type":"BlogPosting","mainEntityOfPage":{"@id": "http://pythonkim.tistory.com/56"},"url":"http://pythonkim.tistory.com/56","headline":"40. ConvNet을 TensorFlow로 구현하자 (MNIST 99%) (lab 11)","description":"앞서 설명했던 3개 동영상에 대한 실습 동영상이다.  교수님께서 올려 놓으신 소스코드가 있는 웹사이트 주소. 오른쪽 하단의 주소를 입력해서 다운로드하면 된다. 이번 동영상에 나온 코드 외에도 많이 있다. https://github.com/nlintz/TensorFlow-Tutorials  CNN(Convolutional Neural Network) 구성도. conv 2개, pooling 2개, fc의 형태로 만들어 졌다.  이전 동영상에 나왔던 그림을 코드로 어떻게 구현하는지 보여준다...","author":{"@type":"Person","name":"사과쿵"},"image":{"@type":"ImageObject","url":"http://cfile7.uf.tistory.com/image/2130144857ABEB5820FDB0","width":"800px","height":"800px"},"datePublished":"20160811T12:54:12+09:00","dateModified":"20170121T12:27:36+09:00","publisher":{"@type":"Organization","name":"TISTORY","logo":{"@type":"ImageObject","url":"https://t1.daumcdn.net/cssjs/icon/557567EA016E200001","width":"800px","height":"800px"}}}</script>
<!-- END STRUCTURED_DATA -->

<link rel="apple-touch-icon" href="//i1.daumcdn.net/thumb/C180x180/?fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F211AB7495706515D201F0D">
<link rel="apple-touch-icon" sizes="76x76" href="//i1.daumcdn.net/thumb/C76x76/?fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F211AB7495706515D201F0D">
<link rel="apple-touch-icon" sizes="120x120" href="//i1.daumcdn.net/thumb/C120x120/?fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F211AB7495706515D201F0D">
<link rel="apple-touch-icon" sizes="152x152" href="//i1.daumcdn.net/thumb/C152x152/?fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F211AB7495706515D201F0D"></head>

<body>

<script type="text/javascript">
	T.config = {"TOP_SSL_URL":"https:\/\/www.tistory.com","PREVIEW":false,"ROLE":"guest","PREV_PAGE":"\/57","NEXT_PAGE":"\/55","BLOG":{"isDormancy":false,"title":"\ud30c\uc774\ucff5"},"NEED_COMMENT_LOGIN":false,"COMMENT_LOGIN_CONFIRM_MESSAGE":"","LOGIN_URL":"https:\/\/www.tistory.com\/auth\/login\/?redirectUrl=http%3A%2F%2Fpythonkim.tistory.com%2F56","DEFAULT_URL":"http:\/\/pythonkim.tistory.com","USER":{"name":null,"homepage":null}};
</script>

<script type="text/javascript" src="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/script/blog/common.js"></script>
<div style="margin:0; padding:0; border:none; background:none; float:none; clear:none; z-index:0"></div>


<div id="header">
	<div class="container-fluid">
		<div class="row">
			<div class="col-md-12">
				<!-- Wrapper for slides 가로세로 비율(4:1)-->
				<div id="carousel" class="carousel slide" data-ride="carousel">
					<div class="centered carousel-inner" role="listbox">
						<div class="item active">
							<img src="//s1.daumcdn.net/cfs.tistory/custom/blog/207/2072317/skin/images/slider_01.png" width="100%" alt="Carousel 01">
							<div class="carousel-caption">
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>
</div>
<!-- header close -->

<div id="content">					<!-- 슬라이드와 본문 사이의 여백 -->
	<div class="container">
		<div class="row">				<!-- 본문 수평 마진 결정 -->
			<div class="col-md-9">
				

				

				
					<div class="entry">
						<div class="titleWrap jumbotron">
							<!-- 현재 보여지는 글의 제목 -->
							<h2>40. ConvNet을 TensorFlow로 구현하자 (MNIST 99%) (lab 11)</h2>
							<!-- 현재 보여지는 글 제목의 아래에 있는 레이블 박스 2개 -->
							<!--<span class="category label label-primary">머신러닝_김성훈교수님</span> -->
							<!--<span class="date label label-info">2016.08.11 12:54</span> -->
						</div>
						
						<!-- 현재 보여지는 글의 본문과 본문 아래 글 목록까지 함께. _article_rep_desc_로 동시 처리 -->
						<div class="article">
							<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:491px;;height:auto;max-width:100%"><img src="http://cfile7.uf.tistory.com/image/2130144857ABEB5820FDB0" style="max-width:100%;height:auto" width="491" height="211" filename="K-001.png" filemime="image/jpeg"/></span></p>
<p><br /></p>
<p>앞서 설명했던 3개 동영상에 대한 실습 동영상이다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile27.uf.tistory.com/image/25359A4857ABEB581E91F5" style="max-width:100%;height:auto" width="772" height="435" filename="K-002.png" filemime="image/jpeg"/></span></p>
<p>교수님께서 올려 놓으신 소스코드가 있는 웹사이트 주소. 오른쪽 하단의 주소를 입력해서 다운로드하면 된다. 이번 동영상에 나온 코드 외에도 많이 있다.</p>
<p>&nbsp; <b><a href="https://github.com/nlintz/TensorFlow-Tutorials" target="_blank" class="tx-link"><span style="color: rgb(255, 94, 0);">https://github.com/nlintz/TensorFlow-Tutorials</span></a></b></p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile5.uf.tistory.com/image/25321C4857ABEB59202196" style="max-width:100%;height:auto" width="772" height="435" filename="K-005.png" filemime="image/jpeg"/></span></p>
<p>CNN(Convolutional Neural Network) 구성도. conv 2개, pooling 2개, fc의 형태로 만들어 졌다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile7.uf.tistory.com/image/2541F94857ABEB59147FA2" style="max-width:100%;height:auto" width="772" height="435" filename="K-007.png" filemime="image/jpeg"/></span></p>
<p>이전 동영상에 나왔던 그림을 코드로 어떻게 구현하는지 보여준다. conv2d 함수의 설명은 아래와 같다.</p>
<p>&nbsp; <b>tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)</b></p>
<p>&nbsp; input : [batch, in_height, in_width, in_channels] 형식. 28x28x1 형식의 손글씨 이미지.<br />&nbsp; filter :&nbsp;[filter_height, filter_width, in_channels, out_channels] 형식. 3, 3, 1, 32의 w.<br />&nbsp; strides : 크기 4인 1차원 리스트. [0], [3]은 반드시 1. 일반적으로 [1], [2]는 같은 값 사용.<br />&nbsp; padding : 'SAME' 또는 'VALID'. 패딩을 추가하는 공식의 차이. SAME은 출력 크기를 입력과 같게 유지.</p>
<p>3x3x1 필터를 32개 만드는 것을 코드로 표현하면 [3, 3, 1, 32]가 된다. 순서대로 너비(3), 높이(3), 입력 채널(1), 출력 채널(32)을 뜻한다. 32개의 출력이 만들어진다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile22.uf.tistory.com/image/243D074857ABEB5A18C2B3" style="max-width:100%;height:auto" width="772" height="435" filename="K-008.png" filemime="image/jpeg"/></span></p>
<p>출력 채널을 부르는 용어는 activation map이다. 물음표로 처리되어 크기를 알 수 없는데, 원본 이미지와 똑같은 28이 된다. SAME 옵션을 사용해서 패딩을 줬으니까.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile22.uf.tistory.com/image/222C5C4857ABEB5A245429" style="max-width:100%;height:auto" width="772" height="435" filename="K-009.png" filemime="image/jpeg"/></span></p>
<p>convolutional layer를 적용한 결과를 ReLU에 전달하고 있다. 그냥 매개변수로 전달하면 끝이다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile30.uf.tistory.com/image/22398C4857ABEB5B1A96D4" style="max-width:100%;height:auto" width="772" height="435" filename="K-011.png" filemime="image/jpeg"/></span></p>
<p>여러 개 중에서 하나를 선택하는 것을 pooling이라고 한다. 다른 말로는 sampling이라고도 한다.</p>
<p>&nbsp; <b>tf.nn.max_pool(value, ksize, strides, padding, data_format='NHWC', name=None)</b></p>
<p>&nbsp; value : [batch, height, width, channels] 형식의 입력 데이터. ReLU를 통과한 출력 결과가 된다.<br />&nbsp; ksize : 4개 이상의 크기를 갖는 리스트로 입력 데이터의 각 차원의 윈도우 크기.<br />&nbsp; data_format : NHWC 또는 NCHW. n-count, height, width, channel의 약자 사용.</p>
<p>ksize가 [1,2,2,1]이라는 뜻은 2칸씩 이동하면서 출력 결과를 1개 만들어 낸다는 것이다. 다시 말해 4개의 데이터 중에서 가장 큰 1개를 반환하는 역할을 한다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile7.uf.tistory.com/image/242E0B4857ABEB5B22DE7A" style="max-width:100%;height:auto" width="772" height="435" filename="K-012.png" filemime="image/jpeg"/></span></p>
<p>Max Pooling에 대한 그림이 다시 나왔다. 4개의 칸에서 1개를 추출하고 있다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile3.uf.tistory.com/image/2160044A57ABEB5C1756D3" style="max-width:100%;height:auto" width="772" height="435" filename="K-013.png" filemime="image/jpeg"/></span></p>
<p>여러 개의 변수를 사용하는 과정에서 헷갈리는 것이 당연하다. 이럴 경우 tensorflow에게 물어보는 것이 좋다고 말씀하셨다. print 함수로 출력하면 알려준다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile22.uf.tistory.com/image/2266F44A57ABEB5C113CD0" style="max-width:100%;height:auto" width="772" height="435" filename="K-014.png" filemime="image/jpeg"/></span></p>
<p>reshape 함수에 대해 설명하셨다. trX라는 변수의 형태를 4차원으로 변환하고 있다. -1은 갯수가 정해지지 않아서 모를 경우에 사용한다.</p>
<p>max_pool 함수에도 padding 옵션을 사용하고 있다. 앞의 설명에서 필터와 stride만으로 크기가 결정되는 줄 알았는데, 실제로는 크기가 바뀔 수 있다. l3a에서 결과는 [?, 7, 7, 128]인데, max pooling에서 나누어 떨어지지 않기 때문에 처리할 수 없다. 이때 padding 옵션이 들어가서 나누어 떨어지도록 패딩을 추가하게 된다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile21.uf.tistory.com/image/2163A74A57ABEB5D1464E1" style="max-width:100%;height:auto" width="772" height="435" filename="K-017.png" filemime="image/jpeg"/></span></p>
<p>앞의 코드에 dropout을 살짝 추가했다. 기존 코드를 수정하지 않고, 중간에 넣으면 끝.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile26.uf.tistory.com/image/225BBE4A57ABEB5D1B9CB4" style="max-width:100%;height:auto" width="772" height="435" filename="K-018.png" filemime="image/jpeg"/></span></p>
<p>이전 코드에서 마지막 max pooling의 결과는 [?, 4, 4, 128]이었다. 이것을 FC로 구현하려면 Wx + b에 맞게 W를 구성해야 한다. 5x5x3의 필터가 75개의 feature를 갖는 것처럼, 4x4x128만큼의 feature가 필요하다. w4의 출력 결과는 625개로 설정했고, 다음 번 layer에서는 625를 10개로 축소했다. 10개는 0부터 9까지의 숫자 label을 뜻한다.</p>
<p>이번 코드에서는 layer가 3개 사용됐다. l3와 l4는 hidden layer, pyx는 output layer. l3는 [?, 2048]이고, l4는 [2048, 625], pyx는 [625, 10]이 된다. FC에서 이전 출력 크기와 다음 입력 크기가 같아야 행렬 곱셈을 할 수 있기 때문에 숫자가 중복되고 있다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile27.uf.tistory.com/image/22501E4A57ABEB5E2261C8" style="max-width:100%;height:auto" width="772" height="435" filename="K-019.png" filemime="image/jpeg"/></span></p>
<p>cost를 계산하는 것은 이전 동영상에서 봤던 그 함수다. 달라진 점은 RMSOptimizer 함수 사용에 있다. RMSProp 알고리듬을 구현하고 있는 함수다. 0.001은 learning rate, 0.9는 learning rate을 감소시킬 매개변수(decay)를 뜻한다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile25.uf.tistory.com/image/2453164A57ABEB5F2164C9" style="max-width:100%;height:auto" width="772" height="435" filename="K-020.png" filemime="image/jpeg"/></span></p>
<p>tensorflow에서 제공하는 다양한 optimizer에 대해 보여준다. 시간이 허락하면 모두 사용해 보고 언제 어떤 성능을 내는지 이해해야 한다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile10.uf.tistory.com/image/2254574A57ABEB5F1F1715" style="max-width:100%;height:auto" width="772" height="435" filename="K-022.png" filemime="image/jpeg"/></span></p>
<p>128개씩 끊어서 전달하는 코드를 보여준다. 전체적으로 100번 반복하고 있다.</p>
<p><br /></p>
<p style="text-align: center; clear: none; float: none;"><span class="imageblock" style="display:inline-block;width:772px;;height:auto;max-width:100%"><img src="http://cfile2.uf.tistory.com/image/2461154D57ABEB601F6D26" style="max-width:100%;height:auto" width="772" height="435" filename="K-023.png" filemime="image/jpeg"/></span></p>
<p>결과는 놀랍다. 무려 99.2%의 정확도를 자랑한다. 더욱이 왼쪽이 반복 횟수를 의미한다면 5번만에 찾았다는 것인데.. 실제 코드를 돌려본 결과는 여기 출력과는 차이가 있다. 아래에서 다시 설명한다.</p>
<p>교수님께서 올려놓으신 코드. 전혀 수정하지 않았다. 소스 코드에 대한 설명은 앞에서 했으므로 생략한다. 참, 이 코드를 구동하려면 구글에서 배포한 input_data.py 파일도 필요하다. 앞에서 언급한 사이트에 있다. 아니면 모듈 import 위치에서도 확인할 수 있다. tensorflow 모듈의 examples 폴더 아래에 tutorials/mnist 폴더가 실제로 존재한다.</p><p><br /></p><pre style="background-color:#272822;color:#f8f8f2;font-family:'DejaVu Sans Mono';font-size:9.8pt;"><span style="color:#66d9ef;font-style:italic;">import </span>tensorflow <span style="color:#66d9ef;font-style:italic;">as </span>tf<br /><span style="color:#66d9ef;font-style:italic;">import </span>numpy <span style="color:#66d9ef;font-style:italic;">as </span>np<br /><span style="color:#66d9ef;font-style:italic;">from </span>tensorflow.examples.tutorials.mnist <span style="color:#66d9ef;font-style:italic;">import </span>input_data<br /><br />batch_size <span style="color:#f92672;">= </span><span style="color:#ae81ff;">128<br /></span>test_size <span style="color:#f92672;">= </span><span style="color:#ae81ff;">256<br /></span><span style="color:#ae81ff;"><br /></span><span style="color:#66d9ef;font-style:italic;">def </span><span style="color:#a6e22e;">init_weights</span>(<span style="color:#fd971f;font-style:italic;">shape</span>)<span style="color:#f92672;">:<br /></span><span style="color:#f92672;">    </span><span style="color:#66d9ef;font-style:italic;">return </span>tf.Variable(tf.random_normal(<span style="color:#fd971f;font-style:italic;">shape</span>, <span style="color:#fd971f;font-style:italic;">stddev</span><span style="color:#f92672;">=</span><span style="color:#ae81ff;">0.01</span>))<br /><br /><span style="color:#66d9ef;font-style:italic;">def </span><span style="color:#a6e22e;">model</span>(<span style="color:#fd971f;font-style:italic;">X</span>, <span style="color:#fd971f;font-style:italic;">w</span>, <span style="color:#fd971f;font-style:italic;">w2</span>, <span style="color:#fd971f;font-style:italic;">w3</span>, <span style="color:#fd971f;font-style:italic;">w4</span>, <span style="color:#fd971f;font-style:italic;">w_o</span>, <span style="color:#fd971f;font-style:italic;">p_keep_conv</span>, <span style="color:#fd971f;font-style:italic;">p_keep_hidden</span>)<span style="color:#f92672;">:<br /></span><span style="color:#f92672;">    </span>l1a <span style="color:#f92672;">= </span>tf.nn.relu(tf.nn.conv2d(<span style="color:#fd971f;font-style:italic;">X</span>, <span style="color:#fd971f;font-style:italic;">w</span>,                       <span style="color:#75715e;"># l1a shape=(?, 28, 28, 32)<br /></span><span style="color:#75715e;">                        </span><span style="color:#fd971f;font-style:italic;">strides</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">1</span>], <span style="color:#fd971f;font-style:italic;">padding</span><span style="color:#f92672;">=</span><span style="color:#e6db74;">'SAME'</span>))<br />    l1 <span style="color:#f92672;">= </span>tf.nn.max_pool(l1a, <span style="color:#fd971f;font-style:italic;">ksize</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">1</span>],              <span style="color:#75715e;"># l1 shape=(?, 14, 14, 32)<br /></span><span style="color:#75715e;">                        </span><span style="color:#fd971f;font-style:italic;">strides</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">1</span>], <span style="color:#fd971f;font-style:italic;">padding</span><span style="color:#f92672;">=</span><span style="color:#e6db74;">'SAME'</span>)<br />    l1 <span style="color:#f92672;">= </span>tf.nn.dropout(l1, <span style="color:#fd971f;font-style:italic;">p_keep_conv</span>)<br /><br />    l2a <span style="color:#f92672;">= </span>tf.nn.relu(tf.nn.conv2d(l1, <span style="color:#fd971f;font-style:italic;">w2</span>,                     <span style="color:#75715e;"># l2a shape=(?, 14, 14, 64)<br /></span><span style="color:#75715e;">                        </span><span style="color:#fd971f;font-style:italic;">strides</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">1</span>], <span style="color:#fd971f;font-style:italic;">padding</span><span style="color:#f92672;">=</span><span style="color:#e6db74;">'SAME'</span>))<br />    l2 <span style="color:#f92672;">= </span>tf.nn.max_pool(l2a, <span style="color:#fd971f;font-style:italic;">ksize</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">1</span>],              <span style="color:#75715e;"># l2 shape=(?, 7, 7, 64)<br /></span><span style="color:#75715e;">                        </span><span style="color:#fd971f;font-style:italic;">strides</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">1</span>], <span style="color:#fd971f;font-style:italic;">padding</span><span style="color:#f92672;">=</span><span style="color:#e6db74;">'SAME'</span>)<br />    l2 <span style="color:#f92672;">= </span>tf.nn.dropout(l2, <span style="color:#fd971f;font-style:italic;">p_keep_conv</span>)<br /><br />    l3a <span style="color:#f92672;">= </span>tf.nn.relu(tf.nn.conv2d(l2, <span style="color:#fd971f;font-style:italic;">w3</span>,                     <span style="color:#75715e;"># l3a shape=(?, 7, 7, 128)<br /></span><span style="color:#75715e;">                        </span><span style="color:#fd971f;font-style:italic;">strides</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">1</span>], <span style="color:#fd971f;font-style:italic;">padding</span><span style="color:#f92672;">=</span><span style="color:#e6db74;">'SAME'</span>))<br />    l3 <span style="color:#f92672;">= </span>tf.nn.max_pool(l3a, <span style="color:#fd971f;font-style:italic;">ksize</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">1</span>],              <span style="color:#75715e;"># l3 shape=(?, 4, 4, 128)<br /></span><span style="color:#75715e;">                        </span><span style="color:#fd971f;font-style:italic;">strides</span><span style="color:#f92672;">=</span>[<span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">2</span>, <span style="color:#ae81ff;">1</span>], <span style="color:#fd971f;font-style:italic;">padding</span><span style="color:#f92672;">=</span><span style="color:#e6db74;">'SAME'</span>)<br />    l3 <span style="color:#f92672;">= </span>tf.reshape(l3, [<span style="color:#f92672;">-</span><span style="color:#ae81ff;">1</span>, <span style="color:#fd971f;font-style:italic;">w4</span>.get_shape().as_list()[<span style="color:#ae81ff;">0</span>]])    <span style="color:#75715e;"># reshape to (?, 2048)<br /></span><span style="color:#75715e;">    </span>l3 <span style="color:#f92672;">= </span>tf.nn.dropout(l3, <span style="color:#fd971f;font-style:italic;">p_keep_conv</span>)<br /><br />    l4 <span style="color:#f92672;">= </span>tf.nn.relu(tf.matmul(l3, <span style="color:#fd971f;font-style:italic;">w4</span>))<br />    l4 <span style="color:#f92672;">= </span>tf.nn.dropout(l4, <span style="color:#fd971f;font-style:italic;">p_keep_hidden</span>)<br /><br />    pyx <span style="color:#f92672;">= </span>tf.matmul(l4, <span style="color:#fd971f;font-style:italic;">w_o</span>)<br />    <span style="color:#66d9ef;font-style:italic;">return </span>pyx<br /><br />mnist <span style="color:#f92672;">= </span>input_data.read_data_sets(<span style="color:#e6db74;">"MNIST_data/"</span>, <span style="color:#fd971f;font-style:italic;">one_hot</span><span style="color:#f92672;">=</span><span style="color:#66d9ef;font-style:italic;">True</span>)<br />trX, trY, teX, teY <span style="color:#f92672;">= </span>mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels<br />trX <span style="color:#f92672;">= </span>trX.reshape(<span style="color:#f92672;">-</span><span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">28</span>, <span style="color:#ae81ff;">28</span>, <span style="color:#ae81ff;">1</span>)  <span style="color:#75715e;"># 28x28x1 input img<br /></span>teX <span style="color:#f92672;">= </span>teX.reshape(<span style="color:#f92672;">-</span><span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">28</span>, <span style="color:#ae81ff;">28</span>, <span style="color:#ae81ff;">1</span>)  <span style="color:#75715e;"># 28x28x1 input img<br /></span><span style="color:#75715e;"><br /></span>X <span style="color:#f92672;">= </span>tf.placeholder(<span style="color:#e6db74;">"float"</span>, [<span style="color:#66d9ef;font-style:italic;">None</span>, <span style="color:#ae81ff;">28</span>, <span style="color:#ae81ff;">28</span>, <span style="color:#ae81ff;">1</span>])<br />Y <span style="color:#f92672;">= </span>tf.placeholder(<span style="color:#e6db74;">"float"</span>, [<span style="color:#66d9ef;font-style:italic;">None</span>, <span style="color:#ae81ff;">10</span>])<br /><br />w <span style="color:#f92672;">= </span>init_weights([<span style="color:#ae81ff;">3</span>, <span style="color:#ae81ff;">3</span>, <span style="color:#ae81ff;">1</span>, <span style="color:#ae81ff;">32</span>])       <span style="color:#75715e;"># 3x3x1 conv, 32 outputs<br /></span>w2 <span style="color:#f92672;">= </span>init_weights([<span style="color:#ae81ff;">3</span>, <span style="color:#ae81ff;">3</span>, <span style="color:#ae81ff;">32</span>, <span style="color:#ae81ff;">64</span>])     <span style="color:#75715e;"># 3x3x32 conv, 64 outputs<br /></span>w3 <span style="color:#f92672;">= </span>init_weights([<span style="color:#ae81ff;">3</span>, <span style="color:#ae81ff;">3</span>, <span style="color:#ae81ff;">64</span>, <span style="color:#ae81ff;">128</span>])    <span style="color:#75715e;"># 3x3x32 conv, 128 outputs<br /></span>w4 <span style="color:#f92672;">= </span>init_weights([<span style="color:#ae81ff;">128 </span><span style="color:#f92672;">* </span><span style="color:#ae81ff;">4 </span><span style="color:#f92672;">* </span><span style="color:#ae81ff;">4</span>, <span style="color:#ae81ff;">625</span>]) <span style="color:#75715e;"># FC 128 * 4 * 4 inputs, 625 outputs<br /></span>w_o <span style="color:#f92672;">= </span>init_weights([<span style="color:#ae81ff;">625</span>, <span style="color:#ae81ff;">10</span>])         <span style="color:#75715e;"># FC 625 inputs, 10 outputs (labels)<br /></span><span style="color:#75715e;"><br /></span>p_keep_conv <span style="color:#f92672;">= </span>tf.placeholder(<span style="color:#e6db74;">"float"</span>)<br />p_keep_hidden <span style="color:#f92672;">= </span>tf.placeholder(<span style="color:#e6db74;">"float"</span>)<br />py_x <span style="color:#f92672;">= </span>model(X, w, w2, w3, w4, w_o, p_keep_conv, p_keep_hidden)<br /><br />cost <span style="color:#f92672;">= </span>tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(py_x, Y))<br />train_op <span style="color:#f92672;">= </span>tf.train.RMSPropOptimizer(<span style="color:#ae81ff;">0.001</span>, <span style="color:#ae81ff;">0.9</span>).minimize(cost)<br />predict_op <span style="color:#f92672;">= </span>tf.argmax(py_x, <span style="color:#ae81ff;">1</span>)<br /><br /><span style="color:#75715e;"># Launch the graph in a session<br /></span><span style="color:#66d9ef;font-style:italic;">with </span>tf.Session() <span style="color:#66d9ef;font-style:italic;">as </span>sess<span style="color:#f92672;">:<br /></span><span style="color:#f92672;">    </span><span style="color:#75715e;"># you need to initialize all variables<br /></span><span style="color:#75715e;">    </span>tf.initialize_all_variables().run()<br /><br />    <span style="color:#66d9ef;font-style:italic;">for </span>i <span style="color:#66d9ef;font-style:italic;">in </span><span style="color:#66d9ef;">range</span>(<span style="color:#ae81ff;">100</span>)<span style="color:#f92672;">:<br /></span><span style="color:#f92672;">        </span>training_batch <span style="color:#f92672;">= </span><span style="color:#66d9ef;">zip</span>(<span style="color:#66d9ef;">range</span>(<span style="color:#ae81ff;">0</span>, <span style="color:#66d9ef;">len</span>(trX), batch_size),<br />                             <span style="color:#66d9ef;">range</span>(batch_size, <span style="color:#66d9ef;">len</span>(trX)<span style="color:#f92672;">+</span><span style="color:#ae81ff;">1</span>, batch_size))<br />        <span style="color:#66d9ef;font-style:italic;">for </span>start, end <span style="color:#66d9ef;font-style:italic;">in </span>training_batch<span style="color:#f92672;">:<br /></span><span style="color:#f92672;">            </span>sess.run(train_op, <span style="color:#fd971f;font-style:italic;">feed_dict</span><span style="color:#f92672;">=</span>{X<span style="color:#f92672;">: </span>trX[start<span style="color:#f92672;">:</span>end], Y<span style="color:#f92672;">: </span>trY[start<span style="color:#f92672;">:</span>end],<br />                                          p_keep_conv<span style="color:#f92672;">: </span><span style="color:#ae81ff;">0.8</span>, p_keep_hidden<span style="color:#f92672;">: </span><span style="color:#ae81ff;">0.5</span>})<br /><br />        test_indices <span style="color:#f92672;">= </span>np.arange(<span style="color:#66d9ef;">len</span>(teX)) <span style="color:#75715e;"># Get A Test Batch<br /></span><span style="color:#75715e;">        </span>np.random.shuffle(test_indices)<br />        test_indices <span style="color:#f92672;">= </span>test_indices[<span style="color:#ae81ff;">0</span><span style="color:#f92672;">:</span>test_size]<br /><br />        <span style="color:#66d9ef;">print</span>(i, np.mean(np.argmax(teY[test_indices], <span style="color:#fd971f;font-style:italic;">axis</span><span style="color:#f92672;">=</span><span style="color:#ae81ff;">1</span>) <span style="color:#f92672;">==<br /></span><span style="color:#f92672;">                         </span>sess.run(predict_op, <span style="color:#fd971f;font-style:italic;">feed_dict</span><span style="color:#f92672;">=</span>{X<span style="color:#f92672;">: </span>teX[test_indices],<br />                                                         Y<span style="color:#f92672;">: </span>teY[test_indices],<br />                                                         p_keep_conv<span style="color:#f92672;">: </span><span style="color:#ae81ff;">1.0</span>,<br />                                                         p_keep_hidden<span style="color:#f92672;">: </span><span style="color:#ae81ff;">1.0</span>})))<br /></pre><pre style="background-color:#272822;color:#f8f8f2;font-family:'Menlo';font-size:9.0pt;"><span style="color: rgb(255, 255, 255);">[출력 결과]<br />0 0.94140625<br />1 0.97265625<br />2 0.98828125<br />3 0.98828125<br />4 0.99609375<br />5 0.99609375<br />6 0.99609375<br />7 0.98828125<br />8 1.0<br />9 0.98828125<br />...<br />95 0.9921875<br />96 1.0<br />97 0.99609375<br />98 0.9921875<br />99 0.9921875</span></pre>
<p>출력 결과를 보면 1.0 부근에서 왔다갔다 한다. 이런 상황이 100번 반복할 때까지 계속된다. 어떻든지간에 결과는 99.2% 이상 나온다. 소요 시간은 너무 길어서 측정할 생각도 하지 않았는데, 1시간 이상 걸리는 걸로 판단. 이전에 수행해 봤던 비슷한 코드가 그만큼 나왔으니까.</p>
<p>얼마 전 구매한 GTX1060 그래픽카드를 사용하면 대략 2분에서 3분 정도 걸린다. CPU로는 50분 걸릴 때도 있고 1시간 30분 걸릴 때도 있었다. 보급형 GPU만으로도 너무 잘 나와서 기분이 좋았다. 다만 GPU를 지원하는 텐서플로우 설치는 좀 피곤하다.</p><div class="daum_like_wrapper"><iframe class="daum_like_button" id="daum_like_button_56" frameborder="0" scrolling="no" allowTransparency="true" src="http://pythonkim.tistory.com/like/?uid=2072317_56&sc=404%2CblogId_2072317&url=http%3A%2F%2Fpythonkim.tistory.com%2F56&published=1470887652" style="width:100%;height:44px;margin:10px auto"></iframe></div><div style="width:100%;margin-top:30px;clear:both;height:30px">		<div class="entry-ccl" style="float:right;margin-top:0;height:0">
			<a href="http://creativecommons.org/licenses/by/4.0/deed.ko" target="_blank" style="text-decoration: none">
				<img id="ccl-icon-56-0" class="entry-ccl-by" src="//i1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/static/admin/editor/ccl_black01.png"
				     onmouseover="tistoryCcl.show(this, 3)"
				     onmouseout="tistoryCcl.hide()" alt="저작자 표시" style="width:15px;height:15px"/>
								<!--
	<rdf:RDF xmlns="http://web.resource.org/cc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
		<Work rdf:about="">
			<license rdf:resource="http://creativecommons.org/licenses/by-fr/2.0/kr/" />
		</Work>
		<License rdf:about="http://creativecommons.org/licenses/by-fr/">
			<permits rdf:resource="http://web.resource.org/cc/Reproduction"/>
			<permits rdf:resource="http://web.resource.org/cc/Distribution"/>
			<requires rdf:resource="http://web.resource.org/cc/Notice"/>
			<requires rdf:resource="http://web.resource.org/cc/Attribution"/>
			<permits rdf:resource="http://web.resource.org/cc/DerivativeWorks"/>
		</License>
	</rdf:RDF>
	-->
			</a>
		</div>
					<script type="text/javascript">
				if (/MSIE [0-6]\./.test(navigator.userAgent)) {
					for (var i = 0; i <1; i++) {
						var el = document.getElementById('ccl-icon-56-' + i);
						el.style.filter = 'progid:DXImageTransform.Microsoft.AlphaImageLoader(src="' + el.src + '",sizingMethod="image")';
						el.src = '//i1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/static/admin/form/s.gif';
					}
				}
			</script>
			<div style="width:31px;float:left;"><a href="/toolbar/popup/abuseReport/?entryId=56" onclick="window.open(this.href, 'tistoryThisBlogPopup', 'width=550, height=510, toolbar=no, menubar=no, status=no, scrollbars=no'); return false;"><img style="border:0" src="//t1.daumcdn.net/tistory_admin/static/ico/ico_spam_report.png" alt="신고"></a></div></div><div class="another_category another_category_color_gray">
<h4>'<a href="/category/머신러닝_김성훈교수님">머신러닝_김성훈교수님</a>' 카테고리의 다른 글</h4>
<table>
<tr>
<th>
<a href="http://pythonkim.tistory.com/58" >42. TensorFlow에서 RNN 구현하기 (lab 12)</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.12</td>
</tr>
<tr>
<th>
<a href="http://pythonkim.tistory.com/57" >41. NN의 꽃 RNN 이야기 (lec 12)</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.11</td>
</tr>
<tr>
<th>
<a href="http://pythonkim.tistory.com/56"  class ="current" >40. ConvNet을 TensorFlow로 구현하자 (MNIST 99%) (lab 11)</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.11</td>
</tr>
<tr>
<th>
<a href="http://pythonkim.tistory.com/54" >39. ConvNet의 활용예 (lec 11-3)</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.11</td>
</tr>
<tr>
<th>
<a href="http://pythonkim.tistory.com/53" >38. ConvNet Max pooling 과 Full Network (lec 11-2)</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.11</td>
</tr>
<tr>
<th>
<a href="http://pythonkim.tistory.com/52" >37. ConvNet의 Conv 레이어 만들기 (lec 11-1)</a>&nbsp;&nbsp;<span>(0)</span>
</th>
<td>
2016.08.11</td>
</tr>
</table></div>
						</div>

						<!-- 글 목록 하단의 프로필. 이미지와 간략한 소개 나오는 곳 -->
						<!-- 프로필 아래에 "받은 트랙백이 없고, 댓글이 없습니다." <div class="actionTrail"> -->
						
					</div> 					<!-- end of entry -->
				

			<!-- 하단 목록 번호 1 2 3 .. 9 10 <s_paging> -->
			</div>
			
			<div class="col-md-3">
				<!-- 기본 사이드바 -->
				<div class="sidebar">
				
					<!-- 오른쪽 사이드바의 공지사항 모듈. 없앨려면, s_sidebar_element 안쪽을 주석으로 막아야 한다. b 태그 추가했다 -->
						
							<div id="notice" class="widget">
								<h3><i class="fa fa-bullhorn"></i>공지사항</h3>
								<ul class="fa-ul">
									
										<li><i class="fa-ul fa fa-chevron-right"></i>
											<a href="/notice/77"><b>파이썬 동영상</b></a> </li>
									
										<li><i class="fa-ul fa fa-chevron-right"></i>
											<a href="/notice/76"><b>머신러닝 동영상</b></a> </li>
									
										<li><i class="fa-ul fa fa-chevron-right"></i>
											<a href="/notice/25"><b>머신러닝 목차</b></a> </li>
									
								</ul>
							</div>
						
					
					<!-- 오른쪽 사이드바의 카테고리 모듈. 없앨려면, s_sidebar_element 안쪽을 주석으로 막아야 한다. -->
						<div id="category" class="widget">
							<h3><i class="fa fa-folder"></i>카테고리</h3>
							<ul class="tt_category">
	<li class="">
		<a class="link_tit" href="/category">
			분류 전체보기							<span class="c_cnt">(70)</span>
			
					</a>

				<ul class="category_list">
							<li class="">
					<a class="link_item" href="/category/프로필">
						프로필													<span class="c_cnt">(0)</span>
						
											</a>

					
				</li>
							<li class="">
					<a class="link_item" href="/category/머신러닝">
						머신러닝													<span class="c_cnt">(3)</span>
						
											</a>

					
				</li>
							<li class="">
					<a class="link_item" href="/category/머신러닝_김성훈교수님">
						머신러닝_김성훈교수님													<span class="c_cnt">(45)</span>
						
											</a>

					
				</li>
							<li class="">
					<a class="link_item" href="/category/텐서플로우">
						텐서플로우													<span class="c_cnt">(12)</span>
						
											</a>

					
				</li>
							<li class="">
					<a class="link_item" href="/category/이것저것">
						이것저것													<span class="c_cnt">(10)</span>
						
											</a>

					
				</li>
					</ul>
			</li>
</ul>

						</div>
					
						<div class="author alert alert-success">
							<img src="http://cfile4.uf.tistory.com/image/211AB7495706515D201F0D" alt="블로그 이미지" 
									 class="img-responsive img-circle text-center" width="50%">
							<p><span class="text label label-primary"></span></p>
							<p>얼떨결에 붙인 이름 파이썬_킴</p>
						</div>
					
				</div>
			</div>
		</div>
	</div>
</div>
<!--	
<div id="footer">
	<div class="container">
		<div class="row">
				<div class="copyright">
					<p class="text-center">Copyright 2016 파이썬_킴. All Rights Reserved.<br/>
				</div>
		</div>
	</div>
</div>
-->


<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="//s1.daumcdn.net/cfs.tistory/custom/blog/207/2072317/skin/images/bootstrap.min.js"></script>
<script>
$(window).scroll(function() {
  if ($(document).scrollTop() > 50) {
    $('nav').addClass('shrink');
  } else {
    $('nav').removeClass('shrink');
  }
});
</script>
<script id="DragSearchJs" type="text/javascript" src="http://s1.daumcdn.net/img.search/front/js/searchDragSelection.js?nil_ch=tistory" charset="euc-kr"></script>
<script>
$("body").bind('copy', function (e) {
    if (typeof window.getSelection == "undefined") {//IE8 or earlier...
        event.preventDefault();

        var pagelink = '\n\n 출처: ' + decodeURI(document.location.href),
            copytext =  window.getSelection() + pagelink;

        if (window.clipboardData) {
            window.clipboardData.setData('Text', copytext);
        }
        return;
    }
    var body_element = document.getElementsByTagName('body')[0];
    var selection = window.getSelection();

    //if the selection is short let's not annoy our users
    if (("" + selection).length < 30) return;

    //create a div outside of the visible area
    var newdiv = document.createElement('div');
    newdiv.style.position = 'absolute';
    newdiv.style.left = '-99999px';
    body_element.appendChild(newdiv);
    newdiv.appendChild(selection.getRangeAt(0).cloneContents());

    //we need a <pre> tag workaround
    //otherwise the text inside "pre" loses all the line breaks!
    if (selection.getRangeAt(0).commonAncestorContainer.nodeName == "PRE") {
        newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
    }

    newdiv.innerHTML += "<br /><br />출처: <a href='"
        + document.location.href + "'>"
        + decodeURI(document.location.href) + "</a> [파이쿵]";

    selection.selectAllChildren(newdiv);
    window.setTimeout(function () { body_element.removeChild(newdiv); }, 200);
});
</script><script> if (!window.jQuery) document.write("<script src=\"http://t1.daumcdn.net/tistory_admin/lib/jquery-1.12.4.min.js\"><\/script>") </script>
	<script src="//s1.daumcdn.net/cfs.tistory/resource/0c59a9d20b31be342e2141a1d0559a4755f3d334/blog/plugins/lightbox/assets/js/lightbox.min.js"></script>
	<script>
	    lightbox.option({
			"fadeDuration": 200,
		    "resizeDuration": 200,
		    "wrapAround": false,
			"albumLabel": "%1 / %2",
			"fitImagesInViewport":true ,
			"stopEvent": false
	    })
	</script><script type="text/javascript">
var _tiq = 'undefined' !== typeof _tiq ? _tiq : []; // Global Variables
_tiq.push(["__setParam", "title", "파이쿵 :: 40. ConvNet을 TensorFlow로 구현하자 (MNIST 99%) (lab 11)"]);
_tiq.push(["__setParam", "svcdomain", "user.tistory.com"]);
_tiq.push(["__setParam", "category", ""]);
_tiq.push(["__setParam", "articleno", "56"]);
_tiq.push(["__setParam", "plink", "http://pythonkim.tistory.com/56"]);
_tiq.push(["__setParam", "date", "2016-08-11 12:54:12"]);
_tiq.push(["__setParam", "author", "pythonkim"]);
_tiq.push(["__setParam", "length", "25081"]);
_tiq.push(["__setParam", "isauthor", "N"]);
_tiq.push(["__setParam", "ishidden", "1"]);
_tiq.push(["__setParam", "comments", "0"]);
_tiq.push(["__setParam", "param1", "0"]);
_tiq.push(["__setParam", "param2", "e"]);
_tiq.push(["__setParam", "param3", ""]);
_tiq.push(["__setParam", "like_ex", "{'serviceId': 'tistory', 'uniqueId': '2072317_56', 'serviceCategories': '404,blogId_2072317'}"]);
_tiq.push(["__trackPageview"]);
(function(d) {
	var se = d.createElement('script'); se.type = 'text/javascript'; se.async = true;
	se.src = location.protocol + '//m2.daumcdn.net/tiara/js/td.min.js';
	var s = d.getElementsByTagName('head')[0]; s.appendChild(se);
})(document);
</script>
<script type="text/javascript">
var __TiaraObj = __TiaraObj || {}; if ('undefined' === typeof __TiaraObj.startTime) { __TiaraObj.startTime = new Date(); }
var addEvent = function (evt, fn) { window.addEventListener ? window.addEventListener(evt, fn, false) : window.attachEvent('on' + evt, fn); };
var ua = navigator.userAgent.toLowerCase(); var isIOS = /iP[ao]d|iPhone/i.test(ua); var contentStat = function() {
_tiq.push(['__content', 't_content', {
"c_id":"2072317_56", 
"c_title":"파이쿵 :: 40. ConvNet을 TensorFlow로 구현하자 (MNIST 99%) (lab 11)", 
"type":"article", 
"author":"사과쿵", 
"author_id":"1415031", 
"cp":"pythonkim", 
"cp_id":"2072317", 
"regdata":"2016-08-11 12:54:12", 
"plink":"http://pythonkim.tistory.com/56", 
"media":"pcweb", 
"comment_cnt":0, 
"duration": (new Date()).getTime() - __TiaraObj.startTime.getTime()
}]); };
addEvent(isIOS ? "pagehide" : "beforeunload", contentStat);
</script>
<script type="text/javascript">window.roosevelt_params_queue = window.roosevelt_params_queue || []; window.roosevelt_params_queue.push({channel_id: "dk", channel_label: "tistory"});</script>
<script type="text/javascript" src="//adimg.daumcdn.net/rt/dk_bt/roosevelt_dk_bt.js" async></script><script type="text/javascript">if(window.console!=undefined){setTimeout(console.log.bind(console,"%cTISTORY","font:8em Arial;color:#EC6521;font-weight:bold"),0);setTimeout(console.log.bind(console,"%c  나를 표현하는 블로그","font:2em sans-serif;color:#333;"),0);}</script>		<div id="tistorytoolbarid"
		     style="position:absolute;height:20px;top:4px;right:0px;background-color:transparent;background-image:none;z-index:11;">
			<div class="tistorytoolbar tt_menubar_login">
				<div
					class="tt_menubar_whiteBar">
					<div id="ttMenubarInnerWrap" class="tt_menubar_inner">
						<div class="tt_menubar_bg_toolbar"></div>
						<h2 style="display:none;">티스토리 툴바</h2>
						<div class="tt_menubar_mainmenu"><a
								class="tt_menubar_link_tit tt_menubar_link_tit_daum tt_menubar_link_tit_eng"
								href="http://www.daum.net/?nil_ref=tistory"
								target="_blank">Daum</a></div>
						<div class="tt_menubar_bg_bar"></div>
						<div class="tt_menubar_mainmenu"><a class="tt_menubar_link_tit tt_menubar_link_tit_eng"
						                                    href="http://www.tistory.com">Tistory</a>
						</div>
						<div class="tt_menubar_bg_bar"></div>
						<div class="tt_menubar_logout"><a class="tt_menubar_link_tit"
														  href="https://www.tistory.com/auth/login">로그인</a>
						</div>
					</div>
				</div>
			</div>
		</div>
		</body>
</html>
